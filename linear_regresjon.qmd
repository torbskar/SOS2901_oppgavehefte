# Lineær regresjon

I dette kapittelt skal vi bruke følgende pakker:

```{r}
#| eval: true
#| code-fold: false
#| echo: true
#| warning: false 
#| message: false

invisible(Sys.setlocale(locale='no_NB.utf8'))

library(tidyverse)   # datahåndtering, grafikk og glimpse()
library(skimr)       # funksjonen skim() for å se på data
library(rsample)     # for å dele data i training og testing
```

Lineær regresjon slik vi skal bruke det her er helt vanlig regresjon slik du har lært om i grunnleggende kurs i kvantitative metoder. Altså lineær funksjon estimert med minste kvadraters metode. Alt du har lært før gjelder også her. Forskjellen er at vi nå ikke er så interessert i å tolke $\beta$ men i den predikerte $\hat{y}$.

```{r uke2_pakker}
#| echo: false
#| warning: false 
#| message: false

library(skimr)
library(tidyverse)

```

## Lese inn data

Vi illustrerer lineær regresjon med et empirisk eksempel. Her skal vi bruke data for norske kommuner i 2016. La oss si at vi er interessert i hvordan antall voldshendelser per 1000 innbyggere vil endre seg i en kommune. Dette kunne være relevant for langtidsplanlegging av forebygging, politibemanning, helsetjenester osv. Det kan være et område som er i stor endring slik at befolkningssammensetningen forventes å endre seg og/eller det er endrede lokale økonomiske utsikter.

Først leser vi inn dataene og tar en titt på variabellisten.

```{r}
kommune <- readRDS( "data/kommunedata.rds")
glimpse(kommune)

```

En annen måte å få oversikt over dataene på er å bruke funksjonen `skim()`, som gir noe mer informasjon om fordelingen av hver enkelt variabel.

```{r}

skim(kommune)

```

### Training og testing data

Vi starter med å dele datasettet i *training* og *testing*. Her kan vi bruke pakken 'rsample' og funksjonen `initial_split()` etterfulgt av funksjonene `training()` og `testing()`. Forhåndsvalget for splitten er 0.75, så dermed brukes  75% til training og resten til testing. Du kan også legge til argumentet `prop = ` og sette en annen andel, f.eks. 0.7 for 70%. 

Merk bruken av `set.seed()`. For å splitte genererer R tilfeldige tall, og *seed* styrer hvor den algoritmen starter. Når *seed* er satt vil du få nøyaktig samme resultatet som gjort her. Dette vil du trenge på eksamen for at sensor skal kunne sjekke resultatene dine, så begynn å bruke det med en gang. Tallet inni parentesen betyr ingenting[^linear_regresjon-1] og bare sørger for reproduserbarhet der hvor det er tilfeldige tall involvert.

[^linear_regresjon-1]: Bortsett fra for dem som mener det er svaret på "the Ultimate Question of Life, the Universe, and Everything"

```{r}
library(rsample)

set.seed(42)
kommune_split <- initial_split(kommune, prop = .7)

kommune_train <- training(kommune_split)
kommune_test <- testing(kommune_split)

```

### Enkel lineær regresjon i R


```{r}
#| echo: false
#| message: false
#| warning: false
invisible(Sys.setlocale(locale='no_NB.utf8'))
```


I dette kapittelt skal vi bruke følgende pakker:

```{r}
#| eval: true
#| code-fold: false
#| echo: true
#| warning: false 
#| message: false
library(tidyverse)   # datahåndtering, grafikk og glimpse()
library(skimr)       # funksjonen skim() for å se på data
library(rsample)     # for å dele data i training og testing
library(gtsummary)   # Pent formatert regresjonstabell
library(caret)       # Funksjonen confusionMatrix()
```


En ganske åpenbar faktor som forklarer forekomsten av vold er andel unge menn i kommunen. Rett og slett fordi dette er den demografiske gruppen som begår mest vold - og kriminalitet generelt, faktisk. Hvis befolkningssammensetningen forventes å bli yngre vil det medføre flere unge menn, og da kan vi kanskje forvente at det blir flere voldshendelser bare av den grunn? Sammenhengen mellom unge menn og voldsrate kan estimeres med helt vanlig lineær regresjon.

En god start på de fleste empiriske analyser er å beskrive sammenhengen med et plot. Her legger vi på en lineær regresjonslinje med `geom_smooth()` der vi presiserer lineær modell med `method = "lm"` og lar være å ta med konfidensintervallet `se = FALSE`.

```{r}
#| warning: false
#| message: false 
kommune_train <- kommune_train %>% 
  mutate(prop_unge_menn = (menn_18_25 + menn_26_35)/bef_totalt*100) 

ggplot(kommune_train, aes(x = prop_unge_menn, 
                     y = voldskriminalitet)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) 
```

Lineær regresjon estimeres med `lm()` og du kan få en enkel output med bruk av `summary()`.

```{r}
est <- lm(voldskriminalitet ~ prop_unge_menn, data = kommune_train)
summary(est)

```

Man kan også hente ut kun $r^2$ med følgende kode: 

```{r}
#| code-fold: false
summary(est)$r.squared
```


For ordens skyld: I tidligere metodekurs har du kanskje lært å få ut en penere regresjonstabell med f.eks. gtsummary-pakken. (Det finnes andre pakker også som gjør tilsvarende). Da vil de samme resultatene se ut som følger. Hvordan output er formatert spiller ingen rolle. I denne sammenhengen har vi lite bruk for en pen regresjonstabell da $\beta$ ikke er av primær interesse.

```{r}
library(gtsummary)

tbl_regression(est, intercept = TRUE)

```

Med andre ord kan voldsraten beskrives som:

```{r}
#| echo: false
# library(equatiomatic)
# extract_eq(est, use_coefs = TRUE)
```
$$
\operatorname{\widehat{voldskriminalitet}} = 0.51 + 0.41(\operatorname{prop\_unge\_menn})
$$

Men vi har også sett at $r^2$ er ganske lav, bare `r round(summary(est)$r.squared, digits = 3)`. Denne koeffisienten kalles også "coefficient of determination" og sier noe om i hvor stor grad modellen fanger opp variasjoenen i dataene. En lav $r^2$ betyr at modellen i liten grad gjør det. Vi må altså forvente at modellen vil bomme ganske kraftig i sine prediksjoner. Vi kan velge å ta modellen seriøst likevel, men ikke ha for store forventninger for prediksjonene!

Et annet mål på hvor godt modellen treffer er "Root mean square error", RMSE. Dette kan skrives som:

$$ rmse = \sqrt{ \frac{ \sum{(O_i-P_i)^2} }{N} }  $$

der $O$ er de observerte verdiene og $P$ er de predikerte verdiene for observasjon $i$. Merk at $(O_i-P_i)$ er residualene. I R kan vi hente ut residualene fra regresjons-objektet med dollartegnet `...$res` etter objektnavnet. Da kan du regne ut RMSE som følger:

```{r}
#| code-fold: false
rmse <- sqrt(mean(est$res^2))
rmse
```

RMSE sier altså omtrentlig hvor mye modellen i gjennomsnitt bommer på de observerte verdiene. [^linear_regresjon-2]. Hvorvidt det er presist *nok* eller ikke vil vel strengt tatt komme an på behovet for presisjon, altså: hva man skal bruke det til.

[^linear_regresjon-2]: Denne formuleringen er ganske omtrentlig. RMSE er egentlig kvadratroten av gjennomsnittet til de kvadrerte residualene, som er noe litt annet enn gjennomsnittet av de absolutte verdiene av residualene. Det gir bl.a. litt mer vekt til store residualer enn et vanlig gjennomsnitt. 

For å få litt bedre tak på hva RMSE betyr kan vi se på et plot av de predikerte og observerte verdiene. Vi kan predikere vold for hver enkelt kommune basert på denne modellen, som altså er den forventede voldsraten *hvis modellen er sann*. Funksjonen `predict()` gir oss hva vi trenger.

```{r}
#| code-fold: false
kom <- kommune_train %>% 
  mutate(pred = predict(est))
```

Merk at koden her lagde en kopi av datasettet der vi har alle de opprinnelige variablene pluss en variabel med de predikerte verdiene. Vi kan nå sammenlignet prediksjonene med de observerte utfallene.

```{r}
#| warning: false
#| error: false
#| message: false
ggplot(kom, aes(x = voldskriminalitet, y = pred)) +
  geom_point(alpha = .3) +
  geom_smooth(method = "lm", se = FALSE)
```

Hvis prediksjonen hadde vært perfekt ville disse punktene ligget på linja, noe den jo ikke gjør. Modellen bommer altså ganske mye.

Hva hvis vi vil vite forventet voldsrate for en kommune for en gitt andel unge menn? Løsningen er å lage et nytt datasett med de verdiene vi er interessert i og så predikere for dette datasettet med å spesifisere `newdata = dt`. Her er et eksempel der vi ønsker å vite voldsraten hvis andelen unge menn er 15%.[^](OBS! I en tidligere versjon stod det 0.15 i koden under, men merk at variabelen er på skalaen prosentpoeng og ikke anderl. Hivs du stusset på dette, så var det altså riktig tenkt.)

```{r}
#| code-fold: false
dt <- data.frame(prop_unge_menn = 15)
p <- predict(est, newdata = dt)
p
```

I følge modellen vil altså en kommune der 15% av populasjonen er unge menn ha en `r round(p, digits = 3)` voldshendelser per 1000 innbyggere. Fra tradisjonell statistikk vet vi jo at det er usikkerhet knyttet til dette estimatet og vi kan også ta det med i beregningen her. Vanligvis vil man estimere med et *konfidensintervall*, som gjelder hvis man estimerer et gjennomsnitt i en gruppe. Her skal vi derimot predikere for en enkelt kommune, som da har større usikkerhet enn om man estimerer for en enkelt observasjon. Dette kalles prediksjonsintervall og må spesifiseres i koden. Hvis det ikke er gitt vil R gi konfidensintervallet.

```{r}
p_ki <- predict(est, newdata = dt, interval = "prediction")
p_ki
```

Tolkningen er ellers tilsvarende som for konfidensintervall: vi forventer med "95% sannsynlighet"[^linear_regresjon-3] at voldsraten vil være mellom  `r round(p_ki[2], 1)` og `r round(p_ki[3], 1)` per 1000 innbyggere.

[^linear_regresjon-3]: Dette er en omtrentelig formulering. Alle sannsynligheter gjelder i det lange løp: altså hvis man gjør undersøkelsen veldig mange ganger.

### Multippel regresjon

Enkel regresjon er nettopp enkel og prediksjonen blir ikke så god. Men vi kan komplisere vesentlig ved å inkludere flere variable og bruke alle triksene man evt. har lært om multippel regresjon tidligere, primært interaksjonsledd, polynomer og transformasjoner osv. (Det er ok om du ikke har lært alt dette tidligere).

I R vil vi da bare legge til flere variabelnavn i formelen. Ellers er det meste likt som for enkel lineær regresjon.

```{r}
est_m <- lm(voldskriminalitet ~ prop_unge_menn + inntekt_totalt_median + shj_unge + 
                   ant_husholdninger , 
            data = kommune_train)
summary(est_m)


```

Merk at $r^2$ nå har gått betraktelig opp, til ca `r round(summary(est_m)$r.squared, digits = 2)`. Gitt at vi tolker dette som i hvor stor grad vi kan *predikere* utfallet fra datasettet, så er det kanskje likevel ikke imponerende høyt: vi vil fremdeles forvente mye feil prediksjon.

Her er et scatterplot av observert mot forventet voldsrater:

```{r}
#| warning: false
#| error: false
kom_pred <- kommune_train %>% 
  mutate(pred = predict(est_m))

ggplot(kom_pred, aes(x = voldskriminalitet, y = pred)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

```

La oss inkludere alle aktuelle variable i datasettet. Et lite triks her er å fjerne alle variable vi ikke er interessert i og lagre det i et nytt datasett. I `lm()` kan vi da presisere formelen som `Vold ~ .` som i denne sammenhengen betyr å ta med alle variabelene i stedet for å liste opp hver enkelt variabel.

```{r}
kom_s <- kommune_train %>% 
  select(-c(kommune, kommune_nr, ordenslovbrudd,  
            nark_alko_kriminalitet, trafikklovbrudd, andre_lovbrudd, 
            prop_unge_menn))

full_mod <- lm(voldskriminalitet ~ . , data = kom_s)
summary(full_mod)
```

$r^2$ gikk noe opp, til `r round(summary(full_mod)$r.squared, digits = 3)`.

Men vi kan gjøre modellen ekstra komplisert ved inkludere alle mulige interaksjonsledd. En åpenbar ulempe med dette er at hver enkelt koeffisent blir svært mye vanskeligere å tolke. Vi fokuserer derfor kun på $r^2$ som kan hentes ut uten å ta med resten av output.

```{r}
full_mod2 <- lm( voldskriminalitet ~ .^2, data = kom_s)
summary(full_mod2)$r.squared
```

$r^2$ gikk vesentlig opp. Men når vi først driver med kompliserte modellspesifikasjoner som uansett er vanskelige å tolke - hvorfor begrense seg til 2-veis interaksjoner? Her er en versjon med alle 3-veis interaksjoner, og nå begynner $r^2$ virkelig å bli høy!

```{r}
full_mod3 <- lm( voldskriminalitet ~ .^3, data = kom_s)
summary(full_mod3)$r.squared
```

Vi kan trimme modellen så den ikke har med så voldsomt mange parametre. En mulighet er å overlate dette til datamaskinen ved å la den gjøre en trinnvis test av hvorvidt modellene blir signifikant bedre av å legge til hver av de parametrene, og stopper når modellen ikke blir bedre. Så beholdes den "beste" av disse modellene, ikke nødvendigvis den som er mest komplisert.

OBS! Merk at dette er en rent mekanisk seleksjon, og frarådes i de fleste samfunnsvitenskapelige sammenhenger. Tolkning av parametre og statistisk usikkerhet er nå på svært tynn is. Men det kan gi god prediksjon likevel.

```{r ols_step}
step_mod <- MASS::stepAIC(full_mod3, direction="forward", 
                          trace = FALSE)
summary(step_mod)$r.squared
```

Hvis vi nå predikerer for hver enkelt kommune og plotter forventet mot observert, så får vi et svært mye bedre sammenfall enn tidligere.

```{r}
#| warning: false
#| error: false
#| message: false
kom_pred <- kom_s %>% 
  mutate(pred = predict(step_mod))

ggplot(kom_pred, aes(x = voldskriminalitet, y = pred)) +
  geom_point(alpha = .3) +
  geom_smooth(method = "lm", se = FALSE)

```

Nå kan vi også regne ut RMSE, som altså er "root mean squared error". Med andre ord: regn ut residualene (dvs. "error"), og kvadrer denne, og så ta kvadratroten av gjennomsnittet av denne. Her er en kode skrevet litt omstendelig så den er litt lettere å forstå:

```{r}
rmse <- kom_s %>% 
  mutate(pred = predict(step_mod), 
         residual = pred - voldskriminalitet) %>% 
  mutate(sq.resid = residual^2) %>% 
  summarise(sqrt(mean(sq.resid)))

rmse  
```

Dette betyr omtrentlig at modellen i gjennomsnitt vil bomme med `r base::round(rmse, digits = 3)` prosentpoeng på voldsraten i kommunen. [^linear_regresjon-4] Hvorvidt det er presist *nok* eller ikke vil vel strengt tatt komme an på behovet for presisjon, altså: hva man skal bruke det til.

[^linear_regresjon-4]: Denne formuleringen er ganske omtrentlig. RMSE er egentlig kvadratroten av gjennomsnittet til de kvadrerte residualene, som er noe litt annet enn gjennomsnittet av de absolutte verdiene av residualene. Det gir bl.a. litt mer vekt til store residualer enn et vanlig gjennomsnitt

### Predikere for nye data

Men nå har vi bare sett på hvordan prediksjonen fungerer på training-datasettet. Vi må sjekke med testing-datasettet. Det lagde vi i begynnelsen, så nå henter vi det frem og gjør det samme som over. I 'predict()' må vi nå angi 'newdata ='.

```{r}
#| code-fold: false
#| warning: false
#| error: false
kom_pred2 <- kommune_test %>% 
  mutate(pred = predict(step_mod, newdata = .), 
         residual = pred - voldskriminalitet)

ggplot(kom_pred2, aes(x = voldskriminalitet, y = pred)) +
  geom_point(alpha = .3) +
  geom_smooth(method = "lm", se = FALSE)

```

Ser dette rart ut? Det er to observasjoner som har pedikert skyhøy voldsrate! Disse to prediksjonene bommer voldsomt, og med litt erfaring vil man se at dette her går aldri bra for $r^2$, som regnes ut slik:

```{r}
kom_pred2  %>% 
  mutate(residual_total = voldskriminalitet - mean(voldskriminalitet)) %>% 
  summarise(SSres = sum(residual^2), 
            SStot = sum(residual_total^2)) %>% 
  mutate(r_squared = 1 - (SSres/SStot))
  
```

Ganske riktig! Dette ble bare tull. Kvadratsummen til residualene ble mye høyere enn total kvadratsum. Dermed blir $r^2$ helt fjerne.

Dette er en ganske ekstrem variant av *overfitting*. Ved å formulere en veldig komplisert modell som passer veldig godt til training-dataene kan vi ende opp med en modell som passer veldig, veldig dårlig til nye data. Hvis man skulle utforme f.eks. politikktiltak på grunnlag av en slik prediksjon vil det kunne gå riktig så dårlig.

Det er i dette tilfellet kanskje ikke så rart: modellen ble formulert *kun* for å maksimere $r^2$ og uten så mye andre tanker bak.

Det er nok bedre med en enklere modell. Vi prøver heller å bruke modellen der alle prediktorene er med, men uten alle de kompliserende interaksjonene:

```{r}
#| warning: false
#| error: false
kom_pred3 <- kommune_test %>% 
  mutate(pred = predict(full_mod, newdata = .), 
         residual = pred - voldskriminalitet)

ggplot(kom_pred3, aes(x = voldskriminalitet, y = pred)) +
  geom_point(alpha = .3) +
  geom_smooth(method = "lm", se = FALSE)

```

```{r}
kom_pred3  %>% 
  mutate(residual_total = voldskriminalitet - mean(voldskriminalitet)) %>% 
  summarise(SSres = sum(residual^2), 
            SStot = sum(residual_total^2)) %>% 
  mutate(r_squared = 1 - (SSres/SStot))
  
```

Sammenlignet med $r^2$ på trainingdata, 'r summary(full_mod)\$r.squared', er dette ikke så værst. Litt dårligere tilpassning må man regne med.

RMSE regnes ut slik:

```{r}
kom_pred3 %>% 
  mutate(sq.resid = residual^2) %>% 
  summarise(sqrt(mean(sq.resid)))
  
```

Det er altså slik at en enklere modell kan passe til *nye* data langt bedre enn en veldig komplisert modell. Grunnen er overfitting: modellen fanger opp vel så mye tilfeldig støy som det underliggende mønsteret. Støyen vil jo være annerledes i de nye dataene.

### Oppsummerende kommentar

Dette gjelder generelt: mer komplisert regresjonsmodell vil gi tilsynelatende bedre tilpassning til data enten man måler med $r^2$ eller RMSE. Man kan riktignok bruke mål på tilpassning som justerer for antall parametre etc (f.eks. justert $r^2$, AIC eller BIC), som kanskje kan bedre dette noe, men det vil ofte lede til overfitting likevel.

Det er derfor veldig viktig å teste modellen mot *nye* data. I praksis testing-dataene man lagde til å begynne med.

I resten av kurset skal vi unngå å bruke latterlige kompliserte modeller som ble demonstret ovenfor. Man kan godt bruke interaksjonsledd, polynomer, splines og andre fancy ting. Men med måte. 


## Oppgaver

::: {#exr-ols-rep}
Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer.
:::

::: {#exr-ols-eksplisitt}
Velg et datasettet og formuler hva en prediksjonsmodell kan kunne brukes til. Se for deg at tiltak du foreslår vil altså ha faktiske konsekvenser, så gjør en vurdering av hvorvidt feilprediksjoner vil være problematiske og i så fall på hvilken måte. Vurder mulighetene for feil opp mot gevinst ved riktig prediksjon.

Merk: det er ikke viktig at anvendelsen skal være realistisk, men du må alltid ta konsekvensen i vurderingene.
:::

::: {#exr-split}
Last inn valgte datasett og splitt i et training og et testing datasett. Sett splitten ved .70. Bruk training-data til å gjøre deg kjent med dataene og estimere modellene. Ikke bruk testing-dataene inntil du får beskjed om det.
:::

::: {#exr-sepaa}
Gjør deg kjent med innholdet i disse training-dataene. Du kan gjøre f.eks. følgende:

a)  Bruk `glimpse()` og `skim()` til å få oversikt over innholdet i datasettet
b)  Hvis det er noen variable du ikke kommer til å bruke, slett gjerne disse med en gang
c)  Lag noen tabeller og plot som viser hvordan utfallsvariabelen er fordelt etter andre variable
:::

::: {#exr-ols-train}
Estimer flere lineær regresjonsmodeller med et fåtall prediktorer. Gjør et utvalg av de variablene du mener er mest relevant for å forklare utfallet. Estimer flere lineære regresjonsmodeller for å predikere utfallet, og sammenlign hvor gode prediksjoner disse gir. Mest relevante statistikker er $r^2$ og RMSE.

a)  Velg ut tre forklaringsvariable og estimer en regresjonsmodell
b)  Estimer en ny modell med alle variable i datasettet
c)  Estimer en ny modell og inkluder noen få polynomer og/eller interaksjonsledd
d)  Gjør et automatisk modellsøk

Plot også predikert verdi mot observert verdi og gjør en vurdering av RMSE.
:::

::: {#exr-ols-test}
I forrige oppgave brukte du testing-datasettet til både å estimere modellene og vurdere resultatet. Nå skal du bruke testing-datasettet til å vurdere de samme resultatene. Dette gjør du ved å predikere på testing-datasettet og regne ut $r^2$ og RMSE for disse dataene. For hver modell i forrige oppgave, gjør som følger:

a)  Prediker utfallet på testing-datasettet
b)  Regn ut $r^2$ og RMSE
c)  Hvor stor er *endringen* i $r^2$ og RMSE fra resultatene når du brukte training-datasettet?

Vurdering: En mer komplisert modell beskriver dataene bedre. Men er det like stor *endring* i $r^2$ og RMSE for enkle og mer kompliserte modeller? Beskriv hva du ser og gi en forklaring.
:::

