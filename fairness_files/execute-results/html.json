{
  "hash": "48bf5a83bbdfb2abd9ba9c9ea58eb0fc",
  "result": {
    "markdown": "# Fairness og tuning\n\n\n## Introduksjon til fairness\nDet blir litt repetisjon her nå. Det grunnleggende med fairness har vi vært innom før, men nå gjør vi det i kontekst av random forest. En ting er å avdekke bias og urettferdighet, en annen ting er å gjøre noe med det! \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(tidyverse)\nlibrary(randomForest)\nlibrary(caret)\nlibrary(fairness)\n```\n:::\n\n\n\n\nCompas er et risikoverktøy brukt av amerikansk politi i flere stater som benyttes på individnivå. Bruken av dette verktøyet har vært kontroversielt i flere år og kraftig kritisert av flere. En viktig grunn er at prediksjonene slår forskjellig ut for ulike grupper og er slik sett \"biased\" mot bl.a. svarte borgere. Resultatet er at de blir mer utsatt for politiets oppmerksomhet enn andre.^[Det er verd å minne på at politi i USA i stor grad er mer hardhendte enn norsk politi. Konsekvensene er altså litt mer alvorlig enn at unødig mange føler seg unødig mistenkte.] Et datasett er gjort tilgjengelig av [Propublica her](https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis) som vi skal bruke. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompas <- readRDS(\"../data/compas.rds\")\n\nglimpse(compas)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n```\n:::\n:::\n\n\nVi tilpasser først en random forest modell. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(4356)\nglimpse(compas)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n```\n:::\n\n```{.r .cell-code}\nrf <- randomForest(Two_yr_Recidivism ~ .,\n                   #importance = TRUE,\n                    data = compas)\n```\n:::\n\n\n\nLager en prediksjon i en kopi av datasett, mest for å ikke blande sammen prediksjonene med det opprinnelige datasettet. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf))  \n```\n:::\n\n\n\n\nDa kan vi lage en confusion matrix for å se hvordan modellen fungerer. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(compas_p$pred_rf,\n                compas_p$Two_yr_Recidivism, positive=\"1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2462 1132\n         1  901 1677\n                                          \n               Accuracy : 0.6706          \n                 95% CI : (0.6587, 0.6823)\n    No Information Rate : 0.5449          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.3313          \n                                          \n Mcnemar's Test P-Value : 3.378e-07       \n                                          \n            Sensitivity : 0.5970          \n            Specificity : 0.7321          \n         Pos Pred Value : 0.6505          \n         Neg Pred Value : 0.6850          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2717          \n   Detection Prevalence : 0.4177          \n      Balanced Accuracy : 0.6645          \n                                          \n       'Positive' Class : 1               \n                                          \n```\n:::\n:::\n\n\n\nFor å få litt bedre grep om hvordan fairness-pakken fungerer kan gjøre det mer manuelt først. Vi kan f.eks. se på hvordan modellen slår ut for menn og kvinner. \n\n\nFørst kan vi da splitte datasettet i to etter kjønn. Her for menn. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompas_1 <- compas_p %>% \n  filter(Sex == \"Male\")\n```\n:::\n\n\n\nConfusion matrix for menn blir da tilsvarende som tidligere. \n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(compas_1$pred_rf,\n                compas_1$Two_yr_Recidivism, positive=\"1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 1807  897\n         1  794 1499\n                                          \n               Accuracy : 0.6616          \n                 95% CI : (0.6483, 0.6747)\n    No Information Rate : 0.5205          \n    P-Value [Acc > NIR] : < 2e-16         \n                                          \n                  Kappa : 0.3209          \n                                          \n Mcnemar's Test P-Value : 0.01312         \n                                          \n            Sensitivity : 0.6256          \n            Specificity : 0.6947          \n         Pos Pred Value : 0.6537          \n         Neg Pred Value : 0.6683          \n             Prevalence : 0.4795          \n         Detection Rate : 0.3000          \n   Detection Prevalence : 0.4589          \n      Balanced Accuracy : 0.6602          \n                                          \n       'Positive' Class : 1               \n                                          \n```\n:::\n:::\n\n\nMerk at vi her fikk en accuracy på 0.66 for menn. \nSplitter datasettet i to etter kjønn. Her for kvinner. \n\n::: {.cell}\n\n```{.r .cell-code}\ncompas_2 <- compas_p %>% \n  filter(Sex == \"Female\")\n```\n:::\n\n\nConfusion matrix for kvinner\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(compas_2$pred_rf,\n                compas_2$Two_yr_Recidivism, positive=\"1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 655 235\n         1 107 178\n                                         \n               Accuracy : 0.7089         \n                 95% CI : (0.682, 0.7348)\n    No Information Rate : 0.6485         \n    P-Value [Acc > NIR] : 6.251e-06      \n                                         \n                  Kappa : 0.3128         \n                                         \n Mcnemar's Test P-Value : 6.539e-12      \n                                         \n            Sensitivity : 0.4310         \n            Specificity : 0.8596         \n         Pos Pred Value : 0.6246         \n         Neg Pred Value : 0.7360         \n             Prevalence : 0.3515         \n         Detection Rate : 0.1515         \n   Detection Prevalence : 0.2426         \n      Balanced Accuracy : 0.6453         \n                                         \n       'Positive' Class : 1              \n                                         \n```\n:::\n:::\n\n\nMerk at vi her fikk en accuracy på 0.71 for kvinner. Modellen er altså mer presis for kvinner enn for menn. Dette er et eksempel på *bias* i modellen. Forholdet mellom feilrater er da $.66/.71 = .93$. Dette tallet sier at modellens accuracy for menn er 93% av accuracy for kvinner, og dette er et mål på *bias* i modellen. Om man synes det er mye eller lite er derimot en vurderingssak! \n\nMan kan også regne ut den andre veien, altså kvinner delt på menn. Da får vi 1.08, som sier at modellen er 8% mer presis for kvinner enn for menn. Det blir jo det samme, men motsatt vei. Vi må altså velge *referansegruppe* for sammenligningen. \n\n\nFunksjoner `acc_parity` fra fairness-pakken gjør akkurat dette: regner ut accuracy for ulike grupper og sammenligner dem. Her er koden:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc <- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'pred_rf', \n                  base         = 'Female')\nacc$Metric\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      Female        Male\nAccuracy           0.7089362    0.661597\nAccuracy Parity    1.0000000    0.933225\nGroup size      1175.0000000 4997.000000\n```\n:::\n:::\n\nMen spesifiserer altså hvilke variable som er utfallsvariabel, hvilken som er gruppevariabel, hvilken som er prediksjonsvariabel og hvilken gruppe som skal være referanse. \n\n\n\n\nFairness-pakken har også noen innebygde funksjoner for grafiske fremstillinger. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc$Metric_plot\n```\n\n::: {.cell-output-display}\n![](fairness_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n## Fairness: tuning med stratifisering\n\nVi har lært litt om grunnleggende tuning. For å justere feilratene er den mest effektive måten i random forest å endre hvordan samplingen skjer ved `sampsize`.^[Dette er ikke eneste måten å tune på, men det vi dekker her. Det finnes andre funksjoner for random forest som inneholder mer funksjonalitet for tuning.] Dette hjelper imidlertid ikke nødvendigvis mot *bias*, altså ulike feilrater for undergrupper. Det vil jo være nyttig om man kunne gjøre noe med slike skjevheter! Heldigvis kan vi det, men det er ikke så lett som man skulle håpe. \n\nDet viktige punktet å huske på er at random forest trekker tilfeldige utvalg for hvert tre og parameteren `sampsize` justerer hvor mange observasjoner som trekkes. Vi kan nå justere algoritmen til å gjøre en *stratifisert* trekning. Med andre ord: det gjøres en tilfeldig trekning innenfor subgrupper. Ovenfor har vi altså sett at modellen ikke er helt rettferdig med hensyn på kjønn. La oss fikse det! \n\nFørst må vi lage en vektor for å stratifisere etter. Dette bør være variabelen for kjønn *kombinert med* utfallsvariabelen. Da får vi fire kategorier: menn med og uten tilbakefall, og kvinner med og uten tilbakefall. Så kan vi bruke sampsize til å angi hvor mange som skal trekkes fra hver av disse fire gruppene.  \n\nHer er en kode for å lage en slik stratifiseringsvektor. Pussig nok skal denne vektoren ikke legges inn som en del av datasett, men i et eget objekt. I koden nedenfor bruker vi `mutate()` for å lage en ny variabel og `paste0()` for å \"lime sammen\" de to variabelene. Til sist bruker `pull()` for å trekke ut kun den variabelen i en egen vektor.^[For de av dere som kan en del R fra før: `select()` ville gjort noe tilsvarende, men da ville objektet være en data.frame med én variabel fremfor en vektor. Forskjellen er minimal, men `randomForest()` vil ha det på denne måten.] Koden nedenfor gir også en tabell med antall observasjoner i hver kategori av denne vektoren. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nstrat <- compas %>% \n  mutate(strat = paste0(Sex, Two_yr_Recidivism)) %>% \n  pull(strat)\n\ntable(strat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstrat\nFemale0 Female1   Male0   Male1 \n    762     413    2601    2396 \n```\n:::\n:::\n\n\nMerk at denne vektoren har verdiene som er en kombinasjon av de opprinnelige variablene. Når vi nå angir tall i `sampsize()` så er det i denne samme rekkefølgen. Her blir det altså: \n\n1) Kvinner uten tilbakefall \n1) Kvinner med tilbakefall\n1) Menn uten tilbakefall\n1) Menn med tilbakefall \n\nMerk da at tallene som angis for `sampsize` ikke kan være høyere enn antallet i hver gruppe, og helst ikke høyere enn ca 70% av dette. Men det er primært *forholdet mellom tallene* som er viktig. \n\nHer er kode for random forest med stratifisert utvalg og angitte verdier av sampsize. Tallene oppgis i den rekkefølgen som er angitt i variabelen `strata`, altså som i tabellen ovenfor. Her er altså kvinner vektet lavere enn menn, som burde øke accuracy for menn. Samtidig er kvinner med tilbakefall vektet litt høyere enn kvinner uten tilbakefall. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(45)\nrf <- randomForest(Two_yr_Recidivism ~ .,\n                   data = compas,\n                   strata = strat, \n                   sampsize = c(215, 290, 1500, 1500), \n                   ntree=800)\n```\n:::\n\n\nNå kan vi lage en prediksjon og se om modellen er mer rettferdig på samme måte som vi har gjort tidligere. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf))  \n\nacc <- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'pred_rf', \n                  base         = 'Female')\nacc[[2]]\n```\n\n::: {.cell-output-display}\n![](fairness_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\nMagisk! Plutselig har vi endret en modell med innebygde kjønnsforskjeller til en kjønnsnøytral modell. I hvert fall på akkurat dette målet, da. Man bør jo også sjekke andre relevante mål på fairness.  \n\nNå lurer du helt sikkert på hvordan du skal velge verdier for `sampsize` i et slikt tilfelle. Det litt skuffende svaret er at du må prøve deg litt frem. Men det hjelper å vite hvilket tall som betyr hva. I dette eksempelet sikres det at det trekkes omtrent like mange kvinner med og uten tilbakefall, og tilsvarende for menn. Så er det justert litt for å oversample kvinner med tilbakefall. Men for å være ærlig: jeg testet en god del varianter her før jeg fikk det resultatet jeg ville ha. \n\n\n### Hva andre subgrupper? \nSå er spørsmålet om den balansering vi nå har gjort slår ut på andre grupper også. La oss se på etnisitet. Vi bruker den samme modellen som over, men bytter ut variabelen for kjønn med variabelen for etnisitet. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacc <- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Ethnicity',\n                  preds        = 'pred_rf', \n                  base         = 'Caucasian')\nacc[[2]]\n```\n\n::: {.cell-output-display}\n![](fairness_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nDet er lov å bli litt skuffa nå. Dette ble jo ikke like pent balansert som for kjønn. Men det er jo ikke så rart, egentlig. Det er jo ikke gjort noe for å balansere på etnisitet. \n\nEn første mulighet er å gjøre en vurdering på om kjønnsbalanse eller etnisitet er viktigst. Kanskje man heller skulle fokusere på etnisitet? Det vil antakeligvis ikke være noen dum ide. \n\nEn annen mulighet er å stratifisere på begge variable samtidig. La oss undersøke muligheten ved å lage en tilsvarende stratifiserings-vektor og se på frekvensfordelingen. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nstrat <- compas %>% \n  mutate(strat = paste0(Sex, Ethnicity, Two_yr_Recidivism)) %>% \n  pull(strat)\n\ntable(strat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstrat\nFemaleAfrican_American0 FemaleAfrican_American1            FemaleAsian0 \n                    346                     203                       1 \n           FemaleAsian1        FemaleCaucasian0        FemaleCaucasian1 \n                      1                     312                     170 \n        FemaleHispanic0         FemaleHispanic1  FemaleNative_American1 \n                     56                      26                       2 \n           FemaleOther0            FemaleOther1   MaleAfrican_American0 \n                     47                      11                    1168 \n  MaleAfrican_American1              MaleAsian0              MaleAsian1 \n                   1458                      22                       7 \n         MaleCaucasian0          MaleCaucasian1           MaleHispanic0 \n                    969                     652                     264 \n          MaleHispanic1    MaleNative_American0    MaleNative_American1 \n                    163                       6                       3 \n             MaleOther0              MaleOther1 \n                    172                     113 \n```\n:::\n:::\n\n\nProblemet nå er jo at noen grupper er veldig, veldig små. Å stratifiser på disse vil ikke fungere rett og slett. Det er som i annen statistikk: Estimere på veldig små grupper innebærer at det blir bare støy og tilfeldigheter i estimatene. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstrat <- compas %>% \n  mutate(caucasian = ifelse(Ethnicity == \"Caucasian\", \"Caucasian\", \"Other\")) %>% \n  mutate(strat = paste0(Sex, caucasian, Two_yr_Recidivism)) %>% \n  pull(strat)\n\ntable(strat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nstrat\nFemaleCaucasian0 FemaleCaucasian1     FemaleOther0     FemaleOther1 \n             312              170              450              243 \n  MaleCaucasian0   MaleCaucasian1       MaleOther0       MaleOther1 \n             969              652             1632             1744 \n```\n:::\n:::\n\n\n\nLa oss prøve med dette. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(45)\nrf <- randomForest(Two_yr_Recidivism ~ .,\n                   data = compas,\n                   strata = strat, \n                   sampsize = c(120, 120, \n                                200, 200, \n                                400, 400, \n                                900, 900), \n                   ntree=800)\n\n#rf\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf))  \n\nacc <- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'pred_rf', \n                  base         = 'Female')\nacc[[2]]\n```\n\n::: {.cell-output-display}\n![](fairness_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nacc <- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Ethnicity',\n                  preds        = 'pred_rf', \n                  base         = 'Caucasian')\nacc[[2]]\n```\n\n::: {.cell-output-display}\n![](fairness_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nHer ble det i hvert fall annerledes, men ikke helt likt nå heller. Nå kan man drive på en stund å justere og se hva man får til. Hvis man har et veldig stort datasett (som vi ikke har her) så kan man i teorien justere for flere ulike egenskaper samtidig og i større detalj. Man er rett og slett litt begrenset av dataene. \n\nProblemet er selvsagt at det ikke går an å justere i det uendelige for alle variable. I tillegg kan det uansett være andre egenskaper du ikke har data for som det senere vil vise seg er urettferdig. Det kan f.eks. slå ut svært skjevt for type nabolag, sosioøkonomisk status, religiøs tilhørighet, lengde på håret - eller hva som helst annet. Man trenger data for å sjekke, men også data for å bygge algoritmen. \n\nJeg tror konklusjonen er at man justere for noe, men ikke alt. Men med nok data kan man justere for *mer* - men fremdeles ikke alt. I tillegg er som regel ikke justeringer gratis. Kanskje blir presisjonen i modellen totalt sett dårligere? \n\nSå da er vi tilbake til det litt ubehagelige gjennomgangstemaet om prioriteringer og valg: Vil du f.eks. ha en rettferdig modell eller en presis modell? Hvilke grupper bør den være rettferdig for - og hvilke grupper er det ikke så farlig om den er urettferdig for? Dette kan lett være umulige valg. Men hva er så alternativet? Det er jo heller ikke sikkert er bedre på noen av disse parametrene. \n\n\n## Oppgaver\n\n\n::: {#exr-}\nGå gjennom eksempelet over og sjekk at det fungerer og at du skjønner hvert steg. \n:::\n\n\n::: {#exr-}\nVelg deg et annet datasett og gjør tilsvarende analyse. Det er viktig at du nå gjør en vurdering av hvilke undergrupper du synes er viktigst å motvirke urettferdighet for. Her bør du ta hensyn også til hva slags tiltak og konsekvenser det er snakk om! Skriv ned dine vurderinger om dette som begrunnelse for hvordan du vil motvirke urettferdighet i modellen. \n\na) Vurder hvilke konsekvenser prediksjonen kan få, med henblikk på et tenkt praktisk tiltak. Hvilke feilrater vil du akseptere? Ta et valg. \na) Estimer modellen som tidligere, lag en confusion matrix og vurder resultatet. Juster modellen til du er fornøyd med resultatet. \na) Vurder hvilken undergruppe du synes det er viktigst at ikke blir biased. \na) Hvilket mål på fairness synes du er viktigst i akkurat dette tilfellet? Velg ett mål, begrunn det valget og sjekk. \na) Estimer modellen på nytt med stratifisert utvalg og justert `sampsize`. Prøv deg frem til du får et akseptabelt mål på fairness. \na) Sjekk confusion matrix og sammenlign med den første modellen. Modellen ble kanskje mer rettferdig, men gikk f.eks. accuracy ned eller endrede feilrater? Eller litt flåsete sagt: Var det verd å få en mer rettferdig modell?\na) Sjekk nå det samme målet på fairness med to andre undergrupper. Ble det like bra?  \n\n:::\n\n\n::: {#exr-}\nVelg et annet datasett og gjør tilsvarende øvelse. \n:::\n\n\n\n",
    "supporting": [
      "fairness_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}