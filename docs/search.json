[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SOS2901 Maskinlæring for samfunnsvitere",
    "section": "",
    "text": "Introduksjon\nDette dokumentet gir en oversikt over hva vi skal dekke i løpet av semesteret. Det lages delvis underveis, så det vil bli oppdateringer jevnlig. Ikke alt er klart akkurat nå, og det vil skje endringer i dokumentet underveis gjennom hele semesteret.\nHvert kapittel starter med en introduksjon til temaet og et empirisk eksempel. Deretter kommer noen oppgaver, som dere skal løse. Oppgavene er ganske åpne og det er meningen at dere skal velge et annet datasett og gjøre tilsvarende analyser som i eksempelet. Fra eksempelet får dere også nødvendig kode. Datasettene som er tilgjengelige finner dere i appendikset. Last de ned til egen masking for å jobbe med dem.\nHver uke skal vi jobbe med på følgende måte:\nDette kurset forutsetter at man har grunnleggende ferdigheter i kvantitative metoder og har brukt R før. Hvis du vet du trenger det: frisk opp litt fra tidligere kurs.\nNår det er sagt, så er det begrenset hvor mye man må kunne fra før hvis du er motivert til å jobbe med stoffet skal du nok få til dette. Det blir mye nytt uansett.\nHvis du trenger oppfriskning av hvordan R fungerer, så er Wickham & Grolemunds bok “R for data science” et utmerket oppslagsverk. Men merk at vi i begrenset grad vil bruke “Tidyverse” til annet enn datahåndtering og noe grafikk."
  },
  {
    "objectID": "index.html#forberedelse-til-undervisning",
    "href": "index.html#forberedelse-til-undervisning",
    "title": "SOS2901 Maskinlæring for samfunnsvitere",
    "section": "Forberedelse til undervisning",
    "text": "Forberedelse til undervisning\nTil hver undervisningsgang skal du ha forberedt to ting:\n\nValgt et datasett og splittet dette i training/testing\nFormulert noe om hva en prediksjon med denne typen data kan tenkes å brukes til i praksis (en slags problemstilling, med andre ord)\nForberede minst ett spørsmål eller kommentar til det tekniske eller pensum. Vi starter hver undervisning med oppklaringer"
  },
  {
    "objectID": "index.html#undervisningsvideoer",
    "href": "index.html#undervisningsvideoer",
    "title": "SOS2901 Maskinlæring for samfunnsvitere",
    "section": "Undervisningsvideoer",
    "text": "Undervisningsvideoer\nDet legges ut undervisningsvideoer i Canvas. Det går også an å få tilgang til de samme videoene på denne lenken"
  },
  {
    "objectID": "index.html#installasjon",
    "href": "index.html#installasjon",
    "title": "SOS2901 Maskinlæring for samfunnsvitere",
    "section": "Installasjon",
    "text": "Installasjon\nDu må installere både R og Rstudio på din datamaskin. Hvis du har Windows-maskin trenger du også installere Rtools. Hvis du har Mac OS X kan det hende du må installere XQuartz.\nSe ellers video fra SICSS"
  },
  {
    "objectID": "index.html#pakker",
    "href": "index.html#pakker",
    "title": "SOS2901 Maskinlæring for samfunnsvitere",
    "section": "Pakker",
    "text": "Pakker\nR er basert på bruk av “pakker” som må installeres for å få tilgang til funksjoner vi skal bruke. Disse installeres med bruk av kommandoen install.packages(). F.eks. kan man installere pakken Tidyverse med følgende: install.packages(\"tidyverse\").\nFor å installere flere pakker kan man kjøre install.packages() flere ganger, men det er enklere å liste opp alle pakkene i et objekt og så kjøre install.packages() på dette objektet. Noe slikt:\nVi skal i hvert fall bruke de pakkene som installeres med følgende kode:\n\npkgs <- c(\"tidyverse\", \"skimr\", \"randomForest\", \"rpart\", \"rpart.plot\", \"AUC\", \"rsample\", \"fairness\", \"xgboost\")\ninstall.packages(pkgs)\n\nDet kan hende vi kommer til å bruke flere etterhvert.\nMen for at du skal kunne bruke pakkene må du aktivere dem i R ved library(). Dette må du gjøre hver gang du starter opp R. Det kan se slik ut:\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(randomForest)\nlibrary(caret)\nlibrary(AUC)"
  },
  {
    "objectID": "introduksjon.html#noen-innledende-metodiske-begrep",
    "href": "introduksjon.html#noen-innledende-metodiske-begrep",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.1 Noen innledende metodiske begrep",
    "text": "1.1 Noen innledende metodiske begrep\nI standard samfunnsvitenskapelige metodekurs lærer man først og fremst teknikker for å beskrive data og statistisk inferens for å beskrive usikkerheten rundt estimatene. Avhengig av studiets øvrige design kan resultatene tolkes kausalt og/eller generalisere til en nærmere veldefinert populasjon (Berk 2016).\nUsikkerhet beskrives typisk ved hjelp standardfeil, p-verdier og konfidensintervall tilhørende spesifikke statistiske tester. Dette innebærer at man bruker statistiske modeller for hvordan resultatene ville sett ut under spesifikke forutsetninger. Samplingfordelinger som normalfordelingen og en del andre tilsvarende fordelinger er derfor sentralt. De fleste teknikkene vi skal bruke i dette kurset er ikke statistiske modeller i samme forstand og det er ingen antakelser om samplingfordelinger. Standardfeil og konfidensintervall kan derfor ikke regnes ut. Usikkerhet og hvem resultatene gjelder for er også relevante for maskinlæring, men ikke helt på samme måte."
  },
  {
    "objectID": "introduksjon.html#forklaringer-og-prediksjoner",
    "href": "introduksjon.html#forklaringer-og-prediksjoner",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.2 Forklaringer og prediksjoner",
    "text": "1.2 Forklaringer og prediksjoner\nVi er i liten grad interessert i regresjonskoeffisienter, \\(\\beta\\), og tolkning av denne. Derimot er vi interessert i det predikerte utfallet \\(\\hat{y}_i\\)."
  },
  {
    "objectID": "introduksjon.html#overfitting-training-og-testing-dataset",
    "href": "introduksjon.html#overfitting-training-og-testing-dataset",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.3 Overfitting: training og testing dataset",
    "text": "1.3 Overfitting: training og testing dataset\nNår man tilpasser en statistisk modell eller algoritme til data så er det lett å tenke at modellen bør gjenspeile dataene så godt som mulig. Samtidig sies det ofte at modellene skal være så enkle som tilrådelig. En mer komplisert modell vil jo være i stand til å tilpasses dataene i større grad, så hvordan avveie dette?\nSpørsmålet nå er ikke hvor godt modellen passer til disse dataene, men hvordan den passer til nye data! Altså fremtidige data eller fremtidig situasjon. La oss si at vi har et datasett som kan plottes om følger:\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nn <- 10\nbeta <- 1\nset.seed(42)\nx <- round(20 + runif(n)*50, digits = 1)\ny <- 1 + beta*x + rnorm(n)*10\n\ndf <- data.frame(x = x, y = y) %>% \n  mutate(d = case_when(x < 50 ~ 0,\n                       x < 56 ~ 1, \n                       TRUE ~2) %>% as_factor())\n\n\ng1 <- ggplot(df, aes(x = x, y = y)) +\n  geom_point() \ng1\n\n\n\n\n\nVi kunne her tilpasse en enkel lineær regresjonsmodell eller en mer komplisert modell. Resultatet vises i grafen nedenfor.\n\n\nCode\nest1 <- lm(y ~ x + x*d, data = df)\nest2 <- lm(y ~ x, data = df)\n\ndf_p1 <- df %>% \n  mutate(pred = predict(est1))  %>% \n  mutate(res_pred = y - pred, \n         res_y = y - mean(y))\n\ndf_p1 %>% \n  summarise(res_pred = sum(res_pred^2), \n            res_y = sum(res_y^2)) %>% \n  mutate(1 - res_pred/res_y)\n\n\n  res_pred    res_y 1 - res_pred/res_y\n1 190.8017 4411.586          0.9567499\n\n\nCode\nggplot(df, aes(x = x, y = y)) +\n  geom_point(col = \"black\") +\n  geom_line(data = df_p1, aes(y = pred), col = \"red\", linewidth = .7) +\n  stat_smooth(method='lm', formula = y ~ x, se = F, col = \"blue\", linewidth = .7)\n\n\n\n\n\nDen kompliserte modellen gir \\(r^2\\) = 0.9567499 mens den enkle lineære gir \\(r^2\\) = 0.8066771.\n\n\nCode\nsummary(est1)$r.squared\n\n\n[1] 0.9567499\n\n\nCode\nsummary(est2)$r.squared\n\n\n[1] 0.8066771\n\n\n\n\nCode\nx <- round(20 + runif(n)*50, digits = 1)\ny <- 1 + beta*x + rnorm(n)*10\ndf2 <- data.frame(x = x, y = y)\n  \ng1 +\n  geom_point(data = df2, col = \"blue\") +\n  geom_smooth(method = lm, se = F, col = \"red\")\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "introduksjon.html#klassifikasjonsusikkerhet---grunnleggende-begreper",
    "href": "introduksjon.html#klassifikasjonsusikkerhet---grunnleggende-begreper",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.4 Klassifikasjonsusikkerhet - grunnleggende begreper",
    "text": "1.4 Klassifikasjonsusikkerhet - grunnleggende begreper\nI praksis kommer vi til å fokusere mest på klassifikasjon, som altså er når det vi predikerer er en kategorisk variabel. For nye personer vil vi da gjerne predikere hvilken kategori vedkommende tilhører. En variant av dette er å predikere en fremtidig handling (slutte i jobb, ikke betale tilbake lån, begå ny kriminalitet etc).\n\n1.4.1 Confusion matrix: riktig og feil klassifisering\nNår vi predikerer et kategorisk utfall er det gjerne ett av utfallene vi primært er interessert i. Disse kalles positive og de andre er negative. Dette har ingenting å gjøre med om utfallet er bra eller dårlig å gjøre. Å predikere en sykdom vil være positivt og å være frisk vil være negativt. Å ha tilbakefall til kriminalitet vil være positivt og lovlydig vil være negativt.\nEn positiv prediksjon kan da være korrekt eller feil, og disse kalles da henholdsvis sanne eller falske positive. Tilsvarende kan en negaitv prediksjon være sann eller falsk.\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredikert\n\n\n\n\n\n\n\nNegativ\nPositiv\n\n\nObservert\nNegativ\nSanne negative (TN)\nFalske positive (FN)\n\n\n\nPositiv\nFalske negative (FN)\nSanne positive (TP)\n\n\n\n\n\n1.4.2 Asymetriske kostnader\nÅ predikere feil kan betraktes som en kostnad. Hvis vi skal bruke prediksjonenen til noe i praksis, så skal det jo få konsekvenser på en eller annen måte. Det kan innebære at man setter i verk tiltak som er unødvendige - eller ikke setter i verk tiltak der man burde gjort det.\nEt sentralt spørsmål er derfor om begge typer feil er like viktig eller alvorlig. Noen ganger er det det, men det bør man ta stilling til helt konkret i det enkelte tilfellet. Det er ikke åpenbart hvem som har kompetanse til å vurdere dette. Det kan kreves inngående fagkunnskap for å gjøre en riktig vurdering, eller det kan være politiske prioriteringer, økonomiske forhold, rettferdighetsvurderinger osv. Det er i hvert fall ikke bare opp til forskeren eller IT-personalet å vurdere.\nDette kan koke ned til helt konkret vurdering av hvor mange falske positive er du villig til å godta per falske negative. Et konkret eksempel er studien til Berk et al (2016) av menn som er arrestert for vold i nære relasjoner. Problemstillingen er hvem skal i arrest frem til saken kommer opp og hvem skal løslates mot kausjon. Prediksjonen er da hvem som vil begå ny voldshandling mot partner. Forholdet mellom TN og FN oversettes konkret til hvor mange mistenkte skal sitte unødig i fengsel (dvs. falske positive) mot hvor mange partnere skal unødig utsettes for ny voldshendelse (dvs. falske negative)? I nevnte studie har noen “stakeholders” landet på at falske negative er vesentlig mer alvorlig enn falske positive. Prediksjonsmodellen utformes så for å reflektere akkurat det."
  },
  {
    "objectID": "introduksjon.html#rettferdighet-og-rimelighet",
    "href": "introduksjon.html#rettferdighet-og-rimelighet",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.5 Rettferdighet og rimelighet",
    "text": "1.5 Rettferdighet og rimelighet\nI diskusjoner av anvendelser av maskinlæring står rettferdighet helt sentralt. Men det er ikke alltid like klart hva dette egentlig betyr utover at det er forskjellsbehandling. Tross alt er hele formålet med prediksjon å nettopp forskjellsbehandle, eller målrette som det også kan kalles. Rettferdighet kommer inn på flere nivåer, fra det helt prinsippielle ved å la data og datamaskiner ha betydning for avgjørelser til det helt konkrete til hvordan feilratene bør se ut. Vurdering av asymetriske kostnader er åpenbart også et rettferdighetsspørsmål med etiske implikasjoner. En variant er at disse feilratene kan se forskjellige ut på tvers av undergrupper.\nHvilke konsekvenser som er akseptable er viktig. Men det er også viktig før man bygger modellen. Software kommer med default innstillinger, men det betyr jo ikke at de er “nøytrale”. Resultatene kan til en viss grad styres, så det må man rett og slett gjøre.\n\n1.5.1 Fundamentale skjevheter i data\nSiden maskinlæring baserer seg på å lære av tilgjengelige data for å benytte det på nye tilfeller spiller det vesentlig rolle hvordan de opprinnelige dataene ble generert i utgangspunktet.\nEt velkjent eksempel er hvordan Amazon besluttet å slutte å bruke en algoritme for rekruttering fordi den systematisk valgte bort kvinner. Grunnen til at algoritmen gjorde dette var så enkelt som at dataene den var trent opp på var mannsdominert. Algoritmen hadde altså primært tilgang til informasjon om hvilke egenskaper som kjennetegnet talentfulle mannlige kandidater, som altså kan være forskjellige fra talentfulle kvinnelige kandidater.\nNår man skal ta en algoritme i bruk er det derfor helt avgjørende at man kan forsvare bruken av de dataene algoritmen er trent på. Kjente skjevheter kan i prinsippet motarbeides ved tuning (dette kommer vi tilbake til), men det er vanskelig å garantere at det er skjevheter man ikke har tenkt på."
  },
  {
    "objectID": "introduksjon.html#oppgaver",
    "href": "introduksjon.html#oppgaver",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.6 Oppgaver",
    "text": "1.6 Oppgaver\n\nExercise 1.1 Kan man tenke seg målrettede tiltak som ikke innebærer en form for prediksjon om fremtiden? (Implisitt eller eksplisitt)\n\n\nExercise 1.2 Hvor alvorlig er det å gjøre feil? Hva avgjør om feil prediksjon spiller noen rolle?\n\n\n\n\n\n\n\nBerk, Richard. 2016. Statistical Learning from a Regression Perspective. USA: Springer."
  },
  {
    "objectID": "linear_regresjon.html#lese-inn-data",
    "href": "linear_regresjon.html#lese-inn-data",
    "title": "2  Lineær regresjon",
    "section": "2.1 Lese inn data",
    "text": "2.1 Lese inn data\nVi illustrerer lineær regresjon med et empirisk eksempel. Her skal vi bruke data for norske kommuner i 2016. La oss si at vi er interessert i hvordan antall voldshendelser per 1000 innbyggere vil endre seg i en kommune. Dette kunne være relevant for langtidsplanlegging av forebygging, politibemanning, helsetjenester osv. Det kan være et område som er i stor endring slik at befolkningssammensetningen forventes å endre seg og/eller det er endrede lokale økonomiske utsikter.\nFørst leser vi inn dataene og tar en titt på variabellisten.\n\n\nCode\nkommune <- readRDS( \"data/kommunedata.rds\")\nglimpse(kommune)\n\n\nRows: 1,529\nColumns: 28\n$ kommune_nr             <chr> \"0101\", \"0101\", \"0101\", \"0101\", \"0104\", \"0104\",…\n$ kommune                <chr> \"Halden (-2019)\", \"Halden (-2019)\", \"Halden (-2…\n$ year                   <dbl> 2015, 2016, 2017, 2018, 2015, 2016, 2017, 2018,…\n$ bef_18min              <int> 3556, 3503, 3505, 3544, 3594, 3652, 3704, 3655,…\n$ bef_18_25              <int> 3575, 3585, 3432, 3438, 3405, 3404, 3355, 3370,…\n$ bef_26_35              <int> 3728, 3804, 3985, 4035, 4057, 4071, 4124, 4110,…\n$ bef_totalt             <int> 30328, 30544, 30790, 31037, 31802, 32182, 32407…\n$ menn_18_25             <int> 1847, 1865, 1813, 1819, 1789, 1802, 1789, 1810,…\n$ menn_26_35             <int> 1880, 1919, 2005, 2062, 2063, 2083, 2113, 2134,…\n$ menn_36_67             <int> 7067, 7051, 7085, 7057, 7418, 7453, 7408, 7407,…\n$ menn_67plus            <int> 2496, 2624, 2697, 2806, 2671, 2777, 2856, 2895,…\n$ menn_18min             <int> 1880, 1847, 1873, 1876, 1842, 1885, 1919, 1878,…\n$ kvinner_18_25          <int> 1728, 1720, 1619, 1619, 1616, 1602, 1566, 1560,…\n$ kvinner_26_35          <int> 1848, 1885, 1980, 1973, 1994, 1988, 2011, 1976,…\n$ kvinner_36_67          <int> 6880, 6832, 6844, 6848, 7479, 7519, 7537, 7596,…\n$ kvinner_67plus         <int> 3026, 3145, 3242, 3309, 3178, 3306, 3423, 3555,…\n$ kvinner_18min          <int> 1676, 1656, 1632, 1668, 1752, 1767, 1785, 1777,…\n$ inntekt_totalt_median  <int> 555000, 562000, 580000, 591000, 561000, 568000,…\n$ inntekt_eskatt_median  <int> 451000, 453000, 470000, 480000, 449000, 456000,…\n$ ant_husholdninger      <int> 13890, 14124, 14281, 14454, 15046, 15132, 15313…\n$ shj_klienter           <int> 1183, 1137, 1099, 1128, 1155, 1129, 1152, 1137,…\n$ shj_unge               <int> 262, 247, 248, 242, 267, 263, 238, 222, 307, 28…\n$ vinningskriminalitet   <dbl> 19.7, 18.7, 16.5, 14.5, 24.5, 21.5, 18.0, 18.0,…\n$ voldskriminalitet      <dbl> 11.2, 12.6, 12.3, 11.2, 7.8, 8.3, 8.7, 9.7, 6.8…\n$ nark_alko_kriminalitet <dbl> 21.0, 21.9, 21.0, 20.3, 12.0, 10.2, 10.9, 10.1,…\n$ ordenslovbrudd         <dbl> 18.5, 16.5, 14.9, 13.7, 8.9, 9.0, 9.1, 9.2, 8.2…\n$ trafikklovbrudd        <dbl> 15.5, 16.3, 16.7, 19.2, 7.4, 6.3, 6.9, 8.0, 9.6…\n$ andre_lovbrudd         <dbl> 25.5, 26.5, 26.1, 25.2, 12.1, 12.2, 11.9, 12.4,…\n\n\nEn annen måte å få oversikt over dataene på er å bruke funksjonen skim(), som gir noe mer informasjon om fordelingen av hver enkelt variabel.\n\n\nCode\nskim(kommune)\n\n\n\nData summary\n\n\nName\nkommune\n\n\nNumber of rows\n1529\n\n\nNumber of columns\n28\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n26\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nkommune_nr\n0\n1\n4\n4\n0\n561\n0\n\n\nkommune\n0\n1\n2\n46\n0\n561\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n2017.17\n1.70\n2015.0\n2016.0\n2017.0\n2018.0\n2020.0\n▇▃▃▁▃\n\n\nbef_18min\n0\n1\n2051.72\n5134.84\n82.0\n478.0\n843.0\n1912.0\n71566.0\n▇▁▁▁▁\n\n\nbef_18_25\n0\n1\n2010.07\n5876.07\n90.0\n423.0\n772.0\n1723.0\n80730.0\n▇▁▁▁▁\n\n\nbef_26_35\n0\n1\n2637.60\n10179.34\n80.0\n466.0\n873.0\n2013.0\n156988.0\n▇▁▁▁▁\n\n\nbef_totalt\n0\n1\n17351.92\n48195.14\n934.0\n4062.0\n6952.0\n15656.0\n693494.0\n▇▁▁▁▁\n\n\nmenn_18_25\n0\n1\n1033.97\n2872.20\n45.0\n224.0\n404.0\n904.0\n38847.0\n▇▁▁▁▁\n\n\nmenn_26_35\n0\n1\n1348.18\n5122.76\n44.0\n240.0\n456.0\n1017.0\n78059.0\n▇▁▁▁▁\n\n\nmenn_36_67\n0\n1\n3940.48\n10521.30\n234.0\n939.0\n1630.0\n3650.0\n150390.0\n▇▁▁▁▁\n\n\nmenn_67plus\n0\n1\n1361.18\n3039.57\n56.0\n383.0\n639.0\n1330.0\n42590.0\n▇▁▁▁▁\n\n\nmenn_18min\n0\n1\n1050.44\n2618.78\n44.0\n244.0\n434.0\n974.0\n36298.0\n▇▁▁▁▁\n\n\nkvinner_18_25\n0\n1\n976.11\n3006.75\n38.0\n201.0\n365.0\n813.0\n41945.0\n▇▁▁▁▁\n\n\nkvinner_26_35\n0\n1\n1289.42\n5058.28\n35.0\n224.0\n420.0\n989.0\n78929.0\n▇▁▁▁▁\n\n\nkvinner_36_67\n0\n1\n3770.34\n9932.02\n200.0\n862.0\n1561.0\n3487.0\n140473.0\n▇▁▁▁▁\n\n\nkvinner_67plus\n0\n1\n1580.52\n3696.66\n64.0\n428.0\n729.0\n1488.0\n50757.0\n▇▁▁▁▁\n\n\nkvinner_18min\n0\n1\n1001.28\n2516.27\n38.0\n232.0\n405.0\n933.0\n35268.0\n▇▁▁▁▁\n\n\ninntekt_totalt_median\n0\n1\n654721.39\n75785.29\n463000.0\n601000.0\n646000.0\n697000.0\n898000.0\n▁▇▇▃▁\n\n\ninntekt_eskatt_median\n0\n1\n519417.92\n52786.68\n376000.0\n482000.0\n514000.0\n550000.0\n675000.0\n▁▆▇▃▁\n\n\nant_husholdninger\n0\n1\n7873.76\n23631.34\n426.0\n1831.0\n3137.0\n6896.0\n348864.0\n▇▁▁▁▁\n\n\nshj_klienter\n0\n1\n449.81\n1383.19\n11.0\n98.0\n179.0\n376.0\n20401.0\n▇▁▁▁▁\n\n\nshj_unge\n0\n1\n89.36\n197.02\n0.0\n20.0\n39.0\n89.0\n2488.0\n▇▁▁▁▁\n\n\nvinningskriminalitet\n0\n1\n9.19\n7.05\n1.5\n4.8\n7.2\n11.5\n91.2\n▇▁▁▁▁\n\n\nvoldskriminalitet\n0\n1\n5.61\n2.28\n1.3\n3.9\n5.2\n6.8\n18.8\n▇▇▂▁▁\n\n\nnark_alko_kriminalitet\n0\n1\n6.91\n4.60\n1.1\n3.9\n5.9\n8.9\n55.5\n▇▁▁▁▁\n\n\nordenslovbrudd\n0\n1\n4.91\n3.23\n1.1\n3.0\n4.1\n5.9\n34.9\n▇▁▁▁▁\n\n\ntrafikklovbrudd\n0\n1\n10.49\n11.36\n2.1\n6.0\n8.1\n11.7\n219.7\n▇▁▁▁▁\n\n\nandre_lovbrudd\n0\n1\n9.59\n4.34\n2.3\n7.1\n8.8\n10.8\n52.5\n▇▁▁▁▁\n\n\n\n\n\n\n2.1.1 Training og testing data\nVi starter med å dele datasettet i training og testing. Her kan vi bruke pakken ‘rsample’ og funksjonen initial_split() etterfulgt av funksjonene training() og testing(). Forhåndsvalget for splitten er 0.75, så dermed brukes 75% til training og resten til testing. Du kan også legge til argumentet prop = og sette en annen andel, f.eks. 0.7 for 70%.\nMerk bruken av set.seed(). For å splitte genererer R tilfeldige tall, og seed styrer hvor den algoritmen starter. Når seed er satt vil du få nøyaktig samme resultatet som gjort her. Dette vil du trenge på eksamen for at sensor skal kunne sjekke resultatene dine, så begynn å bruke det med en gang. Tallet inni parentesen betyr ingenting1 og bare sørger for reproduserbarhet der hvor det er tilfeldige tall involvert.\n\n\nCode\nlibrary(rsample)\n\nset.seed(42)\nkommune_split <- initial_split(kommune, prop = .7)\n\nkommune_train <- training(kommune_split)\nkommune_test <- testing(kommune_split)\n\n\n\n\n2.1.2 Enkel lineær regresjon i R\nEn ganske åpenbar faktor som forklarer forekomsten av vold er andel unge menn i kommunen. Rett og slett fordi dette er den demografiske gruppen som begår mest vold - og kriminalitet generelt, faktisk. Hvis befolkningssammensetningen forventes å bli yngre vil det medføre flere unge menn, og da kan vi kanskje forvente at det blir flere voldshendelser bare av den grunn? Sammenhengen mellom unge menn og voldsrate kan estimeres med helt vanlig lineær regresjon.\nEn god start på de fleste empiriske analyser er å beskrive sammenhengen med et plot. Her legger vi på en lineær regresjonslinje med geom_smooth() der vi presiserer lineær modell med method = \"lm\" og lar være å ta med konfidensintervallet se = FALSE.\n\n\nCode\nkommune_train <- kommune_train %>% \n  mutate(prop_unge_menn = (menn_18_25 + menn_26_35)/bef_totalt*100) \n\nggplot(kommune_train, aes(x = prop_unge_menn, \n                     y = voldskriminalitet)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) \n\n\n\n\n\nLineær regresjon estimeres med lm() og du kan få en enkel output med bruk av summary().\n\n\nCode\nest <- lm(voldskriminalitet ~ prop_unge_menn, data = kommune_train)\nsummary(est)\n\n\n\nCall:\nlm(formula = voldskriminalitet ~ prop_unge_menn, data = kommune_train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0302 -1.5764 -0.3951  1.1826 11.3367 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     0.50954    0.63482   0.803    0.422    \nprop_unge_menn  0.41329    0.05097   8.109  1.4e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.248 on 1068 degrees of freedom\nMultiple R-squared:  0.05799,   Adjusted R-squared:  0.05711 \nF-statistic: 65.75 on 1 and 1068 DF,  p-value: 1.395e-15\n\n\nMan kan også hente ut kun \\(r^2\\) med følgende kode:\n\nsummary(est)$r.squared\n\n[1] 0.05799176\n\n\nFor ordens skyld: I tidligere metodekurs har du kanskje lært å få ut en penere regresjonstabell med f.eks. gtsummary-pakken. (Det finnes andre pakker også som gjør tilsvarende). Da vil de samme resultatene se ut som følger. Hvordan output er formatert spiller ingen rolle. I denne sammenhengen har vi lite bruk for en pen regresjonstabell da \\(\\beta\\) ikke er av primær interesse.\n\n\nCode\nlibrary(gtsummary)\n\ntbl_regression(est, intercept = TRUE)\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n0.51\n-0.74, 1.8\n0.4\n    prop_unge_menn\n0.41\n0.31, 0.51\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nMed andre ord kan voldsraten beskrives som:\n\n\n\\[\n\\operatorname{\\widehat{voldskriminalitet}} = 0.51 + 0.41(\\operatorname{prop\\_unge\\_menn})\n\\]\n\n\nMen vi har også sett at \\(r^2\\) er ganske lav, bare 0.058. Denne koeffisienten kalles også “coefficient of determination” og sier noe om i hvor stor grad modellen fanger opp variasjoenen i dataene. En lav \\(r^2\\) betyr at modellen i liten grad gjør det. Vi må altså forvente at modellen vil bomme ganske kraftig i sine prediksjoner. Vi kan velge å ta modellen seriøst likevel, men ikke ha for store forventninger for prediksjonene!\nEt annet mål på hvor godt modellen treffer er “Root mean square error”, RMSE. Dette kan skrives som:\n\\[ rmse = \\sqrt{ \\frac{ \\sum{(O_i-P_i)^2} }{N} }  \\]\nder \\(O\\) er de observerte verdiene og \\(P\\) er de predikerte verdiene for observasjon \\(i\\). Merk at \\((O_i-P_i)\\) er residualene. I R kan vi hente ut residualene fra regresjons-objektet med dollartegnet ...$res etter objektnavnet. Da kan du regne ut RMSE som følger:\n\nrmse <- sqrt(mean(est$res^2))\nrmse\n\n[1] 2.245685\n\n\nRMSE sier altså omtrentlig hvor mye modellen i gjennomsnitt bommer på de observerte verdiene. 2. Hvorvidt det er presist nok eller ikke vil vel strengt tatt komme an på behovet for presisjon, altså: hva man skal bruke det til.\nFor å få litt bedre tak på hva RMSE betyr kan vi se på et plot av de predikerte og observerte verdiene. Vi kan predikere vold for hver enkelt kommune basert på denne modellen, som altså er den forventede voldsraten hvis modellen er sann. Funksjonen predict() gir oss hva vi trenger.\n\nkom <- kommune_train %>% \n  mutate(pred = predict(est))\n\nMerk at koden her lagde en kopi av datasettet der vi har alle de opprinnelige variablene pluss en variabel med de predikerte verdiene. Vi kan nå sammenlignet prediksjonene med de observerte utfallene.\n\n\nCode\nggplot(kom, aes(x = voldskriminalitet, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nHvis prediksjonen hadde vært perfekt ville disse punktene ligget på linja, noe den jo ikke gjør. Modellen bommer altså ganske mye.\nHva hvis vi vil vite forventet voldsrate for en kommune for en gitt andel unge menn? Løsningen er å lage et nytt datasett med de verdiene vi er interessert i og så predikere for dette datasettet med å spesifisere newdata = dt. Her er et eksempel der vi ønsker å vite voldsraten hvis andelen unge menn er 15%.[^](OBS! I en tidligere versjon stod det 0.15 i koden under, men merk at variabelen er på skalaen prosentpoeng og ikke anderl. Hivs du stusset på dette, så var det altså riktig tenkt.)\n\ndt <- data.frame(prop_unge_menn = 15)\np <- predict(est, newdata = dt)\np\n\n       1 \n6.708919 \n\n\nI følge modellen vil altså en kommune der 15% av populasjonen er unge menn ha en 6.709 voldshendelser per 1000 innbyggere. Fra tradisjonell statistikk vet vi jo at det er usikkerhet knyttet til dette estimatet og vi kan også ta det med i beregningen her. Vanligvis vil man estimere med et konfidensintervall, som gjelder hvis man estimerer et gjennomsnitt i en gruppe. Her skal vi derimot predikere for en enkelt kommune, som da har større usikkerhet enn om man estimerer for en enkelt observasjon. Dette kalles prediksjonsintervall og må spesifiseres i koden. Hvis det ikke er gitt vil R gi konfidensintervallet.\n\n\nCode\np_ki <- predict(est, newdata = dt, interval = \"prediction\")\np_ki\n\n\n       fit      lwr      upr\n1 6.708919 2.288514 11.12932\n\n\nTolkningen er ellers tilsvarende som for konfidensintervall: vi forventer med “95% sannsynlighet”3 at voldsraten vil være mellom 2.3 og 11.1 per 1000 innbyggere.\n\n\n2.1.3 Multippel regresjon\nEnkel regresjon er nettopp enkel og prediksjonen blir ikke så god. Men vi kan komplisere vesentlig ved å inkludere flere variable og bruke alle triksene man evt. har lært om multippel regresjon tidligere, primært interaksjonsledd, polynomer og transformasjoner osv. (Det er ok om du ikke har lært alt dette tidligere).\nI R vil vi da bare legge til flere variabelnavn i formelen. Ellers er det meste likt som for enkel lineær regresjon.\n\n\nCode\nest_m <- lm(voldskriminalitet ~ prop_unge_menn + inntekt_totalt_median + shj_unge + \n                   ant_husholdninger , \n            data = kommune_train)\nsummary(est_m)\n\n\n\nCall:\nlm(formula = voldskriminalitet ~ prop_unge_menn + inntekt_totalt_median + \n    shj_unge + ant_husholdninger, data = kommune_train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6862 -1.3599 -0.2042  1.0689 12.4822 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            7.421e+00  7.333e-01  10.121  < 2e-16 ***\nprop_unge_menn         4.177e-01  5.328e-02   7.840 1.09e-14 ***\ninntekt_totalt_median -1.099e-05  8.539e-07 -12.871  < 2e-16 ***\nshj_unge               4.461e-03  1.016e-03   4.392 1.23e-05 ***\nant_husholdninger     -2.163e-05  8.361e-06  -2.587  0.00983 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.037 on 1065 degrees of freedom\nMultiple R-squared:  0.2288,    Adjusted R-squared:  0.2259 \nF-statistic:    79 on 4 and 1065 DF,  p-value: < 2.2e-16\n\n\nMerk at \\(r^2\\) nå har gått betraktelig opp, til ca 0.23. Gitt at vi tolker dette som i hvor stor grad vi kan predikere utfallet fra datasettet, så er det kanskje likevel ikke imponerende høyt: vi vil fremdeles forvente mye feil prediksjon.\nHer er et scatterplot av observert mot forventet voldsrater:\n\n\nCode\nkom_pred <- kommune_train %>% \n  mutate(pred = predict(est_m))\n\nggplot(kom_pred, aes(x = voldskriminalitet, y = pred)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nLa oss inkludere alle aktuelle variable i datasettet. Et lite triks her er å fjerne alle variable vi ikke er interessert i og lagre det i et nytt datasett. I lm() kan vi da presisere formelen som Vold ~ . som i denne sammenhengen betyr å ta med alle variabelene i stedet for å liste opp hver enkelt variabel.\n\n\nCode\nkom_s <- kommune_train %>% \n  select(-c(kommune, kommune_nr, ordenslovbrudd,  \n            nark_alko_kriminalitet, trafikklovbrudd, andre_lovbrudd, \n            prop_unge_menn))\n\nfull_mod <- lm(voldskriminalitet ~ . , data = kom_s)\nsummary(full_mod)\n\n\n\nCall:\nlm(formula = voldskriminalitet ~ ., data = kom_s)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9650 -1.2333 -0.1813  0.8919 12.2114 \n\nCoefficients: (4 not defined because of singularities)\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           -1.198e+02  9.309e+01  -1.287  0.19851    \nyear                   6.234e-02  4.646e-02   1.342  0.17998    \nbef_18min              3.156e-03  1.839e-03   1.716  0.08637 .  \nbef_18_25             -1.885e-05  1.513e-03  -0.012  0.99006    \nbef_26_35              1.180e-03  1.006e-03   1.173  0.24109    \nbef_totalt            -2.272e-03  7.130e-04  -3.187  0.00148 ** \nmenn_18_25             3.698e-03  2.136e-03   1.731  0.08373 .  \nmenn_26_35            -1.481e-03  2.013e-03  -0.736  0.46197    \nmenn_36_67             2.710e-03  9.461e-04   2.865  0.00425 ** \nmenn_67plus            1.654e-03  1.339e-03   1.236  0.21676    \nmenn_18min             2.461e-03  2.875e-03   0.856  0.39223    \nkvinner_18_25                 NA         NA      NA       NA    \nkvinner_26_35                 NA         NA      NA       NA    \nkvinner_36_67         -1.269e-04  9.021e-04  -0.141  0.88816    \nkvinner_67plus                NA         NA      NA       NA    \nkvinner_18min                 NA         NA      NA       NA    \ninntekt_totalt_median -4.693e-05  7.600e-06  -6.176 9.40e-10 ***\ninntekt_eskatt_median  5.580e-05  1.108e-05   5.037 5.55e-07 ***\nant_husholdninger      1.555e-03  3.169e-04   4.908 1.07e-06 ***\nshj_klienter           2.170e-03  9.967e-04   2.177  0.02968 *  \nshj_unge               2.191e-03  3.054e-03   0.718  0.47322    \nvinningskriminalitet   1.066e-01  1.014e-02  10.513  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.891 on 1052 degrees of freedom\nMultiple R-squared:  0.343, Adjusted R-squared:  0.3324 \nF-statistic:  32.3 on 17 and 1052 DF,  p-value: < 2.2e-16\n\n\n\\(r^2\\) gikk noe opp, til 0.343.\nMen vi kan gjøre modellen ekstra komplisert ved inkludere alle mulige interaksjonsledd. En åpenbar ulempe med dette er at hver enkelt koeffisent blir svært mye vanskeligere å tolke. Vi fokuserer derfor kun på \\(r^2\\) som kan hentes ut uten å ta med resten av output.\n\n\nCode\nfull_mod2 <- lm( voldskriminalitet ~ .^2, data = kom_s)\nsummary(full_mod2)$r.squared\n\n\n[1] 0.5224374\n\n\n\\(r^2\\) gikk vesentlig opp. Men når vi først driver med kompliserte modellspesifikasjoner som uansett er vanskelige å tolke - hvorfor begrense seg til 2-veis interaksjoner? Her er en versjon med alle 3-veis interaksjoner, og nå begynner \\(r^2\\) virkelig å bli høy!\n\n\nCode\nfull_mod3 <- lm( voldskriminalitet ~ .^3, data = kom_s)\nsummary(full_mod3)$r.squared\n\n\n[1] 0.8163974\n\n\nVi kan trimme modellen så den ikke har med så voldsomt mange parametre. En mulighet er å overlate dette til datamaskinen ved å la den gjøre en trinnvis test av hvorvidt modellene blir signifikant bedre av å legge til hver av de parametrene, og stopper når modellen ikke blir bedre. Så beholdes den “beste” av disse modellene, ikke nødvendigvis den som er mest komplisert.\nOBS! Merk at dette er en rent mekanisk seleksjon, og frarådes i de fleste samfunnsvitenskapelige sammenhenger. Tolkning av parametre og statistisk usikkerhet er nå på svært tynn is. Men det kan gi god prediksjon likevel.\n\n\nCode\nstep_mod <- MASS::stepAIC(full_mod3, direction=\"forward\", \n                          trace = FALSE)\nsummary(step_mod)$r.squared\n\n\n[1] 0.8163974\n\n\nHvis vi nå predikerer for hver enkelt kommune og plotter forventet mot observert, så får vi et svært mye bedre sammenfall enn tidligere.\n\n\nCode\nkom_pred <- kom_s %>% \n  mutate(pred = predict(step_mod))\n\nggplot(kom_pred, aes(x = voldskriminalitet, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nNå kan vi også regne ut RMSE, som altså er “root mean squared error”. Med andre ord: regn ut residualene (dvs. “error”), og kvadrer denne, og så ta kvadratroten av gjennomsnittet av denne. Her er en kode skrevet litt omstendelig så den er litt lettere å forstå:\n\n\nCode\nkom_s %>% \n  mutate(pred = predict(step_mod), \n         residual = pred - voldskriminalitet) %>% \n  mutate(sq.resid = residual^2) %>% \n  summarise(sqrt(mean(sq.resid)))\n\n\n  sqrt(mean(sq.resid))\n1            0.9914275\n\n\nDette betyr omtrentlig at modellen i gjennomsnitt vil bomme med 1.38 prosentpoeng på voldsraten i kommunen. 4 Hvorvidt det er presist nok eller ikke vil vel strengt tatt komme an på behovet for presisjon, altså: hva man skal bruke det til.\n\n\n2.1.4 Predikere for nye data\nMen nå har vi bare sett på hvordan prediksjonen fungerer på training-datasettet. Vi må sjekke med testing-datasettet. Det lagde vi i begynnelsen, så nå henter vi det frem og gjør det samme som over. I ‘predict()’ må vi nå angi ‘newdata =’.\n\nkom_pred2 <- kommune_test %>% \n  mutate(pred = predict(step_mod, newdata = .), \n         residual = pred - voldskriminalitet)\n\nggplot(kom_pred2, aes(x = voldskriminalitet, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nSer dette rart ut? Det er to observasjoner som har pedikert skyhøy voldsrate! Disse to prediksjonene bommer voldsomt, og med litt erfaring vil man se at dette her går aldri bra for \\(r^2\\), som regnes ut slik:\n\n\nCode\nkom_pred2  %>% \n  mutate(residual_total = voldskriminalitet - mean(voldskriminalitet)) %>% \n  summarise(SSres = sum(residual^2), \n            SStot = sum(residual_total^2)) %>% \n  mutate(r_squared = 1 - (SSres/SStot))\n\n\n       SSres    SStot r_squared\n1 4473767911 2238.179  -1998842\n\n\nGanske riktig! Dette ble bare tull. Kvadratsummen til residualene ble mye høyere enn total kvadratsum. Dermed blir \\(r^2\\) helt fjerne.\nDette er en ganske ekstrem variant av overfitting. Ved å formulere en veldig komplisert modell som passer veldig godt til training-dataene kan vi ende opp med en modell som passer veldig, veldig dårlig til nye data. Hvis man skulle utforme f.eks. politikktiltak på grunnlag av en slik prediksjon vil det kunne gå riktig så dårlig.\nDet er i dette tilfellet kanskje ikke så rart: modellen ble formulert kun for å maksimere \\(r^2\\) og uten så mye andre tanker bak.\nDet er nok bedre med en enklere modell. Vi prøver heller å bruke modellen der alle prediktorene er med, men uten alle de kompliserende interaksjonene:\n\n\nCode\nkom_pred3 <- kommune_test %>% \n  mutate(pred = predict(full_mod, newdata = .), \n         residual = pred - voldskriminalitet)\n\nggplot(kom_pred3, aes(x = voldskriminalitet, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\nCode\nkom_pred3  %>% \n  mutate(residual_total = voldskriminalitet - mean(voldskriminalitet)) %>% \n  summarise(SSres = sum(residual^2), \n            SStot = sum(residual_total^2)) %>% \n  mutate(r_squared = 1 - (SSres/SStot))\n\n\n     SSres    SStot r_squared\n1 1507.998 2238.179 0.3262389\n\n\nSammenlignet med \\(r^2\\) på trainingdata, ‘r summary(full_mod)$r.squared’, er dette ikke så værst. Litt dårligere tilpassning må man regne med.\nRMSE regnes ut slik:\n\n\nCode\nkom_pred3 %>% \n  mutate(sq.resid = residual^2) %>% \n  summarise(sqrt(mean(sq.resid)))\n\n\n  sqrt(mean(sq.resid))\n1             1.812567\n\n\nDet er altså slik at en enklere modell kan passe til nye data langt bedre enn en veldig komplisert modell. Grunnen er overfitting: modellen fanger opp vel så mye tilfeldig støy som det underliggende mønsteret. Støyen vil jo være annerledes i de nye dataene.\n\n\n2.1.5 Oppsummerende kommentar\nDette gjelder generelt: mer komplisert regresjonsmodell vil gi tilsynelatende bedre tilpassning til data enten man måler med \\(r^2\\) eller RMSE. Man kan riktignok bruke mål på tilpassning som justerer for antall parametre etc (f.eks. justert \\(r^2\\), AIC eller BIC), som kanskje kan bedre dette noe, men det vil ofte lede til overfitting likevel.\nDet er derfor veldig viktig å teste modellen mot nye data. I praksis testing-dataene man lagde til å begynne med.\nI resten av kurset skal vi unngå å bruke latterlige kompliserte modeller som ble demonstret ovenfor. Man kan godt bruke interaksjonsledd, polynomer, splines og andre fancy ting. Men med måte."
  },
  {
    "objectID": "linear_regresjon.html#oppgaver",
    "href": "linear_regresjon.html#oppgaver",
    "title": "2  Lineær regresjon",
    "section": "2.2 Oppgaver",
    "text": "2.2 Oppgaver\n\nExercise 2.1 Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer.\n\n\nExercise 2.2 Velg et datasettet og formuler hva en prediksjonsmodell kan kunne brukes til. Se for deg at tiltak du foreslår vil altså ha faktiske konsekvenser, så gjør en vurdering av hvorvidt feilprediksjoner vil være problematiske og i så fall på hvilken måte. Vurder mulighetene for feil opp mot gevinst ved riktig prediksjon.\nMerk: det er ikke viktig at anvendelsen skal være realistisk, men du må alltid ta konsekvensen i vurderingene.\n\n\nExercise 2.3 Last inn valgte datasett og splitt i et training og et testing datasett. Sett splitten ved .70. Bruk training-data til å gjøre deg kjent med dataene og estimere modellene. Ikke bruk testing-dataene inntil du får beskjed om det.\n\n\nExercise 2.4 Gjør deg kjent med innholdet i disse training-dataene. Du kan gjøre f.eks. følgende:\n\nBruk glimpse() og skim() til å få oversikt over innholdet i datasettet\nHvis det er noen variable du ikke kommer til å bruke, slett gjerne disse med en gang\nLag noen tabeller og plot som viser hvordan utfallsvariabelen er fordelt etter andre variable\n\n\n\nExercise 2.5 Estimer flere lineær regresjonsmodeller med et fåtall prediktorer. Gjør et utvalg av de variablene du mener er mest relevant for å forklare utfallet. Estimer flere lineære regresjonsmodeller for å predikere utfallet, og sammenlign hvor gode prediksjoner disse gir. Mest relevante statistikker er \\(r^2\\) og RMSE.\n\nVelg ut tre forklaringsvariable og estimer en regresjonsmodell\nEstimer en ny modell med alle variable i datasettet\nEstimer en ny modell og inkluder noen få polynomer og/eller interaksjonsledd\nGjør et automatisk modellsøk\n\nPlot også predikert verdi mot observert verdi og gjør en vurdering av RMSE.\n\n\nExercise 2.6 I forrige oppgave brukte du testing-datasettet til både å estimere modellene og vurdere resultatet. Nå skal du bruke testing-datasettet til å vurdere de samme resultatene. Dette gjør du ved å predikere på testing-datasettet og regne ut \\(r^2\\) og RMSE for disse dataene. For hver modell i forrige oppgave, gjør som følger:\n\nPrediker utfallet på testing-datasettet\nRegn ut \\(r^2\\) og RMSE\nHvor stor er endringen i \\(r^2\\) og RMSE fra resultatene når du brukte training-datasettet?\n\nVurdering: En mer komplisert modell beskriver dataene bedre. Men er det like stor endring i \\(r^2\\) og RMSE for enkle og mer kompliserte modeller? Beskriv hva du ser og gi en forklaring."
  },
  {
    "objectID": "logistisk_regresjon.html#empirisk-eksempel",
    "href": "logistisk_regresjon.html#empirisk-eksempel",
    "title": "3  Logistisk regresjon",
    "section": "3.1 Empirisk eksempel",
    "text": "3.1 Empirisk eksempel\nSom eksempel bruker vi et datasettet Attrition. Dette er et datasett over arbeidstakere i en bedrift der utfallsvariabelen er om arbeidstakeren slutter i jobben eller ikke.\nFor arbeidsgivere kan det være kostbart med endringer i staben. Arbeidstakere som slutter tar med seg erfaring og kompetanse, og nye arbeidstakere må læres opp. Arbeidsgiver bør derfor generelt legge til rette for at arbeidstakere ønsker å bli værende, men det kan også være aktuelt med mer målrettede tiltak. Når en arbeidstaker har fått et nytt jobbtilbud kan det være for sent. Hvis man derimot kan komme i forkjøpet kan man kanskje gjøre noe før vedkommende går til det skrittet å søke ny jobb. Hvis man kunne predikere hvem som kommer til å slutte kunne man altså gjort tiltak i forkant.1\nFørst leser vi inn datasettet og evt. laster pakker i trenger. Dataene er i csv-format så vi leser inn med readRDS(). Deretter kan vi se på innholdet med skim():\n\n\nCode\nattrition <- readRDS(\"data/attrition.rds\")\nskim(attrition)  \n\n\n\nData summary\n\n\nName\nattrition\n\n\nNumber of rows\n1470\n\n\nNumber of columns\n32\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n8\n\n\nnumeric\n24\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nAttrition\n0\n1\nFALSE\n2\nNo: 1233, Yes: 237\n\n\nBusinessTravel\n0\n1\nFALSE\n3\nTra: 1043, Tra: 277, Non: 150\n\n\nDepartment\n0\n1\nFALSE\n3\nRes: 961, Sal: 446, Hum: 63\n\n\nEducationField\n0\n1\nFALSE\n6\nLif: 606, Med: 464, Mar: 159, Tec: 132\n\n\nGender\n0\n1\nFALSE\n2\nMal: 882, Fem: 588\n\n\nJobRole\n0\n1\nFALSE\n9\nSal: 326, Res: 292, Lab: 259, Man: 145\n\n\nMaritalStatus\n0\n1\nFALSE\n3\nMar: 673, Sin: 470, Div: 327\n\n\nOverTime\n0\n1\nFALSE\n2\nNo: 1054, Yes: 416\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAge\n0\n1\n36.92\n9.14\n18\n30.00\n36.0\n43.00\n60\n▂▇▇▃▂\n\n\nDailyRate\n0\n1\n802.49\n403.51\n102\n465.00\n802.0\n1157.00\n1499\n▇▇▇▇▇\n\n\nDistanceFromHome\n0\n1\n9.19\n8.11\n1\n2.00\n7.0\n14.00\n29\n▇▅▂▂▂\n\n\nEducation\n0\n1\n2.91\n1.02\n1\n2.00\n3.0\n4.00\n5\n▂▃▇▆▁\n\n\nEmployeeNumber\n0\n1\n1024.87\n602.02\n1\n491.25\n1020.5\n1555.75\n2068\n▇▇▇▇▇\n\n\nEnvironmentSatisfaction\n0\n1\n2.72\n1.09\n1\n2.00\n3.0\n4.00\n4\n▅▅▁▇▇\n\n\nHourlyRate\n0\n1\n65.89\n20.33\n30\n48.00\n66.0\n83.75\n100\n▇▇▇▇▇\n\n\nJobInvolvement\n0\n1\n2.73\n0.71\n1\n2.00\n3.0\n3.00\n4\n▁▃▁▇▁\n\n\nJobLevel\n0\n1\n2.06\n1.11\n1\n1.00\n2.0\n3.00\n5\n▇▇▃▂▁\n\n\nJobSatisfaction\n0\n1\n2.73\n1.10\n1\n2.00\n3.0\n4.00\n4\n▅▅▁▇▇\n\n\nMonthlyIncome\n0\n1\n6502.93\n4707.96\n1009\n2911.00\n4919.0\n8379.00\n19999\n▇▅▂▁▂\n\n\nMonthlyRate\n0\n1\n14313.10\n7117.79\n2094\n8047.00\n14235.5\n20461.50\n26999\n▇▇▇▇▇\n\n\nNumCompaniesWorked\n0\n1\n2.69\n2.50\n0\n1.00\n2.0\n4.00\n9\n▇▃▂▂▁\n\n\nPercentSalaryHike\n0\n1\n15.21\n3.66\n11\n12.00\n14.0\n18.00\n25\n▇▅▃▂▁\n\n\nPerformanceRating\n0\n1\n3.15\n0.36\n3\n3.00\n3.0\n3.00\n4\n▇▁▁▁▂\n\n\nRelationshipSatisfaction\n0\n1\n2.71\n1.08\n1\n2.00\n3.0\n4.00\n4\n▅▅▁▇▇\n\n\nStockOptionLevel\n0\n1\n0.79\n0.85\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▂▁\n\n\nTotalWorkingYears\n0\n1\n11.28\n7.78\n0\n6.00\n10.0\n15.00\n40\n▇▇▂▁▁\n\n\nTrainingTimesLastYear\n0\n1\n2.80\n1.29\n0\n2.00\n3.0\n3.00\n6\n▂▇▇▂▃\n\n\nWorkLifeBalance\n0\n1\n2.76\n0.71\n1\n2.00\n3.0\n3.00\n4\n▁▃▁▇▂\n\n\nYearsAtCompany\n0\n1\n7.01\n6.13\n0\n3.00\n5.0\n9.00\n40\n▇▂▁▁▁\n\n\nYearsInCurrentRole\n0\n1\n4.23\n3.62\n0\n2.00\n3.0\n7.00\n18\n▇▃▂▁▁\n\n\nYearsSinceLastPromotion\n0\n1\n2.19\n3.22\n0\n0.00\n1.0\n3.00\n15\n▇▁▁▁▁\n\n\nYearsWithCurrManager\n0\n1\n4.12\n3.57\n0\n2.00\n3.0\n7.00\n17\n▇▂▅▁▁\n\n\n\n\n\nMerk at det er en variabel vi helt sikkert ikke trenger, så vi sletter denne like gjerne med en gang: EmployeeNumber er et løpenummer for person. Siden det er et 1:1 forhold mellom dette og utfallsvariabelen, så bør den tas ut.\nBruker select() med minustegn for variable vi vil fjerne. Her overskrives datasettet med det modifiserte datasettet\n\n\nCode\nattrition <- attrition %>%  \n  select(- EmployeeNumber) \nglimpse(attrition)\n\n\nRows: 1,470\nColumns: 31\n$ Age                      <int> 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35, 2…\n$ Attrition                <fct> Yes, No, Yes, No, No, No, No, No, No, No, No,…\n$ BusinessTravel           <fct> Travel_Rarely, Travel_Frequently, Travel_Rare…\n$ DailyRate                <int> 1102, 279, 1373, 1392, 591, 1005, 1324, 1358,…\n$ Department               <fct> Sales, Research & Development, Research & Dev…\n$ DistanceFromHome         <int> 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26, …\n$ Education                <int> 2, 1, 2, 4, 1, 2, 3, 1, 3, 3, 3, 2, 1, 2, 3, …\n$ EducationField           <fct> Life Sciences, Life Sciences, Other, Life Sci…\n$ EnvironmentSatisfaction  <int> 2, 3, 4, 4, 1, 4, 3, 4, 4, 3, 1, 4, 1, 2, 3, …\n$ Gender                   <fct> Female, Male, Male, Female, Male, Male, Femal…\n$ HourlyRate               <int> 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84, 4…\n$ JobInvolvement           <int> 3, 2, 2, 3, 3, 3, 4, 3, 2, 3, 4, 2, 3, 3, 2, …\n$ JobLevel                 <int> 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, …\n$ JobRole                  <fct> Sales Executive, Research Scientist, Laborato…\n$ JobSatisfaction          <int> 4, 2, 3, 3, 2, 4, 1, 3, 3, 3, 2, 3, 3, 4, 3, …\n$ MaritalStatus            <fct> Single, Married, Single, Married, Married, Si…\n$ MonthlyIncome            <int> 5993, 5130, 2090, 2909, 3468, 3068, 2670, 269…\n$ MonthlyRate              <int> 19479, 24907, 2396, 23159, 16632, 11864, 9964…\n$ NumCompaniesWorked       <int> 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5, …\n$ OverTime                 <fct> Yes, No, Yes, Yes, No, No, Yes, No, No, No, N…\n$ PercentSalaryHike        <int> 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13, 1…\n$ PerformanceRating        <int> 3, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, …\n$ RelationshipSatisfaction <int> 1, 4, 2, 3, 4, 3, 1, 2, 2, 2, 3, 4, 4, 3, 2, …\n$ StockOptionLevel         <int> 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, 0, …\n$ TotalWorkingYears        <int> 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5, 3…\n$ TrainingTimesLastYear    <int> 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, 4, …\n$ WorkLifeBalance          <int> 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, …\n$ YearsAtCompany           <int> 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, 4,…\n$ YearsInCurrentRole       <int> 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, 2, …\n$ YearsSinceLastPromotion  <int> 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0, …\n$ YearsWithCurrManager     <int> 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, 3, …\n\n\nDel datasettet i to deler. Vi trekker tilfeldig 70% og legger dette i datasettet training. Resten legges i testing. De nye datasettene behøver jo ikke hete akkurat dette. Kall det hva du vil.\n\n\nCode\nset.seed(426)\nattrition_split <- initial_split(attrition)\n\ntraining <- training(attrition_split) \ntesting  <- testing(attrition_split) \n\n\nSjekk at antallet i hvert datasett summeres til totalen\n\n\nCode\nnrow(attrition) \n\n\n[1] 1470\n\n\nCode\nnrow(training) \n\n\n[1] 1102\n\n\nCode\nnrow(testing) \n\n\n[1] 368\n\n\nOBS! variabelen Attrition er en “factor”, dvs. kategorisk med underliggende nummer. Ta en titt.\n\n\nCode\nstr(training$Attrition)   \n\n\n Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 1 1 2 1 1 ...\n\n\nCode\nhead(training$Attrition) \n\n\n[1] No  Yes No  Yes No  No \nLevels: No Yes\n\n\nCode\nlevels(training$Attrition) \n\n\n[1] \"No\"  \"Yes\"\n\n\nI en regresjon vil lm() og glm() håndtere en factor automatisk som dummy. Men det funker ikke nødvendigvis like greit for plotting etc. Gjør om factor til dummy-variabel. Inni parentesen er et logisk uttrykk som får TRUE/FALSE, men med å eksplisitt be om at variabelen skal være numerisk blir det 1/0 Vi overskriver variablen slik:\n\n\nCode\ntraining$Attrition <- as.numeric(training$Attrition == \"Yes\") \nhead(training$Attrition) \n\n\n[1] 0 1 0 1 0 0\n\n\nAndelen kan vi få med mean():\n\n\nCode\nmean(training$Attrition) \n\n\n[1] 0.1533575\n\n\nVi kan vise hvordan det å slutte i jobben varierer med f.eks. alder ved å beregne andel per verdi av alder.\n\n\nCode\ntraining_p <- training %>% \n  group_by(Age) %>% \n  summarise(Attrition = mean(Attrition == 1)) \nggplot(training_p, aes(x=Age, y=Attrition))+ \n  geom_point()"
  },
  {
    "objectID": "logistisk_regresjon.html#estimere-en-sannsynlighet",
    "href": "logistisk_regresjon.html#estimere-en-sannsynlighet",
    "title": "3  Logistisk regresjon",
    "section": "3.2 Estimere en sannsynlighet",
    "text": "3.2 Estimere en sannsynlighet\nNår utfallsvariabelen er binær (to verdier) kan man likevel bruke lineær regresjon. Det kalles da gjerne en lineær sannsynlighetsmodell.\n\n\nCode\nlm_est <- lm(Attrition ~ Age , data = training)\nsummary(lm_est)\n\n\n\nCall:\nlm(formula = Attrition ~ Age, data = training)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.28444 -0.18737 -0.14576 -0.06256  0.99292 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.409254   0.044335   9.231  < 2e-16 ***\nAge         -0.006934   0.001166  -5.948 3.65e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.355 on 1100 degrees of freedom\nMultiple R-squared:  0.03116,   Adjusted R-squared:  0.03027 \nF-statistic: 35.37 on 1 and 1100 DF,  p-value: 3.652e-09\n\n\nDette betyr at vi har estimert følgende regresjonsligning:\n\n\n\\[\n\\operatorname{\\widehat{Attrition}} = 0.409 - 0.007(\\operatorname{Age})\n\\]\n\n\nVi kan da predikere for ulike aldre ved å første lage et nytt datasett med kun alder som variabel og de verdiene som finnes i datasettet, og så bruke ‘predict()’ på dette datasettet etterpå. Da kan vi også se resultatet for ulike aldre. Her er et eksempel:\n\n\nCode\nn_data <- data.frame(Age = seq(18, 65))\nn_data$pred <- predict(lm_est, newdata = n_data)\n\n\nggplot(training_p, aes(x=Age, y=Attrition))+ \n  geom_point()+ \n  geom_line(data =n_data, aes(x = Age, y = pred))\n\n\n\n\n\nMerk at det her er vist predikerte sannsynligheter litt utenfor omfanget av de opprinnelige dataene, dvs. opp til 65 år i stedet for bare til 60. Da får vi en negativ sannsynlighet. Dette er kanskje ikke så problematisk hvis man er nøye på å ikke tolke resultatene utenfor training-data. Men det kan jo hente nye data vil ha slike verdier. Det blir mer komplisert hvis det er mange prediktorer og kompliserte modeller. En ting er om de predikerte sannsynlighetene blir lavere enn 0 eller høyere enn 1, men vi vil uansett forvente at stigningstallet vil avta når det nærmer seg disse grenseverdiene.\nDen viktigste ulempen med lineære sannsynlighetsmodeller er altså at modellen da kan predikere sannsynligheter lavere enn 0 og høyere enn 1. Når man er mest interessert i \\(\\beta\\) er det ikke sikkert det er så nøye. Men når vi er interessert i \\(\\hat{y}\\) kan det derimot være viktig."
  },
  {
    "objectID": "logistisk_regresjon.html#logistisk-regresjon-i-r",
    "href": "logistisk_regresjon.html#logistisk-regresjon-i-r",
    "title": "3  Logistisk regresjon",
    "section": "3.3 Logistisk regresjon i R",
    "text": "3.3 Logistisk regresjon i R\nLogistisk regresjon har det til felles med lineær regresjon at utfallet er en lineær spesifikasjon.\n\\[  log( \\frac{\\pi}{(1-\\pi)}) = \\alpha + \\beta X \\]\nVenstresiden av ligningen kalles en logit, der \\(\\pi\\) er en sannsynlighet. Uttrykket \\(\\frac{\\pi}{(1-\\pi)}\\) er en odds, som er et forholdstall mellom sannsynligheten for at utfallet skjer mot sannsynligheten for det motsatte. Tolkningen av \\(\\beta\\) er da en endring av odds på logaritisk skala. Hvis man eksponensierer \\(\\beta\\) er den da tolkbar som en oddsrate.\nSom du nå sikkert skjønner så er altså tolkningen av regresjonskoeffisientene nokså krøkete å tolke substansielt for de fleste av oss. Det kan i seg selv være et argument mot å bruke logistisk regresjon i en del sammenhenger.\nMen man kan regne om til sannsynligheter som er vesentlig enklere å forstå. Særlig hvis man ikke er så interessert i tolkningen av \\(\\beta\\), men prediksjon av \\(\\pi\\).\nLigningen kan da skrives om slik at venstresiden av ligningen blir en sannsynlighet direkte:\n\\[  \\pi = \\frac{e^{\\alpha + \\beta X}}{1 + e^{\\alpha + \\beta X}} \\]\nEn enkel omregning av regresjonsresultatet gir altså en sannynlighet. Denne sannsynligheten kan vi da bruke til klassifikasjon hvis det er formålet med analysen. Hvis utfallsvariabelen har to kategorier, så er en nærliggende mulighet å klassifisere til den gruppen hver person mest sannsynlig tilhører. Altså: de som har \\(\\pi = P(y = 1) > 0.5\\) tilhører den ene gruppen og resten i den andre gruppen.\nLogistisk regresjon kan dessuten håndtere utfall med flere enn to kategorier, noe OLS ikke kan. Vi bruker derfor logistisk regresjon når det er kategoriske utfall. I andre sammenhenger vil folk hevde at OLS er bedre å bruke (av diverse grunner), men i denne sammenhengen er logistisk regresjon som hovedregel å foretrekke over OLS for kategoriske utfall.\nHer er et eksempel på hvordan estimere enkel logistisk regresjon i R:\n\n\nCode\nest_logit <- glm(Attrition ~ Age, data = training, family = \"binomial\")\nsummary(est_logit)\n\n\n\nCall:\nglm(formula = Attrition ~ Age, family = \"binomial\", data = training)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9093  -0.6310  -0.5343  -0.3790   2.4998  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.41516    0.36402   1.140    0.254    \nAge         -0.06026    0.01050  -5.741 9.43e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 944.39  on 1101  degrees of freedom\nResidual deviance: 907.48  on 1100  degrees of freedom\nAIC: 911.48\n\nNumber of Fisher Scoring iterations: 5\n\n\nEn penere output kan gis med ‘gtsummary’ på samme måte som for OLS slik:\n\n\nCode\ntbl_regression(est_logit)\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      log(OR)1\n      95% CI1\n      p-value\n    \n  \n  \n    Age\n-0.06\n-0.08, -0.04\n<0.001\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\n\n\\[\n\\log\\left[ \\frac { \\widehat{P( \\operatorname{Attrition} = \\operatorname{1} )} }{ 1 - \\widehat{P( \\operatorname{Attrition} = \\operatorname{1} )} } \\right] = 0.415 - 0.06(\\operatorname{Age})\n\\]\n\n\nHvordan plotte slike data? Bruk geom_jitter eller geom_point. Å legge til en regresjonslinje har brukte vi geom_smooth(). Med stat_smoot() kan vi spesifisere andre typer regresjonsmodeller, herunder logistisk regresjon.\n\n\nCode\nggplot(training, aes(x=Age, y=Attrition))+ \n  geom_point(alpha=.3)+ \n  stat_smooth(method=\"glm\", method.args=list(family=\"binomial\"), se=FALSE, col=\"red\") \n\n\n\n\n\nDu synes sikkert dette plottet ser litt rart ut. Bytt ut geom_point() med følgende: geom_jitter(height = .02, alpha=.3) så skal du få omtrent følgende resultat:\n\n\nCode\nggplot(training, aes(x=Age, y=Attrition))+ \n  geom_jitter(height = .02, alpha=.3)+ \n  stat_smooth(method=\"glm\", method.args=list(family=\"binomial\"), se=FALSE, col=\"red\") \n\n\n\n\n\nDet ser muligens fremdels rart ut, men litt tydeligere, kanskje.\nHer er en variant der andelen som slutter i jobben er regnet ut for hvert alderstrinn. Da er utfallsvariabelen en andel som er litt enklere å tolke når det plottes, og regresjonslinjen er den samme.\n\n\nCode\ntraining_p <- training %>% \n  group_by(Age) %>% \n  summarise(Attrition = mean(Attrition == 1)) \nggplot(training_p, aes(x=Age, y=Attrition))+ \n  geom_point()+ \n  stat_smooth(method=\"glm\", method.args=list(family=\"binomial\"), se=FALSE, col=\"red\")"
  },
  {
    "objectID": "logistisk_regresjon.html#prediksjon",
    "href": "logistisk_regresjon.html#prediksjon",
    "title": "3  Logistisk regresjon",
    "section": "3.4 Prediksjon",
    "text": "3.4 Prediksjon\nVi kan predikere med bruk av ‘predict()’ som tidligere. Nå er det imidlertid viktig å presisere hva vi ønsker å predikere: \\(log( \\frac{\\pi}{(1-\\pi)})\\) eller \\(\\pi\\). Vi ønsker det siste fordi det er direkte tolkbart. Vi må da skrive ‘type = “response”’ som følger.\n\n\nCode\nattrition_pred <- training %>% \n  mutate(prob = predict(est_logit, type = \"response\"))\n\n\n\n3.4.1 ROC og AUC\n\n\nCode\nROC <- roc( attrition_pred$Attrition, attrition_pred$prob )\n\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\nCode\ndf <- data.frame(Sensitivity = ROC$sensitivities, \n                 Specificity = ROC$specificities)\n\nggplot(df, aes(y = Sensitivity, x= (1-Specificity))) + \n  geom_line() + \n  geom_abline(intercept = 0, slope = 1, col = \"gray\")+\n  coord_equal()\n\n\n\n\n\nArea under the curve er 0.65."
  },
  {
    "objectID": "logistisk_regresjon.html#multippel-logistisk-regresjon",
    "href": "logistisk_regresjon.html#multippel-logistisk-regresjon",
    "title": "3  Logistisk regresjon",
    "section": "3.5 Multippel logistisk regresjon",
    "text": "3.5 Multippel logistisk regresjon\nVi kan estimere en multippel regresjon på tilsvarende måte som for lineær regresjon ved å legge til flere variable eller angi å bruke samtlige variable i datasettet med ‘Attrition ~ .’\n\n\nCode\nest_multlogit <- glm(Attrition ~ ., data = training, family = \"binomial\")\nsummary(est_multlogit)\n\n\n\nCall:\nglm(formula = Attrition ~ ., family = \"binomial\", data = training)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6864  -0.4792  -0.2391  -0.0884   3.2219  \n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                      -1.035e+01  4.542e+02  -0.023 0.981824    \nAge                              -3.565e-02  1.628e-02  -2.190 0.028495 *  \nBusinessTravelTravel_Frequently   1.628e+00  4.675e-01   3.482 0.000498 ***\nBusinessTravelTravel_Rarely       8.988e-01  4.267e-01   2.106 0.035192 *  \nDailyRate                        -3.117e-04  2.648e-04  -1.177 0.239034    \nDepartmentResearch & Development  1.203e+01  4.542e+02   0.026 0.978861    \nDepartmentSales                   1.239e+01  4.542e+02   0.027 0.978244    \nDistanceFromHome                  4.145e-02  1.300e-02   3.189 0.001428 ** \nEducation                        -1.376e-02  1.039e-01  -0.132 0.894627    \nEducationFieldLife Sciences      -8.013e-01  1.027e+00  -0.781 0.435083    \nEducationFieldMarketing          -2.129e-01  1.076e+00  -0.198 0.843199    \nEducationFieldMedical            -8.617e-01  1.028e+00  -0.838 0.401983    \nEducationFieldOther              -7.977e-01  1.098e+00  -0.727 0.467345    \nEducationFieldTechnical Degree    1.370e-01  1.048e+00   0.131 0.896014    \nEnvironmentSatisfaction          -4.957e-01  9.942e-02  -4.986 6.18e-07 ***\nGenderMale                        2.156e-01  2.149e-01   1.003 0.315665    \nHourlyRate                       -3.532e-03  5.385e-03  -0.656 0.511937    \nJobInvolvement                   -5.422e-01  1.452e-01  -3.734 0.000189 ***\nJobLevel                          1.864e-02  3.817e-01   0.049 0.961047    \nJobRoleHuman Resources            1.308e+01  4.542e+02   0.029 0.977028    \nJobRoleLaboratory Technician      1.531e+00  5.543e-01   2.762 0.005746 ** \nJobRoleManager                   -1.451e+00  1.269e+00  -1.144 0.252636    \nJobRoleManufacturing Director    -3.131e-01  6.086e-01  -0.514 0.606923    \nJobRoleResearch Director         -2.440e+00  1.244e+00  -1.961 0.049843 *  \nJobRoleResearch Scientist         3.417e-01  5.694e-01   0.600 0.548406    \nJobRoleSales Executive            3.595e-01  1.603e+00   0.224 0.822589    \nJobRoleSales Representative       1.518e+00  1.650e+00   0.920 0.357555    \nJobSatisfaction                  -3.169e-01  9.701e-02  -3.267 0.001087 ** \nMaritalStatusMarried              3.453e-01  3.135e-01   1.101 0.270697    \nMaritalStatusSingle               8.690e-01  4.056e-01   2.143 0.032140 *  \nMonthlyIncome                     8.613e-05  9.875e-05   0.872 0.383105    \nMonthlyRate                       8.922e-06  1.482e-05   0.602 0.547277    \nNumCompaniesWorked                1.721e-01  4.623e-02   3.722 0.000198 ***\nOverTimeYes                       1.877e+00  2.296e-01   8.174 2.98e-16 ***\nPercentSalaryHike                -6.102e-02  4.687e-02  -1.302 0.192953    \nPerformanceRating                 6.920e-01  4.794e-01   1.443 0.148883    \nRelationshipSatisfaction         -3.738e-01  9.827e-02  -3.804 0.000142 ***\nStockOptionLevel                 -3.059e-01  1.810e-01  -1.690 0.091064 .  \nTotalWorkingYears                -6.605e-02  3.580e-02  -1.845 0.065052 .  \nTrainingTimesLastYear            -2.129e-01  8.533e-02  -2.495 0.012582 *  \nWorkLifeBalance                  -2.150e-01  1.456e-01  -1.476 0.139869    \nYearsAtCompany                    6.067e-02  4.877e-02   1.244 0.213537    \nYearsInCurrentRole               -9.948e-02  5.569e-02  -1.786 0.074038 .  \nYearsSinceLastPromotion           2.052e-01  5.182e-02   3.960 7.50e-05 ***\nYearsWithCurrManager             -1.866e-01  6.072e-02  -3.073 0.002122 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 944.39  on 1101  degrees of freedom\nResidual deviance: 619.99  on 1057  degrees of freedom\nAIC: 709.99\n\nNumber of Fisher Scoring iterations: 14\n\n\n\n3.5.1 ROC og AUC\nFor å beregne ROC og AUC gjør vi tilsvarende som over med predict og angi type respons. Dette brukes så videre i ROC og AUC.\n\n\nCode\nattrition_pred <- training %>% \n  mutate(prob = predict(est_multlogit, type = \"response\")) \n\n\nFunksjonen roc() gjør utregningene som trengs for ROC-kurven basert på observert utfall og predikerte sannsynligheter (Hsieh 2008).\nOBS! Man må man angi data som første argument i funksjonen roc(), deretter observerte utfall og til sist predikert sannsynlighet. Rekkefølgen er viktig!\nDet går an å få ut plottet med en quick-and-dirty versjon med plot(ROC), men det blir penere med bruk av ggplot() slik som er gjort nedenfor. Det krever at man lager en data.frame først ved å plukke ut de relevante tallene fra ROC-objektet. (Men layout er strengt tatt ikke viktig i dette kurset).\n\n\nCode\nROC <- roc(attrition_pred, Attrition, prob)\n\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\nCode\ndf <- data.frame(Sensitivity = ROC$sensitivities, \n                 Specificity = ROC$specificities)\n\nggplot(df, aes(y = Sensitivity, x= (1-Specificity))) + \n  geom_line() + \n  geom_abline(intercept = 0, slope = 1, col = \"gray\")+\n  coord_equal()\n\n\n\n\n\nVi kan da få rapportert arealet under kurven med auc() slik:\n\n\nCode\nauc(ROC)\n\n\nArea under the curve: 0.8675\n\n\nNår arealet under kurven (AUC) er 0.867 er det vesentlig bedre prediksjon enn den enkle modellen."
  },
  {
    "objectID": "logistisk_regresjon.html#testing-data",
    "href": "logistisk_regresjon.html#testing-data",
    "title": "3  Logistisk regresjon",
    "section": "3.6 Testing-data",
    "text": "3.6 Testing-data\nOvenfor er øvelsen gjort på training-data, men vi må sjekke på testing-dataene.\nFor å beregne ROC og AUC gjør vi tilsvarende som over med predict, men nå er det viktig å angi ‘newdata = …’ slik at prediksjonen gjøres på riktig datasett.\n\n\nCode\nattrition_test <- testing %>% \n  mutate(prob = predict(est_multlogit, newdata = testing, type = \"response\")) \n\n\nFunksjonen roc() gjør utregningene som trengs for ROC-kurven basert på observert utfall og predikerte sannsynligheter (Hsieh 2008).\nOBS! Man må man angi data som første argument i funksjonen roc(), deretter observerte utfall og til sist predikert sannsynlighet. Rekkefølgen er viktig!\nDet går an å få ut plottet med en quick-and-dirty versjon med plot(ROC), men det blir penere med bruk av ggplot() slik som er gjort nedenfor. Det krever at man lager en data.frame først ved å plukke ut de relevante tallene fra ROC-objektet. (Men layout er strengt tatt ikke viktig i dette kurset).\n\n\nCode\nROC_test <- roc(attrition_test, Attrition, prob)\n\n\nSetting levels: control = No, case = Yes\n\n\nSetting direction: controls < cases\n\n\nCode\ndf <- data.frame(Sensitivity = ROC_test$sensitivities, \n                 Specificity = ROC_test$specificities)\n\nggplot(df, aes(y = Sensitivity, x= (1-Specificity))) + \n  geom_line() + \n  geom_abline(intercept = 0, slope = 1, col = \"gray\")+\n  coord_equal()\n\n\n\n\n\nVi kan da få rapportert arealet under kurven med auc() slik:\n\n\nCode\nauc(ROC_test)\n\n\nArea under the curve: 0.8397\n\n\nNår arealet under kurven (AUC) er 0.84. Kanskje litt overraskende, men dette like godt som for på training dataene. Dette altså selv om det er tydelige forskjeller på ROC-curvene som er plottet. AUC er altså arealet under kurven. Litt ulik form kan i prinsippet ha samme areal."
  },
  {
    "objectID": "logistisk_regresjon.html#klassifikasjon",
    "href": "logistisk_regresjon.html#klassifikasjon",
    "title": "3  Logistisk regresjon",
    "section": "3.7 Klassifikasjon",
    "text": "3.7 Klassifikasjon\nMen for et handlingsvalg må vi gjøre faktisk klassifisering. Det vi har estimert så langt er bare en sannsynlighet. Selve klassifiseringen krever at man tar et aktivt valg på en cut-off for hvem man tror faktisk slutter. La oss først se på fordelingen av sannsynligheter.\n\n\nCode\nggplot(attrition_test, aes(x = prob)) +\n  geom_histogram()\n\n\n\n\n\nVi kan bestemme oss for at et rimelig cut-off er 50/50, altså med sannsynlighet 0.5. Her gjøres en klassifisering for testing-datasettet, og lager en krysstabell med den klassifiserte etter prediksjon mot observert utfall. En slik krysstabell kalles altså en confusion matrix.\n\n\nCode\nattrition_test <- attrition_test %>% \n  mutate(attrition_class = as.factor(ifelse(prob < .5, \"No\", \"Yes\")))\n\nattrition_test %>% \n  select(Attrition, attrition_class) %>% \n  table()\n\n\n         attrition_class\nAttrition  No Yes\n      No  287  13\n      Yes  45  23\n\n\nHvis du nå lurer på om det spiller noen rolle om du har observert eller predikert i rader/kollonner, så gjør det ikke det. Det er bare to variable krysset mot hverandre. I dette tilfellet er det altså 30 personer som er gjettet riktig at vil slutte, men bare halvparten av de som faktisk sluttet ble fanget opp (27 av 30). Det var 12 som ble feilaktig gjettet at ville slutte, men som altså ikke gjorde det.\n\n3.7.1 Confusion matrix\nFra pakken ‘caret’ er det en funksjon for confusion matrix som regner ut masse greier for oss. (Vi skal bare bruke akkurat den funksjonen fra ‘caret’).\n\n\nCode\nconfusionMatrix(attrition_test$Attrition, attrition_test$attrition_class, positive = \"Yes\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  287  13\n       Yes  45  23\n                                          \n               Accuracy : 0.8424          \n                 95% CI : (0.8011, 0.8781)\n    No Information Rate : 0.9022          \n    P-Value [Acc > NIR] : 0.9999          \n                                          \n                  Kappa : 0.3605          \n                                          \n Mcnemar's Test P-Value : 4.691e-05       \n                                          \n            Sensitivity : 0.63889         \n            Specificity : 0.86446         \n         Pos Pred Value : 0.33824         \n         Neg Pred Value : 0.95667         \n             Prevalence : 0.09783         \n         Detection Rate : 0.06250         \n   Detection Prevalence : 0.18478         \n      Balanced Accuracy : 0.75167         \n                                          \n       'Positive' Class : Yes"
  },
  {
    "objectID": "logistisk_regresjon.html#hvor-feil-kan-man-ta",
    "href": "logistisk_regresjon.html#hvor-feil-kan-man-ta",
    "title": "3  Logistisk regresjon",
    "section": "3.8 Hvor feil kan man ta?",
    "text": "3.8 Hvor feil kan man ta?\nI klassifiseringen over er det gjort et klart valg for hvem man tror faktisk vil slutte i jobben eller ikke. Det er selvsagt slik at noen er mer sannsynlige vil slutte enn andre, men ingen har 0 sannsynlighet. Ingen har 1 heller, for den saks skyld. Det er altså usikkerhet. Men hvis vi skal gjøre et tiltak, så må vi ta det valget!\nHvis vi gjør klassifiseringen på 0.5 som over, så betyr jo det at vi synes begge feil er like viktige: Falske positive eller falske negative. Hvis det er et langt større problem at folk slutter enn at noen f.eks. får tilbud om goder eller ekstra oppfølging etc, så kan det hende cut-off skal settes lavere? Da får man flere sanne positive, men også flere feil. Det kan det jo være verd, men kommer jo an på hva konsekvensene. Vi kommer tilbake til dette, men test gjerne ut selv med ulik cut-off og se hvordan resultatene endrer seg."
  },
  {
    "objectID": "logistisk_regresjon.html#oppgaver",
    "href": "logistisk_regresjon.html#oppgaver",
    "title": "3  Logistisk regresjon",
    "section": "3.9 Oppgaver",
    "text": "3.9 Oppgaver\nDisse oppgavene vil være ganske tilsvarende som for oppgavene med lineær regresjon. Men du skal nå bruke logistisk regresjon med tilhørende teknikker og vurderinger.\n\nExercise 3.1 Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer.\n\n\nExercise 3.2 Velg et datasettet og formuler hva en prediksjonsmodell kan kunne brukes til. Se for deg at tiltak du foreslår vil altså ha faktiske konsekvenser, så gjør en vurdering av hvorvidt feilprediksjoner vil være problematiske og i så fall på hvilken måte. Vurder mulighetene for feil opp mot gevinst ved riktig prediksjon.\nMerk: det er ikke viktig at anvendelsen skal være realistisk, men du må alltid ta konsekvensen i vurderingene.\n\n\nExercise 3.3 Last inn valgte datasett og splitt i et training og et testing datasett. Sett splitten ved .70. Bruk training-data til å gjøre deg kjent med dataene og estimere modellene. Ikke bruk testing-dataene inntil du får beskjed om det.\n\n\nExercise 3.4 Gjør deg kjent med innholdet i disse training-dataene. Du kan gjøre f.eks. følgende:\n\nBruk glimpse() og skim() til å få oversikt over innholdet i datasettet\nHvis det er noen variable du ikke kommer til å bruke, slett gjerne disse med en gang\nLag noen tabeller og plot som viser hvordan utfallsvariabelen er fordelt etter andre variable\n\n\n\nExercise 3.5 Estimer flere logistiske regresjonsmodeller med et fåtall prediktorer. Gjør et utvalg av de variablene du mener er mest relevant for å forklare utfallet. Estimer flere regresjonsmodeller for å predikere utfallet, og sammenlign hvor gode prediksjoner disse gir. Mest relevante statistikk er AUC og ROC-curve.\n\nVelg ut tre forklaringsvariable og estimer en regresjonsmodell\nEstimer en ny modell med alle variable i datasettet\nEstimer en ny modell og inkluder noen få polynomer og/eller interaksjonsledd\nGjør et automatisk modellsøk\n\nLag gjerne noen plot av ROC-curve for i hvert fall noen av modellene slik at du får en følelse med hva AUC egentlig betyr. Plot også predikert verdi mot observert verdi og gjør en vurdering av RMSE.\n\n\nExercise 3.6 I forrige oppgave brukte du training-datasettet til både å estimere modellene og vurdere resultatet. Nå skal du bruke testing-datasettet til å vurdere de samme resultatene. Dette gjør du ved å predikere på testing-datasettet og regne ut AUC for disse dataene. For hver modell i forrige oppgave, gjør som følger:\n\nPrediker utfallet på testing-datasettet\nRegn ut AUC\nHvor stor er endringen i AUC er fra resultatene når du brukte training-datasettet?\n\nVurdering: En mer komplisert modell beskriver dataene bedre. Men er det like stor endring i AUC og RMSE for enkle og mer kompliserte modeller? Beskriv hva du ser og gi en forklaring.\n\n\nExercise 3.7 Når over har predikert en sannsynlighet og regnet ut AUC har du ennå ikke tatt noen avgjørelse. Bestem deg for et grenseverdi for når du vil klassifisere som det ene eller andre. (Alså: ved hvilken sannsynlighet). Gjør så en klassifikasjon og lag en confusion matrix. Gi en vurdering av resultatet.\n\n\n\n\n\n\n\nHsieh, John. 2008. “Receiver Operating Characteristic (ROC) Curve.” In Encyclopedia of Epidemiology, 895–98. Thousand Oaks, California: Sage. https://doi.org/10.4135/9781412953948."
  },
  {
    "objectID": "intro_fairness.html#hva-slags-rettferdighet",
    "href": "intro_fairness.html#hva-slags-rettferdighet",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.1 Hva slags rettferdighet",
    "text": "4.1 Hva slags rettferdighet\nI denne settingen kan rettferdighet kommer i betraktning på flere måter, herunder følgende:\n\nI hvilken grad maskiner vs mennesker tar avgjørelser, og herunder mulighet til å bli hørt og legge frem sin sak\nI hvilken grad dataene algoritmen er trent opp på inneholder skjevheter i utgangspunktet som så reproduseres i videre implementering\nI hvilken grad sluttresultatet har rimelig presisjon og akseptable feilrater, herunder vurdering av asymetriske feilrater\nI hvilken grad forrige punkt er avpasset mot hvilke tiltak man så setter i verk\nI hvilken grad feilrater og presisjon varierer systematisk med undergrupper i populasjonen\n\nDet er nok av ting å tak i her, men vi skal her fokusere på det som kan tallfestes gitt den modellen man har. Men for all del: Hvis datakvaliteten er det begrenset hvor bra det kan bli uansett. Selv om kjente skjevheter i dataene kan i prinsippet motarbeides, så er det vel i praksis slik at en skjevhet kommer sjelden alene?\nVurderinger av overordnet feilrater er et gjennomgående tema, så vi starter med det. Deretter skal vi se på mål på skjevheter over undergrupper. Prinsippet er relativt enkelt, uten at vurderingene blir enkle av den grunn."
  },
  {
    "objectID": "intro_fairness.html#mer-confusion-matrix",
    "href": "intro_fairness.html#mer-confusion-matrix",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.2 Mer confusion matrix",
    "text": "4.2 Mer confusion matrix\n\n\nCode\nest_multlogit <- glm(Attrition ~ ., data = training, family = \"binomial\")\nsummary(est_multlogit)\n\n\n\nCall:\nglm(formula = Attrition ~ ., family = \"binomial\", data = training)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6886  -0.4840  -0.2374  -0.0862   3.3170  \n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                      -1.090e+01  7.450e+02  -0.015 0.988322    \nAge                              -3.671e-02  1.637e-02  -2.243 0.024906 *  \nBusinessTravelTravel_Frequently   1.627e+00  4.663e-01   3.490 0.000483 ***\nBusinessTravelTravel_Rarely       8.847e-01  4.265e-01   2.074 0.038070 *  \nDailyRate                        -3.249e-04  2.657e-04  -1.223 0.221450    \nDepartmentResearch & Development  1.303e+01  7.450e+02   0.017 0.986048    \nDepartmentSales                   1.348e+01  7.450e+02   0.018 0.985565    \nDistanceFromHome                  4.325e-02  1.308e-02   3.307 0.000944 ***\nEducation                         2.259e-03  1.047e-01   0.022 0.982789    \nEducationFieldLife Sciences      -8.614e-01  1.036e+00  -0.832 0.405637    \nEducationFieldMarketing          -2.986e-01  1.085e+00  -0.275 0.783245    \nEducationFieldMedical            -9.341e-01  1.037e+00  -0.901 0.367673    \nEducationFieldOther              -8.090e-01  1.106e+00  -0.731 0.464508    \nEducationFieldTechnical Degree    6.014e-02  1.057e+00   0.057 0.954635    \nEmployeeNumber                   -3.297e-04  1.818e-04  -1.814 0.069727 .  \nEnvironmentSatisfaction          -4.976e-01  9.990e-02  -4.981 6.31e-07 ***\nGenderMale                        2.224e-01  2.157e-01   1.031 0.302405    \nHourlyRate                       -3.877e-03  5.392e-03  -0.719 0.472136    \nJobInvolvement                   -5.454e-01  1.458e-01  -3.741 0.000183 ***\nJobLevel                         -1.437e-02  3.834e-01  -0.037 0.970101    \nJobRoleHuman Resources            1.413e+01  7.450e+02   0.019 0.984868    \nJobRoleLaboratory Technician      1.579e+00  5.597e-01   2.822 0.004773 ** \nJobRoleManager                   -1.613e+00  1.280e+00  -1.260 0.207596    \nJobRoleManufacturing Director    -2.403e-01  6.135e-01  -0.392 0.695291    \nJobRoleResearch Director         -2.531e+00  1.243e+00  -2.035 0.041806 *  \nJobRoleResearch Scientist         3.845e-01  5.748e-01   0.669 0.503513    \nJobRoleSales Executive            3.167e-01  1.614e+00   0.196 0.844462    \nJobRoleSales Representative       1.478e+00  1.662e+00   0.890 0.373555    \nJobSatisfaction                  -3.238e-01  9.696e-02  -3.340 0.000839 ***\nMaritalStatusMarried              3.633e-01  3.130e-01   1.161 0.245800    \nMaritalStatusSingle               9.102e-01  4.057e-01   2.243 0.024875 *  \nMonthlyIncome                     9.730e-05  9.890e-05   0.984 0.325190    \nMonthlyRate                       1.173e-05  1.499e-05   0.783 0.433906    \nNumCompaniesWorked                1.705e-01  4.652e-02   3.665 0.000248 ***\nOverTimeYes                       1.892e+00  2.308e-01   8.195 2.50e-16 ***\nPercentSalaryHike                -6.513e-02  4.714e-02  -1.382 0.167122    \nPerformanceRating                 6.772e-01  4.816e-01   1.406 0.159676    \nRelationshipSatisfaction         -3.888e-01  9.884e-02  -3.934 8.37e-05 ***\nStockOptionLevel                 -2.737e-01  1.822e-01  -1.502 0.133202    \nTotalWorkingYears                -6.528e-02  3.587e-02  -1.820 0.068731 .  \nTrainingTimesLastYear            -2.136e-01  8.571e-02  -2.492 0.012712 *  \nWorkLifeBalance                  -2.117e-01  1.469e-01  -1.441 0.149470    \nYearsAtCompany                    6.602e-02  4.876e-02   1.354 0.175764    \nYearsInCurrentRole               -1.021e-01  5.548e-02  -1.840 0.065748 .  \nYearsSinceLastPromotion           2.056e-01  5.166e-02   3.979 6.91e-05 ***\nYearsWithCurrManager             -1.933e-01  6.078e-02  -3.180 0.001473 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 944.39  on 1101  degrees of freedom\nResidual deviance: 616.66  on 1056  degrees of freedom\nAIC: 708.66\n\nNumber of Fisher Scoring iterations: 15\n\n\n\n\nCode\nattrition_test <- testing %>% \n  mutate(prob = predict(est_multlogit, newdata = testing, type = \"response\")) %>% \n    mutate(attrition_class = as.factor(ifelse(prob < .5, \"No\", \"Yes\")))\n\n\n\n\nCode\ncm <- confusionMatrix(attrition_test$Attrition, attrition_test$attrition_class, positive = \"Yes\")\n\ncm\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  288  12\n       Yes  42  26\n                                          \n               Accuracy : 0.8533          \n                 95% CI : (0.8129, 0.8878)\n    No Information Rate : 0.8967          \n    P-Value [Acc > NIR] : 0.9965          \n                                          \n                  Kappa : 0.4128          \n                                          \n Mcnemar's Test P-Value : 7.933e-05       \n                                          \n            Sensitivity : 0.68421         \n            Specificity : 0.87273         \n         Pos Pred Value : 0.38235         \n         Neg Pred Value : 0.96000         \n             Prevalence : 0.10326         \n         Detection Rate : 0.07065         \n   Detection Prevalence : 0.18478         \n      Balanced Accuracy : 0.77847         \n                                          \n       'Positive' Class : Yes"
  },
  {
    "objectID": "intro_fairness.html#mål-på-fairness",
    "href": "intro_fairness.html#mål-på-fairness",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.3 Mål på fairness",
    "text": "4.3 Mål på fairness\nOvenfor så vi blant annet at “positive predicted value” , altså andelen sanne positive av alle predikerte positive, er 0.382.\nMen det er ulike typer jobber i denne bedriften. Her er fordelingen for test-datasettet:\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      No, N = 3001\n      Yes, N = 681\n    \n  \n  \n    JobRole\n\n\n        Healthcare Representative\n31 (10%)\n1 (1.5%)\n        Human Resources\n11 (3.7%)\n3 (4.4%)\n        Laboratory Technician\n47 (16%)\n17 (25%)\n        Manager\n24 (8.0%)\n3 (4.4%)\n        Manufacturing Director\n29 (9.7%)\n3 (4.4%)\n        Research Director\n17 (5.7%)\n1 (1.5%)\n        Research Scientist\n59 (20%)\n18 (26%)\n        Sales Executive\n70 (23%)\n14 (21%)\n        Sales Representative\n12 (4.0%)\n8 (12%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nFor illustrasjonens skyld kan vi da dele inn datamaterialet i to deler: lab-teknikkere og resten. For hver gruppe kan vi så lage en confusion matrix og undersøke verdiene.\n\n\nCode\nlabTech <- attrition_test %>% \n  filter(JobRole %in% c(\"Laboratory Technician\"))\n\nothers <- attrition_test %>% \n  filter( !(JobRole %in% c(\"Laboratory Technician\") ))\n\ncm1 <- confusionMatrix(labTech$Attrition, labTech$attrition_class, positive = \"Yes\")\n\ncm2 <- confusionMatrix(others$Attrition, others$attrition_class, positive = \"Yes\")\n\ncm1 \n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  39   8\n       Yes 10   7\n                                         \n               Accuracy : 0.7188         \n                 95% CI : (0.5924, 0.824)\n    No Information Rate : 0.7656         \n    P-Value [Acc > NIR] : 0.8490         \n                                         \n                  Kappa : 0.251          \n                                         \n Mcnemar's Test P-Value : 0.8137         \n                                         \n            Sensitivity : 0.4667         \n            Specificity : 0.7959         \n         Pos Pred Value : 0.4118         \n         Neg Pred Value : 0.8298         \n             Prevalence : 0.2344         \n         Detection Rate : 0.1094         \n   Detection Prevalence : 0.2656         \n      Balanced Accuracy : 0.6313         \n                                         \n       'Positive' Class : Yes            \n                                         \n\n\nCode\ncm2\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  249   4\n       Yes  32  19\n                                          \n               Accuracy : 0.8816          \n                 95% CI : (0.8398, 0.9157)\n    No Information Rate : 0.9243          \n    P-Value [Acc > NIR] : 0.997           \n                                          \n                  Kappa : 0.4569          \n                                          \n Mcnemar's Test P-Value : 6.795e-06       \n                                          \n            Sensitivity : 0.82609         \n            Specificity : 0.88612         \n         Pos Pred Value : 0.37255         \n         Neg Pred Value : 0.98419         \n             Prevalence : 0.07566         \n         Detection Rate : 0.06250         \n   Detection Prevalence : 0.16776         \n      Balanced Accuracy : 0.85610         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nPositive predicted value for lab-teknikker er 0.412 og for resten 0.373.\nForholdstallet mellom disse er 0.9047619, alså nesten likt. Slik sett kan vi si at modellen er rettferdig på dette målet ved at disse to gruppene er like.\nMen hvis du sjekker output fra confusionMatrix ovenfor, så er jo ikke alle tallene like. Så det kommer an på hvilke mål du sammenligner.\nPakken fairness gjør en tilsvarende beregning for deg og kan gi resultatet grafisk. Her er sammenligning av positive predicted value gjort for alle grupper av jobber:\n\n\nCode\npred_rate_parity(data = attrition_test,\n                 outcome = \"Attrition\", \n                 group = \"JobRole\", \n                 preds = \"attrition_class\", \n                 base = \"Laboratory Technician\"\n                 )[[2]]\n\n\n\n\n\nNå er det vesentig større forskjeller. Utvilsomt er grunnen at gruppen av ‘andre’ var sammensatt av veldig ulike grupper som var veldig forskjellig innbyrdes, men som jevnet hverandre ut i snitt. Noen av disse gruppene var dessuten små."
  },
  {
    "objectID": "intro_fairness.html#oppgaver",
    "href": "intro_fairness.html#oppgaver",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.4 Oppgaver",
    "text": "4.4 Oppgaver\n\nExercise 4.1 Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer.\n\n\nExercise 4.2 Regn ut minst tre ulike mål på fairness og velg selv over hvilke grupper. Gi en forklaring på hva hver av dem betyr.\n\n\nExercise 4.3 Det er mange muligheter her: ulike mål og flere grupper. Man kan også kombinere grupper på flere måter. Gjør følgende vurderinger:\n\nEr det rimelig å gjøre en prediksjon som gir like resultater på tvers av alle mål og grupper? Kan du i det hele tatt få en “fair” modell?\nHvilke mål på “fairness” vil du si er viktigst i dette eksempelet? Hvorfor?\n\n\n\nExercise 4.4 Kanskje hjelper det å estimere en annen modell? Estimer en ny logistisk regresjon, men velg bare et fåtall variable som du velger selv. Hold det enkelt i første omgang. Se på resultatene og vurder:\n\nBle accuracy bedre eller verre?\nBle resultatet mer “fair”?\n\n\n\nExercise 4.5 Velg et nytt datasett, gjør en prediksjon med logistisk regresjon og regn ut mål på “fairness” igjen. Gjør tilsvarende som over."
  },
  {
    "objectID": "cart.html#oppgaver",
    "href": "cart.html#oppgaver",
    "title": "5  Klassifikasjonstrær",
    "section": "5.1 Oppgaver",
    "text": "5.1 Oppgaver\n\nExercise 5.1 Gjenta oppgave 1, men basert på dine vurderinger i e) se om du klarer å tune modellen mer i retning av ønsket cost-ratio. Bruk argumentene prior, cp, minbucket og maxdepth.\n\n\nExercise 5.2 Bruk datasettet credit til å predikere kredittverdighet for nye kunder.\n\nSpesifiser en formel med et fåtall variable og lag et klassifikasjonstre.\nPlot med rpart.plot()\nBruk predict() til å klassifisere.\nLag en confusion matrix med table()\nGi en vurdering av resultatet.\n\nSi noe om forholdet mellom resultat for training og testing datasett.\nEr cost-ratio ok fra bankens perspektiv?\nEr cost-ratio ok fra kundens perspektiv?\nAndre hensyn som bør spille inn her?\n\n\n\n\nExercise 5.3 Datafilen credit_kunder.csv inneholder data om to lånesøkere: Ola Normann og Kari Hansen.\nSkal banken gi dem lån? Bruk foretrukne modell fra forrige oppgave.\n\n\nExercise 5.4 Banker bruker slike systemer i dag i større eller mindre grad til automatisere behandling av lånesøknader. (Men de bruker både rikere data og mer avanserte algoritmer). I hvilken grad synes du slike systemer kan/bør helautomatiseres? Bør det være reguleringer på hva slags data som benyttes til slike systemer? Bør kunden få innsyn i algoritmen ved avslag? Gi noen vurderinger av mulige fordeler og ulemper med tanke på hvordan det kan slå ut for enkeltindivider."
  },
  {
    "objectID": "bagging.html",
    "href": "bagging.html",
    "title": "6  Bagging",
    "section": "",
    "text": "7 Introduksjon til bagging"
  },
  {
    "objectID": "bagging.html#oppgaver",
    "href": "bagging.html#oppgaver",
    "title": "6  Bagging",
    "section": "7.1 Oppgaver",
    "text": "7.1 Oppgaver\n\nExercise 7.1 Bruk bagging til å forbedre prediksjonene. Bruk samme formel, men bygg 150 trær.\n\n\n\nSolution. \n\nCode\nfmla <- default ~ age + amount + percent_of_income + purpose + employment_duration + housing \n\nfmla\n\n\ndefault ~ age + amount + percent_of_income + purpose + employment_duration + \n    housing\n\n\nCode\nset.seed(1)\nbag <- bagging(\n  formula = fmla,\n  data = credit,\n  nbagg = 150,   \n  coob = TRUE,\n  control = rpart.control(minsplit = 2, cp = 0)\n)\nbag\n\n\n\nBagging classification trees with 150 bootstrap replications \n\nCall: bagging.data.frame(formula = fmla, data = credit, nbagg = 150, \n    coob = TRUE, control = rpart.control(minsplit = 2, cp = 0))\n\nOut-of-bag estimate of misclassification error:  0.342"
  },
  {
    "objectID": "randomForest.html#eksempel",
    "href": "randomForest.html#eksempel",
    "title": "7  Random forest",
    "section": "7.1 Eksempel",
    "text": "7.1 Eksempel\nLeser inn Compas-dataene.\n\n\nCode\ncompas <- readRDS(\"../data/compas.rds\")\nglimpse(compas)\n\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\nEstimerer random forest med alle variable\n\n\nCode\nset.seed(4356)\nrf <- randomForest(Two_yr_Recidivism ~ . , \n                    data = compas)\nrf\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.94%\nConfusion matrix:\n     0    1 class.error\n0 2462  901   0.2679156\n1 1132 1677   0.4029904\n\n\nFølgende plot gir en oversikt over feilrater for random forest etter hvor mange trær. Det siste tallet til høyre i plottet er de feilratene som vises i output fra randomForest som vist over. Den svarte linjen er altså den totale feilraten, den grønne er falske positive, og den røde er falske negative. I utgangspunktet bruker random forest 500 trær (slik den er implementert i R). Dette plottet viser når resultatene stabiliserer seg. Kort sagt: Hvis linjene er ganske stabile mot til høyre i plottet har man nok trær. Hvis det har stabilisert seg før kunne man forsåvidt klart seg med færre trær. Hvis grafen er ganske humpete mot høyre i plottet, så kan man øke antall trær og se om det bedrer seg.\n\n\nCode\nplot(rf)\n\n\n\n\n\nPredikerer på samme datasett\n\n\nCode\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf))\n\n\nLager enkel krysstabell med predikert mot observert (dvs confusion matrix)\n\n\nCode\ntable(compas_p$pred_rf, compas_p$Two_yr_Recidivism) \n\n\n   \n       0    1\n  0 2462 1132\n  1  901 1677\n\n\nLager bedre confusion matrix med alle øvrige utregninger. NB! Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei.\n\n\nCode\nconfusionMatrix(compas_p$pred_rf,\n                compas_p$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2462 1132\n         1  901 1677\n                                          \n               Accuracy : 0.6706          \n                 95% CI : (0.6587, 0.6823)\n    No Information Rate : 0.5449          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.3313          \n                                          \n Mcnemar's Test P-Value : 3.378e-07       \n                                          \n            Sensitivity : 0.5970          \n            Specificity : 0.7321          \n         Pos Pred Value : 0.6505          \n         Neg Pred Value : 0.6850          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2717          \n   Detection Prevalence : 0.4177          \n      Balanced Accuracy : 0.6645          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nEstimerer på nytt og øker antall trær og lager nytt plot. Her er det lagt inn en linje ved 500 trær for å markere tilsvarende resultat som ovenfor. Merk at det endelige resultatet endrer seg noe og mer stabilt mot slutten enn før, men kanskje ikke veldig vesentlig bedre. Merk at vi ikke kan forvente at linjene blir helt flate, og bedring i den ene feilraten går gjerne på bekostning av den andre.\n\n\nCode\nset.seed(4356)\nrf1 <- randomForest(Two_yr_Recidivism ~ . , \n                    ntree = 1500, \n                   data = compas)\n\nplot(rf1)\nabline(v=500, col = \"gray\")\n\n\n\n\n\nVi kan justere resultatet med å endre antall variable som tas med i hver split (i hvert tre). I forrige eksempel valgte funksjonen å bruke kun to variable, men det kan settes til f.eks. fire. Merk at det er et poeng at det ikke skal være så mange variable i hver split! Dette endrer normalt ikke resultatene veldig mye.\n\n\nCode\nset.seed(4356)\nrf2 <- randomForest(Two_yr_Recidivism ~ . , \n                    mtry=4,\n                    data = compas)\nrf2\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      mtry = 4) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 4\n\n        OOB estimate of  error rate: 34.36%\nConfusion matrix:\n     0    1 class.error\n0 2608  755   0.2245019\n1 1366 1443   0.4862941\n\n\n\n7.1.1 Variable importance\nFor å få ut variable importance må dette settes i estimeringen med importance = TRUE. Det tar nå litt lengre tid å estimere, så med store datasett bør du vente med dette til du ellers er fornøyd med modellen.\n\n\nCode\nset.seed(4356)\nrf <- randomForest(Two_yr_Recidivism ~ . , \n                   importance = TRUE, \n                    data = compas)\nrf\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.42%\nConfusion matrix:\n     0    1 class.error\n0 2538  825   0.2453167\n1 1176 1633   0.4186543\n\n\nVi kan da plotte variable importance plot. Set type = 1 for at det skal vise gjennomsnittlig reduksjon i accuracy fremfor gini-koeffisienten. Endring i accuracy er lettest tolkbart og er oftest mest meningsfult.\n\n\nCode\nvarImpPlot(rf, type = 1)\n\n\n\n\n\nHer er det altså antall tidligere dommer som har størst betydning for prediksjon av tilbakefall, etterfulgt av alder og kjønn, og til sist om lovbruddet var en forseelse eller ikke.1\n\n\n7.1.2 Partial dependence\nHer må du velge hvilken variabel du ønsker å se på. Det er oftest de “viktigste variablene” fra variable importanc som er mest relevante å se på.\n\n\nCode\npartialPlot(rf, pred.data = compas, \n            x.var = Number_of_Priors, \n            which.class = \"1\")"
  },
  {
    "objectID": "randomForest.html#tuning-av-random-forest",
    "href": "randomForest.html#tuning-av-random-forest",
    "title": "7  Random forest",
    "section": "7.2 Tuning av random forest",
    "text": "7.2 Tuning av random forest\nDet som faktisk endrer resultatene en god del er sampling prosedyren, altså hvor mange observasjoner som trekkes til å bygge hvert tre. I utgangspunktet trekkes 70% av hele utvalget. Men ved å bruke argumentet sampsize = ... kan vi angi en annen andel. Hvis vi angir to tall er det antallet som trekkes fra hver kategori i utfallsvariabelen. Vi kan altså angi hvor mange som trekkes av de med og uten tilbakefall, men disse tallene bør ikke settes større enn 70% av hver kategori. I disse dataene er det 2809 med tilbakefall og 3364 uten tilbakefall. Vi kan da velge å trekke maks 1900 fra gruppen med tilbakefall.\nHensikten med å gjøre dette er at hvis det er et mindretall som har tilbakefall, så blir hvert tre bygget med mer informasjon om ikke-residivistene enn residivistene. Hvis vi vekter opp residivistene, så får disse større inflytelse på hvert tre. Dermed vil dette også påvirke resultatet. Det er imidlertid vanskelig å vite helt sikkert hvordan det vil slå ut, så man må prøve seg litt frem. Noen ganger vil man veie gruppene likt, andre ganger ulikt. Her er et eksempel der de veies likt:\n\n\nCode\nset.seed(4356)\nrf3 <- randomForest(Two_yr_Recidivism ~ . , \n                    sampsize = c(1900, 1900),\n                    data = compas)\nrf3\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      sampsize = c(1900, 1900)) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.73%\nConfusion matrix:\n     0    1 class.error\n0 2321 1042   0.3098424\n1  978 1831   0.3481666\n\n\nHer er et eksempel der de veies ulikt:\n\n\nCode\nset.seed(4356)\nrf3 <- randomForest(Two_yr_Recidivism ~ . , \n                    sampsize = c(1000, 1900),\n                   data = compas)\nrf3\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      sampsize = c(1000, 1900)) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 41.15%\nConfusion matrix:\n     0    1 class.error\n0 1170 2193   0.6520963\n1  347 2462   0.1235315\n\n\nDet viktige nå er at feilratene for falske positive og falske negative blir vesentlig forskjellig! Det betyr at ved hvordan vi estimerer modellen kan vi legge sterke føringer på resultatet. Vi bør derfor ta stilling til på forhånd hvilke feilrater vi er villig til å akseptere - og hvorvidt de to typer feil er like ille eller ikke. Det er dette Berk (2016) kaller asymetriske kostnader og må vurderes i henhold til konsekvenser av hva prediksjonen skal brukes til.\nPredikere for nye data:\n\n\nCode\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf, newdata=compas))\n\n\nConfusion matrix:\n\n\nCode\nconfusionMatrix(compas_p$pred_rf, compas_p$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2595 1156\n         1  768 1653\n                                          \n               Accuracy : 0.6883          \n                 95% CI : (0.6765, 0.6998)\n    No Information Rate : 0.5449          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.3642          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n                                          \n            Sensitivity : 0.5885          \n            Specificity : 0.7716          \n         Pos Pred Value : 0.6828          \n         Neg Pred Value : 0.6918          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2678          \n   Detection Prevalence : 0.3923          \n      Balanced Accuracy : 0.6800          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "randomForest.html#oppgaver",
    "href": "randomForest.html#oppgaver",
    "title": "7  Random forest",
    "section": "7.3 Oppgaver",
    "text": "7.3 Oppgaver\n\nExercise 7.1 Bruk datasettet credit som i forrige oppgave.\n\nBruk random forest til å gjøre en tilsvarende klassifisering som du gjorde med klassifikasjonstre. Bruk default instillinger i randomForest().\nBruk predict() til å klassifisere\nLag en confusion matrix med table() og gjenta med confusionMatrix()\nGjør en vurdering av resultatet og sammenlign med resultat fra klassifikasjonstre\n\n\n\nExercise 7.2 Gjenta oppgave 1, men se om du kan justere modellen til et mer tilfredsstillende resultat. Gjør deg først opp en mening om hvordan du vil at confusion matrix skal se ut (f.eks. cost-ratio) og prøv å nærme deg dette. Bruk parameterne sampsize, mtry og ntree.\n\n\nExercise 7.3 Tolk random forest a) Hvilke variable har størst prediktiv verdi? Lag et variable importance plot og gi en tolkning. a) Velg noen av variablene (gjerne f.eks. de med størst prediktiv verdi) og lag partial dependence plot.\n\n\nExercise 7.4 Datafilen credit_kunder.csv inneholder data om to lånesøkere: Ola Normann og Kari Hansen. Skal banken gi dem lån? Bruk foretrukne modell fra forrige oppgave. Hvis du virkelig vil at begge skal få lån kan du kanskje justere modellen? Legge til/fjerne variable fra formelen og justere tuning parametrene. Prøv deg frem."
  },
  {
    "objectID": "fairness.html#introduksjon-til-fairness",
    "href": "fairness.html#introduksjon-til-fairness",
    "title": "8  Fairness",
    "section": "8.1 Introduksjon til fairness",
    "text": "8.1 Introduksjon til fairness\n\nlibrary(tidyverse)\nlibrary(randomForest)\nlibrary(caret)\nlibrary(fairness)\n\nCompas er et risikoverktøy brukt av amerikansk politi i flere stater som benyttes på individnivå. Bruken av dette verktøyet har vært kontroversielt i flere år og kraftig kritisert av flere. En viktig grunn er at prediksjonene slår forskjellig ut for ulike grupper og er slik sett “biased” mot bl.a. svarte borgere. Resultatet er at de blir mer utsatt for politiets oppmerksomhet enn andre.1 Et datasett er gjort tilgjengelig av Propublica her som vi skal bruke.\n\n\nCode\ncompas <- readRDS(\"../data/compas.rds\")\n\nglimpse(compas)\n\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\nVi tilpasser først en random forest modell.\n\n\nCode\nset.seed(4356)\nglimpse(compas)\n\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\nCode\nrf <- randomForest(Two_yr_Recidivism ~ .,\n                   #importance = TRUE,\n                    data = compas)\n\n\nLager en prediksjon i nytt datasett\n\n\nCode\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf))  \n\n\nConfusion matrix\n\n\nCode\nconfusionMatrix(compas_p$pred_rf,\n                compas_p$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2462 1132\n         1  901 1677\n                                          \n               Accuracy : 0.6706          \n                 95% CI : (0.6587, 0.6823)\n    No Information Rate : 0.5449          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.3313          \n                                          \n Mcnemar's Test P-Value : 3.378e-07       \n                                          \n            Sensitivity : 0.5970          \n            Specificity : 0.7321          \n         Pos Pred Value : 0.6505          \n         Neg Pred Value : 0.6850          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2717          \n   Detection Prevalence : 0.4177          \n      Balanced Accuracy : 0.6645          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nSplitter datasettet i to etter kjønn. Her for menn.\n\n\nCode\ncompas_1 <- compas_p %>% \n  filter(Sex == \"Male\")\n\n\nConfusion matrix for menn\n\n\nCode\nconfusionMatrix(compas_1$pred_rf,\n                compas_1$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 1807  897\n         1  794 1499\n                                          \n               Accuracy : 0.6616          \n                 95% CI : (0.6483, 0.6747)\n    No Information Rate : 0.5205          \n    P-Value [Acc > NIR] : < 2e-16         \n                                          \n                  Kappa : 0.3209          \n                                          \n Mcnemar's Test P-Value : 0.01312         \n                                          \n            Sensitivity : 0.6256          \n            Specificity : 0.6947          \n         Pos Pred Value : 0.6537          \n         Neg Pred Value : 0.6683          \n             Prevalence : 0.4795          \n         Detection Rate : 0.3000          \n   Detection Prevalence : 0.4589          \n      Balanced Accuracy : 0.6602          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nSplitter datasettet i to etter kjønn. Her for kvinner.\n\n\nCode\ncompas_2 <- compas_p %>% \n  filter(Sex == \"Female\")\n\n\nConfusion matrix for kvinner\n\n\nCode\nconfusionMatrix(compas_2$pred_rf,\n                compas_2$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 655 235\n         1 107 178\n                                         \n               Accuracy : 0.7089         \n                 95% CI : (0.682, 0.7348)\n    No Information Rate : 0.6485         \n    P-Value [Acc > NIR] : 6.251e-06      \n                                         \n                  Kappa : 0.3128         \n                                         \n Mcnemar's Test P-Value : 6.539e-12      \n                                         \n            Sensitivity : 0.4310         \n            Specificity : 0.8596         \n         Pos Pred Value : 0.6246         \n         Neg Pred Value : 0.7360         \n             Prevalence : 0.3515         \n         Detection Rate : 0.1515         \n   Detection Prevalence : 0.2426         \n      Balanced Accuracy : 0.6453         \n                                         \n       'Positive' Class : 1              \n                                         \n\n\nBruker funksjoner i fairness-pakken til å gjøre det samme:\n\n\nCode\nacc <- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'pred_rf', \n                  base         = 'Female')\nacc$Metric\n\n\n                      Female        Male\nAccuracy           0.7089362    0.661597\nAccuracy Parity    1.0000000    0.933225\nGroup size      1175.0000000 4997.000000\n\n\nHer er en grafisk fremstilling av ACC\n\n\nCode\nacc$Metric_plot"
  },
  {
    "objectID": "fairness.html#flere-mål-på-fairness",
    "href": "fairness.html#flere-mål-på-fairness",
    "title": "8  Fairness",
    "section": "8.2 Flere mål på fairness",
    "text": "8.2 Flere mål på fairness"
  },
  {
    "objectID": "fairness.html#tuning-til-mer-fairness",
    "href": "fairness.html#tuning-til-mer-fairness",
    "title": "8  Fairness",
    "section": "8.3 Tuning til mer fairness",
    "text": "8.3 Tuning til mer fairness"
  },
  {
    "objectID": "fairness.html#oppgaver",
    "href": "fairness.html#oppgaver",
    "title": "8  Fairness",
    "section": "8.4 Oppgaver",
    "text": "8.4 Oppgaver"
  },
  {
    "objectID": "boosting.html#adaptive-boosting---adaboost",
    "href": "boosting.html#adaptive-boosting---adaboost",
    "title": "9  Boosting",
    "section": "9.1 Adaptive boosting - Adaboost",
    "text": "9.1 Adaptive boosting - Adaboost\nAdaptive boosting har et enkelt prinsipp: Først estimeres en modell, og deretter estimeres en ny modell der feilklassifikasjonene fra forrige modell vektes tyngre. Teorien tilsier at dette vil bedre klassifikasjonen. Så fortsetter den slik og estimerer nye vektede modeller til vi ikke får noen vesetnlig forbedring."
  },
  {
    "objectID": "boosting.html#gradient-boosting---gbm",
    "href": "boosting.html#gradient-boosting---gbm",
    "title": "9  Boosting",
    "section": "9.2 Gradient boosting - gbm",
    "text": "9.2 Gradient boosting - gbm\nGradient boosting er bygget på et tilsvarende prinsipp, men vekter ikke dataene. Derimot bruker den loss-funksjon i stedet."
  },
  {
    "objectID": "boosting.html#extreme-gradient-boosting---xgboost",
    "href": "boosting.html#extreme-gradient-boosting---xgboost",
    "title": "9  Boosting",
    "section": "9.3 Extreme gradient boosting - XGboost",
    "text": "9.3 Extreme gradient boosting - XGboost"
  },
  {
    "objectID": "unsupervised.html#hierarkisk-klustering",
    "href": "unsupervised.html#hierarkisk-klustering",
    "title": "10  Unsupervised learning",
    "section": "10.1 Hierarkisk klustering",
    "text": "10.1 Hierarkisk klustering\n\nExercise 10.1 Last ned filen krim2016.RData fra Canvas. Dette er deler av dataene vi brukte i første seminar med kommunetall. Her er det anmeldt kriminalitet per 1000 innbyggere i kommuner i 2016.\n\nGjør en hierarkisk klusteranalsyse. Er det noen kommuner som skiller seg veldig fra de andre? Spiller det noen rolle hvilken type distance du setter?\nHvilke kommuner er de de klusterne som skiller seg ut?\nHva kjennetegner lovbruddsbildet i de ulike klustrene? Kan du tenke deg noen grunner til at akkurat disse stikker seg ut?\n\n\n\nSolution. Leser inn data om inntektsutvikling for ulike yrker fra 2001 til 2016\nDataene er i “bred” format. Det er slik vi vil ha det for clusteranalyse, men dårlig for å lage en graf.\n\n\nCode\nload(\"../data/oes.RData\")\n\ngathered_oes <- gather(data = df_oes, \n                       key = year, \n                       value = mean_salary, \n                       -occupation)\n\nggplot(gathered_oes, aes(x=as.numeric(year), y=mean_salary, col = occupation))+\n  geom_line()\n\n\n\n\n\nCode\ndist_oes <- dist(df_oes[,-1], method = \"euclidian\") # calculate distances \n\nhc_oes <- hclust(dist_oes, method = \"single\")  # minste avstand\n\nhc_oes <- hclust(dist_oes, method = \"complete\") # lengste avstand\n\nhc_oes <- hclust(dist_oes, method = \"average\") #gjennomsnittlig avstand\n\npar(mar=c(10,4,2,2))  # Endre marginer for base-plot\n\ndend_oes <- as.dendrogram(hc_oes) #Create a dendrogram object\ndend_colored <- color_branches(dend_oes, h = 100000)\nplot(dend_colored)\n\n# Illustrer mulige cutoff - legger linjer oppå eksisterende plot\nabline(h=100000, col=\"red\", lwd=1.5)  # Viser cut ved h=100000\nabline(h=10000, col=\"red\", lwd=1.5)   # Viser cut ved h=10000\n\n\n\n\n\nCode\n# Henter ut cluster ved valgt h\ncluster <- cutree(hc_oes, h=100000)\n#cluster <- cutree(hc_oes, k=3)\ntable(cluster)\n\n\ncluster\n 1  2  3 \n 2  5 15 \n\n\nCode\n# Legger til vektoren cluster til opprinnelige data\nhclust_oes <- mutate(df_oes, cluster = cluster)\n\nhead(hclust_oes)\n\n\n                 occupation  2001  2002  2003  2004  2005  2006  2007   2008\n1                Management 70800 78870 83400 87090 88450 91930 96150 100310\n2       Business Operations 50580 53350 56000 57120 57930 60000 62410  64720\n3          Computer Science 60350 61630 64150 66370 67100 69240 72190  74500\n4  Architecture/Engineering 56330 58020 60390 63060 63910 66190 68880  71430\n5 Life/Physical/Social Sci. 49710 52380 54930 57550 58030 59660 62020  64280\n6        Community Services 34190 34630 35800 37050 37530 39000 40540  41790\n    2010   2011   2012   2013   2014   2015   2016 cluster\n1 105440 107410 108570 110550 112490 115020 118020       1\n2  67690  68740  69550  71020  72410  73800  75070       2\n3  77230  78730  80180  82010  83970  86170  87880       2\n4  75550  77120  79000  80100  81520  82980  84300       2\n5  66390  67470  68360  69400  70070  71220  72930       2\n6  43180  43830  44240  44710  45310  46160  47200       3\n\n\nCode\n# vrenger dataene \"nedover\" for å plotte\ngathered_oes <- gather(data = hclust_oes,    # datasett\n                       key = year,           # navn på ny variabel, verdier hentes fra gamle variabelnavn\n                       value = mean_salary,  # navn på ny variabel med gamle variabelverdier\n                       -occupation, -cluster) # variable som skal beholdes / grupperes etter\nggplot(gathered_oes, aes(x = year, y = mean_salary, color = factor(cluster), group = occupation)) + \n  geom_line()"
  },
  {
    "objectID": "unsupervised.html#k-means-klustering",
    "href": "unsupervised.html#k-means-klustering",
    "title": "10  Unsupervised learning",
    "section": "10.2 K-means klustering",
    "text": "10.2 K-means klustering\n\nExercise 10.2 Gjenta analysen over med k-means clustering. Hvor mange klustre bør det være? Får du samme resultat?\n\n\n\nSolution. \n\nCode\n## K-means clustering med samme data \n\n# Eksempel ved å sette antall kluster til 3\n# I dette tilfellet bør vi få samme resultat\nkm_oes <- kmeans(dist_oes, centers = 3)\n\ntable(km_oes$cluster)\n\n\n\n1 2 3 \n8 7 7 \n\n\nCode\nkmclust_oes <- mutate(df_oes, cluster=km_oes$cluster)\n\n# Plotter\ngathered_kmoes <- gather(data = kmclust_oes,    # datasett\n                       key = year,           # navn på ny variabel, verdier hentes fra gamle variabelnavn\n                       value = mean_salary,  # navn på ny variabel med gamle variabelverdier\n                       -occupation, -cluster) # variable som skal beholdes / grupperes etter\nggplot(gathered_kmoes, aes(x = year, y = mean_salary, color = factor(cluster), group = occupation)) + \n  geom_line()\n\n\n\n\n\nCode\n### K-means clustering. Make a search\nwss <- 0\n# For 1 to 15 cluster centers\nfor (i in 1:5) {\n  km.out <- kmeans(dist_oes, centers = i, nstart=20)\n  # Save total within sum of squares to wss variable\n  wss[i] <- km.out$tot.withinss\n}\n\n# Plot total within sum of squares vs. number of clusters\nplot(1:5, wss, type = \"b\", \n     xlab = \"Number of Clusters\", \n     ylab = \"Within groups sum of squares\")\n# Marker \"albuen\" med en linje i plottet \nabline(v=2, col=\"red\")\n\n\n\n\n\nCode\noes <- readRDS(\"../data/oes.rds\")\n\n## Create final clustering\nkm_oes <- kmeans(oes, centers = 2, nstart=20)\ntable(km_oes$cluster)\n\n\n\n 1  2 \n15  7 \n\n\nCode\nkmclust_oes <- mutate(df_oes, cluster=km_oes$cluster)\ngathered_kmoes <- gather(data = kmclust_oes,    # datasett\n                         key = year,           # navn på ny variabel, verdier hentes fra gamle variabelnavn\n                         value = mean_salary,  # navn på ny variabel med gamle variabelverdier\n                         -occupation, -cluster) # variable som skal beholdes / grupperes etter\nggplot(gathered_kmoes, aes(x = year, y = mean_salary, color = factor(cluster), group = occupation)) + \n  geom_line()"
  },
  {
    "objectID": "unsupervised.html#datareduksjon-med-principal-component-analysis-pca",
    "href": "unsupervised.html#datareduksjon-med-principal-component-analysis-pca",
    "title": "10  Unsupervised learning",
    "section": "10.3 Datareduksjon med principal component analysis (PCA)",
    "text": "10.3 Datareduksjon med principal component analysis (PCA)\n\n10.3.1 Multippel korrespondanseanalyse\nPCA har egentlig som forutsetning av variablene er kontinuerlige, og det er litt trøblete å bruke det på kategoriske variable. Men ofte har vi kategoriske variable.\nEn variant av PCA for kategoriske variable er korrespondanseanalyse, som i teorien altså skal være bedre enn PCA. I praksis er det imidlertid ikke nødvendigvis veldig stor forskjell (REF), så det er neppe stor skade skjedd hvis man bruker PCA likevel."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Berk, Richard. 2016. Statistical Learning from a Regression\nPerspective. USA: Springer.\n\n\nHsieh, John. 2008. “Receiver Operating Characteristic (ROC)\nCurve.” In Encyclopedia of Epidemiology, 895–98.\nThousand Oaks, California: Sage. https://doi.org/10.4135/9781412953948.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data\nScience. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley."
  },
  {
    "objectID": "datasets.html#credit",
    "href": "datasets.html#credit",
    "title": "Appendix A — Datasett",
    "section": "A.1 Credit",
    "text": "A.1 Credit\nUtfallsvariabel: “default” (misligholdelse av lån) Data er hentet fra datacamp.com\nDataene inneholder følgende variable:\n\n\nCode\ncredit <- read.csv(\"data/credit.csv\")\n\nglimpse(credit)\n\n\nRows: 1,000\nColumns: 17\n$ checking_balance     <chr> \"< 0 DM\", \"1 - 200 DM\", \"unknown\", \"< 0 DM\", \"< 0…\n$ months_loan_duration <int> 6, 48, 12, 42, 24, 36, 24, 36, 12, 30, 12, 48, 12…\n$ credit_history       <chr> \"critical\", \"good\", \"critical\", \"good\", \"poor\", \"…\n$ purpose              <chr> \"furniture/appliances\", \"furniture/appliances\", \"…\n$ amount               <int> 1169, 5951, 2096, 7882, 4870, 9055, 2835, 6948, 3…\n$ savings_balance      <chr> \"unknown\", \"< 100 DM\", \"< 100 DM\", \"< 100 DM\", \"<…\n$ employment_duration  <chr> \"> 7 years\", \"1 - 4 years\", \"4 - 7 years\", \"4 - 7…\n$ percent_of_income    <int> 4, 2, 2, 2, 3, 2, 3, 2, 2, 4, 3, 3, 1, 4, 2, 4, 4…\n$ years_at_residence   <int> 4, 2, 3, 4, 4, 4, 4, 2, 4, 2, 1, 4, 1, 4, 4, 2, 4…\n$ age                  <int> 67, 22, 49, 45, 53, 35, 53, 35, 61, 28, 25, 24, 2…\n$ other_credit         <chr> \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"…\n$ housing              <chr> \"own\", \"own\", \"own\", \"other\", \"other\", \"other\", \"…\n$ existing_loans_count <int> 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2…\n$ job                  <chr> \"skilled\", \"skilled\", \"unskilled\", \"skilled\", \"sk…\n$ dependents           <int> 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ phone                <chr> \"yes\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\"…\n$ default              <chr> \"no\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\",…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#attrition",
    "href": "datasets.html#attrition",
    "title": "Appendix A — Datasett",
    "section": "A.2 Attrition",
    "text": "A.2 Attrition\nUtfallsvariabel: “Attrition”, dvs om en arbeidstaker slutter i jobben.\nDatasettet er tilgjengelig fra Kaggle.\n\n\nCode\nattrition <- readRDS(\"data/attrition.rds\")\nglimpse(attrition)\n\n\nRows: 1,470\nColumns: 32\n$ Age                      <int> 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35, 2…\n$ Attrition                <fct> Yes, No, Yes, No, No, No, No, No, No, No, No,…\n$ BusinessTravel           <fct> Travel_Rarely, Travel_Frequently, Travel_Rare…\n$ DailyRate                <int> 1102, 279, 1373, 1392, 591, 1005, 1324, 1358,…\n$ Department               <fct> Sales, Research & Development, Research & Dev…\n$ DistanceFromHome         <int> 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26, …\n$ Education                <int> 2, 1, 2, 4, 1, 2, 3, 1, 3, 3, 3, 2, 1, 2, 3, …\n$ EducationField           <fct> Life Sciences, Life Sciences, Other, Life Sci…\n$ EmployeeNumber           <int> 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16,…\n$ EnvironmentSatisfaction  <int> 2, 3, 4, 4, 1, 4, 3, 4, 4, 3, 1, 4, 1, 2, 3, …\n$ Gender                   <fct> Female, Male, Male, Female, Male, Male, Femal…\n$ HourlyRate               <int> 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84, 4…\n$ JobInvolvement           <int> 3, 2, 2, 3, 3, 3, 4, 3, 2, 3, 4, 2, 3, 3, 2, …\n$ JobLevel                 <int> 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, …\n$ JobRole                  <fct> Sales Executive, Research Scientist, Laborato…\n$ JobSatisfaction          <int> 4, 2, 3, 3, 2, 4, 1, 3, 3, 3, 2, 3, 3, 4, 3, …\n$ MaritalStatus            <fct> Single, Married, Single, Married, Married, Si…\n$ MonthlyIncome            <int> 5993, 5130, 2090, 2909, 3468, 3068, 2670, 269…\n$ MonthlyRate              <int> 19479, 24907, 2396, 23159, 16632, 11864, 9964…\n$ NumCompaniesWorked       <int> 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5, …\n$ OverTime                 <fct> Yes, No, Yes, Yes, No, No, Yes, No, No, No, N…\n$ PercentSalaryHike        <int> 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13, 1…\n$ PerformanceRating        <int> 3, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, …\n$ RelationshipSatisfaction <int> 1, 4, 2, 3, 4, 3, 1, 2, 2, 2, 3, 4, 4, 3, 2, …\n$ StockOptionLevel         <int> 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, 0, …\n$ TotalWorkingYears        <int> 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5, 3…\n$ TrainingTimesLastYear    <int> 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, 4, …\n$ WorkLifeBalance          <int> 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, …\n$ YearsAtCompany           <int> 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, 4,…\n$ YearsInCurrentRole       <int> 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, 2, …\n$ YearsSinceLastPromotion  <int> 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0, …\n$ YearsWithCurrManager     <int> 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, 3, …\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#kommunedata",
    "href": "datasets.html#kommunedata",
    "title": "Appendix A — Datasett",
    "section": "A.3 Kommunedata",
    "text": "A.3 Kommunedata\nDisse dataene er hentet fra SSBs offisielle statistikk og koblet sammen på kommunenummer. Fra statistikkbanken tabeller nr. 06944 (inntekt), 12210 (sosialhjelp/KOSTRA), 07459 (befolkning), 08487 (anmeldte lovbrudd). Flere variable kan kobles på. Merk: det er flere endringer i kommunestruktur, særlig i 2020. Kommunene er altså ikke helt det samme over tid.\nAktuelle utfallsvariable: Flere variable kan være aktuell som utfallsvariable. Prediktorer må nok omarbeides noe etter egne vurderinger (f.eks. omregne til per 1000 eller prosent, summere totaltall etc).\n\n\nCode\nkommune <- readRDS(\"data/kommunedata.rds\")\nglimpse(kommune)\n\n\nRows: 1,529\nColumns: 28\n$ kommune_nr             <chr> \"0101\", \"0101\", \"0101\", \"0101\", \"0104\", \"0104\",…\n$ kommune                <chr> \"Halden (-2019)\", \"Halden (-2019)\", \"Halden (-2…\n$ year                   <dbl> 2015, 2016, 2017, 2018, 2015, 2016, 2017, 2018,…\n$ bef_18min              <int> 3556, 3503, 3505, 3544, 3594, 3652, 3704, 3655,…\n$ bef_18_25              <int> 3575, 3585, 3432, 3438, 3405, 3404, 3355, 3370,…\n$ bef_26_35              <int> 3728, 3804, 3985, 4035, 4057, 4071, 4124, 4110,…\n$ bef_totalt             <int> 30328, 30544, 30790, 31037, 31802, 32182, 32407…\n$ menn_18_25             <int> 1847, 1865, 1813, 1819, 1789, 1802, 1789, 1810,…\n$ menn_26_35             <int> 1880, 1919, 2005, 2062, 2063, 2083, 2113, 2134,…\n$ menn_36_67             <int> 7067, 7051, 7085, 7057, 7418, 7453, 7408, 7407,…\n$ menn_67plus            <int> 2496, 2624, 2697, 2806, 2671, 2777, 2856, 2895,…\n$ menn_18min             <int> 1880, 1847, 1873, 1876, 1842, 1885, 1919, 1878,…\n$ kvinner_18_25          <int> 1728, 1720, 1619, 1619, 1616, 1602, 1566, 1560,…\n$ kvinner_26_35          <int> 1848, 1885, 1980, 1973, 1994, 1988, 2011, 1976,…\n$ kvinner_36_67          <int> 6880, 6832, 6844, 6848, 7479, 7519, 7537, 7596,…\n$ kvinner_67plus         <int> 3026, 3145, 3242, 3309, 3178, 3306, 3423, 3555,…\n$ kvinner_18min          <int> 1676, 1656, 1632, 1668, 1752, 1767, 1785, 1777,…\n$ inntekt_totalt_median  <int> 555000, 562000, 580000, 591000, 561000, 568000,…\n$ inntekt_eskatt_median  <int> 451000, 453000, 470000, 480000, 449000, 456000,…\n$ ant_husholdninger      <int> 13890, 14124, 14281, 14454, 15046, 15132, 15313…\n$ shj_klienter           <int> 1183, 1137, 1099, 1128, 1155, 1129, 1152, 1137,…\n$ shj_unge               <int> 262, 247, 248, 242, 267, 263, 238, 222, 307, 28…\n$ vinningskriminalitet   <dbl> 19.7, 18.7, 16.5, 14.5, 24.5, 21.5, 18.0, 18.0,…\n$ voldskriminalitet      <dbl> 11.2, 12.6, 12.3, 11.2, 7.8, 8.3, 8.7, 9.7, 6.8…\n$ nark_alko_kriminalitet <dbl> 21.0, 21.9, 21.0, 20.3, 12.0, 10.2, 10.9, 10.1,…\n$ ordenslovbrudd         <dbl> 18.5, 16.5, 14.9, 13.7, 8.9, 9.0, 9.1, 9.2, 8.2…\n$ trafikklovbrudd        <dbl> 15.5, 16.3, 16.7, 19.2, 7.4, 6.3, 6.9, 8.0, 9.6…\n$ andre_lovbrudd         <dbl> 25.5, 26.5, 26.1, 25.2, 12.1, 12.2, 11.9, 12.4,…\n\n\n\n\n\n\n Download data as rds"
  },
  {
    "objectID": "datasets.html#churn",
    "href": "datasets.html#churn",
    "title": "Appendix A — Datasett",
    "section": "A.4 Churn",
    "text": "A.4 Churn\n\n\nCode\nchurn <- read.csv(\"data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\nglimpse(churn)\n\n\nRows: 7,043\nColumns: 21\n$ customerID       <chr> \"7590-VHVEG\", \"5575-GNVDE\", \"3668-QPYBK\", \"7795-CFOCW…\n$ gender           <chr> \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Female\",…\n$ SeniorCitizen    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Partner          <chr> \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes…\n$ Dependents       <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\"…\n$ tenure           <int> 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 58, 49, 2…\n$ PhoneService     <chr> \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ MultipleLines    <chr> \"No phone service\", \"No\", \"No\", \"No phone service\", \"…\n$ InternetService  <chr> \"DSL\", \"DSL\", \"DSL\", \"DSL\", \"Fiber optic\", \"Fiber opt…\n$ OnlineSecurity   <chr> \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"…\n$ OnlineBackup     <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"N…\n$ DeviceProtection <chr> \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Y…\n$ TechSupport      <chr> \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Yes…\n$ StreamingTV      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Ye…\n$ StreamingMovies  <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes…\n$ Contract         <chr> \"Month-to-month\", \"One year\", \"Month-to-month\", \"One …\n$ PaperlessBilling <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ PaymentMethod    <chr> \"Electronic check\", \"Mailed check\", \"Mailed check\", \"…\n$ MonthlyCharges   <dbl> 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89.10, 29.7…\n$ TotalCharges     <dbl> 29.85, 1889.50, 108.15, 1840.75, 151.65, 820.50, 1949…\n$ Churn            <chr> \"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Y…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#recidivism-from-iowa-prisons",
    "href": "datasets.html#recidivism-from-iowa-prisons",
    "title": "Appendix A — Datasett",
    "section": "A.5 Recidivism from Iowa prisons",
    "text": "A.5 Recidivism from Iowa prisons\nDatasettet inneholder data på 26020 personer løslatt fra fengsel i staten Iowa, USA mellom 2010 og 2015. For hver person er det informasjon om hvorvidt de har blitt fengslet på nytt innen 3 år (dvs. fulgt til mellom 2013 og 2018).\nAktuell utfallsvariabel: “Recidivism…Return.to.Prison.numeric” Endre gjerne variabelnavn til noe kortere.\nDatasettet er tilgjengelig fra Kaggle og er nærmere omtalt der.\n\n\nCode\nrecidivism <- read.csv(\"data/3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated.csv\", stringsAsFactors = TRUE)\n\nglimpse(recidivism)\n\n\nRows: 26,020\nColumns: 12\n$ Fiscal.Year.Released                      <int> 2010, 2010, 2010, 2010, 2010…\n$ Recidivism.Reporting.Year                 <int> 2013, 2013, 2013, 2013, 2013…\n$ Race...Ethnicity                          <fct> White - Non-Hispanic, White …\n$ Age.At.Release                            <fct> Under 25, 55 and Older, 25-3…\n$ Convicting.Offense.Classification         <fct> D Felony, D Felony, D Felony…\n$ Convicting.Offense.Type                   <fct> Violent, Public Order, Prope…\n$ Convicting.Offense.Subtype                <fct> Assault, OWI, Burglary, Traf…\n$ Main.Supervising.District                 <fct> 4JD, 7JD, 5JD, 8JD, 3JD, , 3…\n$ Release.Type                              <fct> Parole, Parole, Parole, Paro…\n$ Release.type..Paroled.to.Detainder.united <fct> Parole, Parole, Parole, Paro…\n$ Part.of.Target.Population                 <fct> Yes, Yes, Yes, Yes, Yes, No,…\n$ Recidivism...Return.to.Prison.numeric     <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#compas",
    "href": "datasets.html#compas",
    "title": "Appendix A — Datasett",
    "section": "A.6 Compas",
    "text": "A.6 Compas\nUtfallsvariabel: “Two_yr_Revidvism”\nData er hentet fra R-pakken fairmodels, modifisert datsett fra ProPublica\n\n\nCode\ncompas <- readRDS(\"data/compas.rds\")\nglimpse(compas)\n\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#diabetes-rehospitalization",
    "href": "datasets.html#diabetes-rehospitalization",
    "title": "Appendix A — Datasett",
    "section": "A.7 Diabetes rehospitalization",
    "text": "A.7 Diabetes rehospitalization\nData er beskrevet nærmere i Strack et al (2014) (se særlig tabell 1) og er tilgjengelig fra UCI machine learning repository\nUtfallsvariabelen av interesse er readmitted, altså om pasienten blir lagt inn på nytt på et eller annet tidspunkt etter utskrivning.\n\n\nCode\ndiabetic <- read.csv(\"data/diabetic_data.csv\")\nglimpse(diabetic)\n\n\nRows: 101,766\nColumns: 50\n$ encounter_id             <int> 2278392, 149190, 64410, 500364, 16680, 35754,…\n$ patient_nbr              <int> 8222157, 55629189, 86047875, 82442376, 425192…\n$ race                     <chr> \"Caucasian\", \"Caucasian\", \"AfricanAmerican\", …\n$ gender                   <chr> \"Female\", \"Female\", \"Female\", \"Male\", \"Male\",…\n$ age                      <chr> \"[0-10)\", \"[10-20)\", \"[20-30)\", \"[30-40)\", \"[…\n$ weight                   <chr> \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", …\n$ admission_type_id        <int> 6, 1, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 1, 3, …\n$ discharge_disposition_id <int> 25, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 6, 1,…\n$ admission_source_id      <int> 1, 7, 7, 7, 7, 2, 2, 7, 4, 4, 7, 4, 7, 7, 2, …\n$ time_in_hospital         <int> 1, 3, 2, 2, 1, 3, 4, 5, 13, 12, 9, 7, 7, 10, …\n$ payer_code               <chr> \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", …\n$ medical_specialty        <chr> \"Pediatrics-Endocrinology\", \"?\", \"?\", \"?\", \"?…\n$ num_lab_procedures       <int> 41, 59, 11, 44, 51, 31, 70, 73, 68, 33, 47, 6…\n$ num_procedures           <int> 0, 0, 5, 1, 0, 6, 1, 0, 2, 3, 2, 0, 0, 1, 5, …\n$ num_medications          <int> 1, 18, 13, 16, 8, 16, 21, 12, 28, 18, 17, 11,…\n$ number_outpatient        <int> 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ number_emergency         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ number_inpatient         <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ diag_1                   <chr> \"250.83\", \"276\", \"648\", \"8\", \"197\", \"414\", \"4…\n$ diag_2                   <chr> \"?\", \"250.01\", \"250\", \"250.43\", \"157\", \"411\",…\n$ diag_3                   <chr> \"?\", \"255\", \"V27\", \"403\", \"250\", \"250\", \"V45\"…\n$ number_diagnoses         <int> 1, 9, 6, 7, 5, 9, 7, 8, 8, 8, 9, 7, 8, 8, 8, …\n$ max_glu_serum            <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None…\n$ A1Cresult                <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None…\n$ metformin                <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Steady\",…\n$ repaglinide              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ nateglinide              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ chlorpropamide           <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ glimepiride              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Steady\",…\n$ acetohexamide            <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ glipizide                <chr> \"No\", \"No\", \"Steady\", \"No\", \"Steady\", \"No\", \"…\n$ glyburide                <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"St…\n$ tolbutamide              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ pioglitazone             <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ rosiglitazone            <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ acarbose                 <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ miglitol                 <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ troglitazone             <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ tolazamide               <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ examide                  <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ citoglipton              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ insulin                  <chr> \"No\", \"Up\", \"No\", \"Up\", \"Steady\", \"Steady\", \"…\n$ glyburide.metformin      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ glipizide.metformin      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ glimepiride.pioglitazone <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ metformin.rosiglitazone  <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ metformin.pioglitazone   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ change                   <chr> \"No\", \"Ch\", \"No\", \"Ch\", \"Ch\", \"No\", \"Ch\", \"No…\n$ diabetesMed              <chr> \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes…\n$ readmitted               <chr> \"NO\", \">30\", \"NO\", \"NO\", \"NO\", \">30\", \"NO\", \"…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#absenteeism",
    "href": "datasets.html#absenteeism",
    "title": "Appendix A — Datasett",
    "section": "A.8 Absenteeism",
    "text": "A.8 Absenteeism\nDette er et syntetisk datasett som inneholder 8336 personer i en tenkt bedrift og hvor mange timer hver person har fravær fra jobben.\nData er tilgjengelig fra Kaggle\n\n\nCode\nabsenteeism <- read.csv(\"data/MFGEmployees4.csv\")\nglimpse(absenteeism)\n\n\nRows: 8,336\nColumns: 13\n$ EmployeeNumber <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ Surname        <chr> \"Gutierrez\", \"Hardwick\", \"Delgado\", \"Simon\", \"Delvalle\"…\n$ GivenName      <chr> \"Molly\", \"Stephen\", \"Chester\", \"Irene\", \"Edward\", \"Erni…\n$ Gender         <chr> \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", …\n$ City           <chr> \"Burnaby\", \"Courtenay\", \"Richmond\", \"Victoria\", \"New We…\n$ JobTitle       <chr> \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"…\n$ DepartmentName <chr> \"Bakery\", \"Bakery\", \"Bakery\", \"Bakery\", \"Bakery\", \"Bake…\n$ StoreLocation  <chr> \"Burnaby\", \"Nanaimo\", \"Richmond\", \"Victoria\", \"New West…\n$ Division       <chr> \"Stores\", \"Stores\", \"Stores\", \"Stores\", \"Stores\", \"Stor…\n$ Age            <dbl> 32.02882, 40.32090, 48.82205, 44.59936, 35.69788, 48.44…\n$ LengthService  <dbl> 6.018478, 5.532445, 4.389973, 3.081736, 3.619091, 2.717…\n$ AbsentHours    <dbl> 36.57731, 30.16507, 83.80780, 70.02017, 0.00000, 81.830…\n$ BusinessUnit   <chr> \"Stores\", \"Stores\", \"Stores\", \"Stores\", \"Stores\", \"Stor…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#human-resources-hr",
    "href": "datasets.html#human-resources-hr",
    "title": "Appendix A — Datasett",
    "section": "A.9 Human resources (HR)",
    "text": "A.9 Human resources (HR)\nData er tilgjengelig fra Kaggle og variable er beskrevet nærmere på denne lenken.\n\n\nCode\nhr <- read.csv(\"data/HRDataset_v14.csv\")\nglimpse(hr)\n\n\nRows: 311\nColumns: 36\n$ Employee_Name              <chr> \"Adinolfi, Wilson  K\", \"Ait Sidi, Karthikey…\n$ EmpID                      <int> 10026, 10084, 10196, 10088, 10069, 10002, 1…\n$ MarriedID                  <int> 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0…\n$ MaritalStatusID            <int> 0, 1, 1, 1, 2, 0, 0, 4, 0, 2, 1, 1, 2, 0, 2…\n$ GenderID                   <int> 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1…\n$ EmpStatusID                <int> 1, 5, 5, 1, 5, 1, 1, 1, 3, 1, 5, 5, 1, 1, 5…\n$ DeptID                     <int> 5, 3, 5, 5, 5, 5, 4, 5, 5, 3, 5, 5, 3, 5, 5…\n$ PerfScoreID                <int> 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3…\n$ FromDiversityJobFairID     <int> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0…\n$ Salary                     <int> 62506, 104437, 64955, 64991, 50825, 57568, …\n$ Termd                      <int> 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1…\n$ PositionID                 <int> 19, 27, 20, 19, 19, 19, 24, 19, 19, 14, 19,…\n$ Position                   <chr> \"Production Technician I\", \"Sr. DBA\", \"Prod…\n$ State                      <chr> \"MA\", \"MA\", \"MA\", \"MA\", \"MA\", \"MA\", \"MA\", \"…\n$ Zip                        <int> 1960, 2148, 1810, 1886, 2169, 1844, 2110, 2…\n$ DOB                        <chr> \"07/10/83\", \"05/05/75\", \"09/19/88\", \"09/27/…\n$ Sex                        <chr> \"M \", \"M \", \"F\", \"F\", \"F\", \"F\", \"F\", \"M \", …\n$ MaritalDesc                <chr> \"Single\", \"Married\", \"Married\", \"Married\", …\n$ CitizenDesc                <chr> \"US Citizen\", \"US Citizen\", \"US Citizen\", \"…\n$ HispanicLatino             <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"…\n$ RaceDesc                   <chr> \"White\", \"White\", \"White\", \"White\", \"White\"…\n$ DateofHire                 <chr> \"7/5/2011\", \"3/30/2015\", \"7/5/2011\", \"1/7/2…\n$ DateofTermination          <chr> \"\", \"6/16/2016\", \"9/24/2012\", \"\", \"9/6/2016…\n$ TermReason                 <chr> \"N/A-StillEmployed\", \"career change\", \"hour…\n$ EmploymentStatus           <chr> \"Active\", \"Voluntarily Terminated\", \"Volunt…\n$ Department                 <chr> \"Production       \", \"IT/IS\", \"Production  …\n$ ManagerName                <chr> \"Michael Albert\", \"Simon Roup\", \"Kissy Sull…\n$ ManagerID                  <int> 22, 4, 20, 16, 39, 11, 10, 19, 12, 7, 14, 2…\n$ RecruitmentSource          <chr> \"LinkedIn\", \"Indeed\", \"LinkedIn\", \"Indeed\",…\n$ PerformanceScore           <chr> \"Exceeds\", \"Fully Meets\", \"Fully Meets\", \"F…\n$ EngagementSurvey           <dbl> 4.60, 4.96, 3.02, 4.84, 5.00, 5.00, 3.04, 5…\n$ EmpSatisfaction            <int> 5, 3, 3, 5, 4, 5, 3, 4, 3, 5, 4, 3, 4, 4, 5…\n$ SpecialProjectsCount       <int> 0, 6, 0, 0, 0, 0, 4, 0, 0, 6, 0, 0, 5, 0, 0…\n$ LastPerformanceReview_Date <chr> \"1/17/2019\", \"2/24/2016\", \"5/15/2012\", \"1/3…\n$ DaysLateLast30             <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Absences                   <int> 1, 17, 3, 15, 2, 15, 19, 19, 4, 16, 12, 15,…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#nettverk",
    "href": "datasets.html#nettverk",
    "title": "Appendix A — Datasett",
    "section": "A.10 Nettverk",
    "text": "A.10 Nettverk\n\n\nCode\nload(\"data/networkExample.RData\")\nglimpse(dataset)\n\n\nRows: 926\nColumns: 26\n$ degree               <dbl> 0.006282723, 0.002094241, 0.002094241, 0.00104712…\n$ betweenness          <dbl> 0.0081438885, 0.0020810695, 0.0014569424, 0.00000…\n$ closeness            <dbl> 0.08535931, 0.08049562, 0.08226376, 0.07795282, 0…\n$ transitivity         <dbl> 0.13333333, 0.00000000, 0.00000000, 0.00000000, 0…\n$ triangles            <dbl> 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0…\n$ ChurnNeighbors       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ NonChurnNeighbors    <dbl> 6, 2, 2, 1, 3, 5, 2, 2, 2, 6, 2, 3, 6, 2, 3, 2, 2…\n$ Neighbors            <dbl> 6, 2, 2, 1, 3, 5, 2, 2, 3, 6, 2, 3, 6, 2, 3, 2, 2…\n$ RelationalNeighbor   <dbl> 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.000…\n$ ChurnNeighbors2      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ NonChurnNeighbors2   <dbl> 18, 4, 8, 4, 5, 19, 6, 8, 11, 15, 7, 6, 27, 4, 6,…\n$ RelationalNeighbor2  <dbl> 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0…\n$ degree2              <dbl> 0.026178010, 0.006282723, 0.010471204, 0.00523560…\n$ averageDegree        <dbl> 0.004363002, 0.003141361, 0.005235602, 0.00523560…\n$ averageDegree2       <dbl> 0.004188482, 0.004973822, 0.004581152, 0.00549738…\n$ averageTransitivity  <dbl> 0.13888889, 0.05000000, 0.03333333, 0.10000000, 0…\n$ averageTransitivity2 <dbl> 0.11415344, 0.10833333, 0.22777778, 0.18511905, 0…\n$ averageBetweenness   <dbl> 0.005713676, 0.004259980, 0.008147263, 0.00623771…\n$ averageBetweenness2  <dbl> 0.006733850, 0.008557955, 0.007690396, 0.00625752…\n$ averageTriangles     <dbl> 0.8333333, 0.5000000, 0.5000000, 1.0000000, 0.000…\n$ averageTriangles2    <dbl> 0.7777778, 1.2500000, 0.7500000, 1.7500000, 0.400…\n$ pr_0.85              <dbl> 0.0016432968, 0.0008315249, 0.0006479747, 0.00040…\n$ pr_0.20              <dbl> 0.0011679051, 0.0010706518, 0.0009325680, 0.00088…\n$ perspr_0.85          <dbl> 0.0016432968, 0.0008315249, 0.0006479747, 0.00040…\n$ perspr_0.99          <dbl> 0.0017826047, 0.0006187399, 0.0006012571, 0.00030…\n$ Future               <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#occupational-wage-data",
    "href": "datasets.html#occupational-wage-data",
    "title": "Appendix A — Datasett",
    "section": "A.11 Occupational wage data",
    "text": "A.11 Occupational wage data\n\n\nCode\noes <- readRDS(\"data/oes.rds\")\nclass(oes)\n\n\n[1] \"matrix\" \"array\" \n\n\nCode\nglimpse(oes)\n\n\n num [1:22, 1:15] 70800 50580 60350 56330 49710 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:22] \"Management\" \"Business Operations\" \"Computer Science\" \"Architecture/Engineering\" ...\n  ..$ : chr [1:15] \"2001\" \"2002\" \"2003\" \"2004\" ...\n\n\n\n\n\n\n Download data as rds"
  },
  {
    "objectID": "datasets.html#voters",
    "href": "datasets.html#voters",
    "title": "Appendix A — Datasett",
    "section": "A.12 Voters",
    "text": "A.12 Voters\nData er hentet fra 2016 Views of the Electorate Research Survey gjennomført av Voter study group. Full variabelliste er lastet opp i Canvas, der det står\nAktuell problemstilling er å predikere hvilke velgere som støtter Clinton. En slik klassifisering kan brukes til f.eks. å målrette budskap. En relatert problemstilling er å klustre velgerne for å finne segmenter.\n\n\nCode\nvoters <- read.csv(\"data/voters.csv\")\nglimpse(voters)\n\n\nRows: 6,426\nColumns: 42\n$ RIGGED_SYSTEM_1_2016 <int> 3, 2, 2, 1, 3, 3, 3, 2, 4, 2, 3, 3, 4, 4, 3, 3, 2…\n$ RIGGED_SYSTEM_2_2016 <int> 4, 1, 4, 4, 1, 3, 4, 3, 4, 3, 2, 2, 3, 2, 4, 3, 2…\n$ RIGGED_SYSTEM_3_2016 <int> 1, 3, 1, 1, 3, 2, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 3…\n$ RIGGED_SYSTEM_4_2016 <int> 4, 1, 4, 4, 1, 2, 1, 2, 3, 2, 4, 1, 3, 4, 2, 2, 1…\n$ RIGGED_SYSTEM_5_2016 <int> 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 3, 3, 2, 3, 2…\n$ RIGGED_SYSTEM_6_2016 <int> 2, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2…\n$ track_2016           <int> 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2…\n$ persfinretro_2016    <int> 2, 3, 3, 1, 2, 2, 2, 3, 2, 1, 2, 3, 2, 2, 2, 2, 2…\n$ econtrend_2016       <int> 1, 3, 3, 1, 2, 2, 1, 3, 1, 1, 1, 3, 2, 1, 4, 3, 2…\n$ Americatrend_2016    <int> 1, 1, 1, 3, 3, 1, 2, 3, 2, 1, 3, 3, 2, 1, 1, 3, 1…\n$ futuretrend_2016     <int> 4, 1, 1, 3, 4, 3, 1, 3, 1, 1, 3, 1, 1, 4, 3, 4, 3…\n$ wealth_2016          <int> 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1…\n$ values_culture_2016  <int> 2, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 2, 1, 1, 3, 8, 3…\n$ US_respect_2016      <int> 2, 3, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3…\n$ trustgovt_2016       <int> 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3…\n$ trust_people_2016    <int> 8, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 8, 8, 2, 2…\n$ helpful_people_2016  <int> 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 8, 1, 1…\n$ fair_people_2016     <int> 8, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 8, 2, 1…\n$ imiss_a_2016         <int> 2, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 2, 2, 2…\n$ imiss_b_2016         <int> 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1…\n$ imiss_c_2016         <int> 1, 2, 2, 3, 1, 2, 2, 1, 4, 2, 3, 1, 2, 2, 3, 1, 1…\n$ imiss_d_2016         <int> 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 3…\n$ imiss_e_2016         <int> 1, 1, 3, 1, 1, 3, 1, 2, 1, 1, 2, 2, 4, 1, 4, 2, 1…\n$ imiss_f_2016         <int> 2, 1, 1, 2, 1, 2, 1, 3, 2, 1, 1, 1, 2, 1, 3, 2, 2…\n$ imiss_g_2016         <int> 1, 4, 3, 3, 3, 1, 3, 4, 2, 2, 1, 4, 1, 2, 1, 1, 4…\n$ imiss_h_2016         <int> 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3…\n$ imiss_i_2016         <int> 2, 2, 4, 4, 2, 1, 1, 3, 2, 1, 1, 2, 1, 2, 2, 2, 3…\n$ imiss_j_2016         <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2…\n$ imiss_k_2016         <int> 1, 2, 1, 1, 2, 1, 1, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1…\n$ imiss_l_2016         <int> 1, 4, 1, 2, 4, 1, 1, 3, 1, 1, 1, 4, 2, 1, 1, 1, 3…\n$ imiss_m_2016         <int> 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1…\n$ imiss_n_2016         <int> 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1…\n$ imiss_o_2016         <int> 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1…\n$ imiss_p_2016         <int> 2, 1, 2, 3, 1, 3, 1, 1, 4, 1, 1, 1, 2, 3, 2, 3, 1…\n$ imiss_q_2016         <int> 1, 1, 1, 2, 2, 1, 1, 4, 2, 1, 1, 3, 1, 1, 2, 2, 3…\n$ imiss_r_2016         <int> 2, 1, 1, 2, 1, 2, 1, 2, 4, 2, 2, 1, 3, 2, 2, 2, 1…\n$ imiss_s_2016         <int> 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3…\n$ imiss_t_2016         <int> 1, 1, 3, 3, 1, 1, 3, 4, 1, 1, 1, 3, 1, 3, 1, 1, 3…\n$ imiss_u_2016         <int> 2, 2, 2, 2, 1, 3, 3, 1, 4, 2, 3, 2, 4, 3, 3, 3, 1…\n$ imiss_x_2016         <int> 1, 3, 1, 2, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 2, 3…\n$ imiss_y_2016         <int> 1, 4, 2, 3, 1, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 2, 2…\n$ Clinton_supp         <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\", \"No…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "introduksjon_R.html#rstudio-projects",
    "href": "introduksjon_R.html#rstudio-projects",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.1 Rstudio projects",
    "text": "B.1 Rstudio projects\nDet anbefales sterkt å lage en mappestruktur egnet for Rstudio projects. Hensikten med dette er å ha en hensiktsmessig og ryddig mappestruktur for alt arbeidet ditt. Dette er forklart nærmere i (Wickham and Grolemund 2017), se kapittelet om workflow og særlig avsnittet om projects.\nLag en egen mappe for dette kurset og lag følgende undermapper:\n\nData\nScript\nOutput\nDokumenter\n\nDu kan også lage andre undermapper hvis du vil. Det vil være begrenset behov for å eksportere output, men det er selvsagt mulig."
  },
  {
    "objectID": "introduksjon_R.html#litt-begrepsbruk",
    "href": "introduksjon_R.html#litt-begrepsbruk",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.2 Litt begrepsbruk",
    "text": "B.2 Litt begrepsbruk\nI R er alt du gjør er med funksjoner og alt du gjør noe med er objekter.1\nAltså: Alle datasett som leses inn legger du i et objekt og du bruker ulike funksjoner for å estimere modeller. Men du kan også lagre resultater i nye objekter, som f.eks. resultatet av en regresjonsmodell. Objektene kan altså være av forskjellig type, og hvis du lurer på hva slags objekt du har kan du spørre R om det slik:\n\nclass(dittobjekt)\n\nDu gir objektene et navn som du kan referere til senere. Det spiller ingen rolle hva du kaller objektene, men kan ikke ha mellomrom. Bruk navn som gir en viss mening når du jobber med det.\nDu kan ha mange objekter i arbeidsminnet i R samtidig. Hvis du bruker et navn som er i bruk fra før, så overskriver du det gamle objektet.\nFunksjonene har også et navn og etterfølges av en parentes. Inni parentesen angis funksjonens argumenter. Noen slike argumenter er obligatoriske, mens andre er valgfrie. Ofte vil det være forhåndsvalg til en funksjon slik at du ikke behøver å oppgi mer enn et par ting. Et eksempel er å lese inn data med read.csv(), så trenger du bare angi filbanen til datasettet. Denne funksjonen antar at filen er kommaseparert, men hvis det er brukt semikolon kan du angi det med å legge til argumentet sep = \";\"."
  },
  {
    "objectID": "introduksjon_R.html#lese-inn-data",
    "href": "introduksjon_R.html#lese-inn-data",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.3 Lese inn data",
    "text": "B.3 Lese inn data\nData kommer generelt i mange ulike formater og noen ganger skaper det uforutsette utfordringer med å få data inn i R. I dette kurset er imidlertid dataene i formatene .rds eller .csv.\nAlle datasett laster du ned og lagrer i mappen for data (se forrige avsnitt) og leser inn i R derfra. For å lære mer om innlesning av data, se (Wickham and Grolemund 2017) i kapittelet om data import.\nMerk at csv-filer er tekstfiler der kollonnene er separert med komma eller semikolon. Hvis dataene ser veldig rare ut etter å lest de inn kan det være fordi det var et annet skilletegn enn du trodde.\ncsv-filer kan leses inn med funksjonen read.csv() for komma-separerte filer og read.csv2() for semikolon-separerte filer, mens rds-filer leses med readRDS().\nVær obs på at når man leser inn csv-filer så vil R gjette på hva slags variabeltyper det er. De vil i hovedsak være numeriske, tekst eller factor. I all hovedsak bør tekstvariable tolkes som factor. Dette kan du få til ved å spesifiser det når dataene leses inn slik:\n\nread.csv(\"data/navnpaadata.csv\", stringsAsFactors = TRUE)\n\nSe mer om factor-variable i neste avsnitt."
  },
  {
    "objectID": "introduksjon_R.html#variabeltyper",
    "href": "introduksjon_R.html#variabeltyper",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.4 Variabeltyper",
    "text": "B.4 Variabeltyper\nVariable kan være av forskjellige typer, primært numerisk eller kategoriske. Numeriske kan igjen være heltall eller lagret med et angitt presisjonsnivå (integer, numeric eller double), men forskjellen mellom disse har i praksis ikke noe å si for vårt bruk her. Datovariable er også numeriske, men vi skal ikke jobbe med datoer her.\nKategoriske variable er ‘string’ (dvs en tekst-streng) eller factor. Du kan lese mer om factor-variable i Wickham and Grolemund (2017) i kapittelet om factor. Kort sagt er factor-variable tekst-variable som har en tilhørende underliggende numerisk verdi som gjør at den kan benyttes i modeller og beregninger.\nEt alternativ er å kode om faktorvariable eller tekst-variable til dummy-variable med verdiene 0 eller 1.2"
  },
  {
    "objectID": "introduksjon_R.html#dele-et-datasett-i-training-og-testing",
    "href": "introduksjon_R.html#dele-et-datasett-i-training-og-testing",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.5 Dele et datasett i training og testing?",
    "text": "B.5 Dele et datasett i training og testing?\nVi bruker pakken rsample til å splitte datasettet. Funksjonen initial_split() markerer hvilke observasjoner som er i hvilken del. Så kan du trekke ut disse etterpå med training() og testing()."
  },
  {
    "objectID": "introduksjon_R.html#seed---gjør-koden-eksakt-reproduserbar",
    "href": "introduksjon_R.html#seed---gjør-koden-eksakt-reproduserbar",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.6 Seed - gjør koden eksakt reproduserbar",
    "text": "B.6 Seed - gjør koden eksakt reproduserbar\nEn tilfeldig inndeling som med initial_split() bruker tilfeldige tall som genereres av R. Det finnes ikke helt tilfeldige tall i en datamaskin, det bare ser sånn ut. Det er en slags algoritme som generer disse tallen, og det har et startpunkt som varierer med når du setter den igang. Med andre ord: en tilfeldig inndeling vil bli forskjellig hver eneste gang.\nFunksjonen set.seed() definerer startpunktet for neste sekvens av tilfeldige tall slik at du kan reprodusere nøyaktig samme resultat. Hvis dere jobber sammen på oppgaver er det en fordel å sette samme seed slik at dere kan sammenligne resultatet.\n\nset.seed(42)\n\nDette gjelder for alle funksjoner der det benyttes tilfeldige tall. Det gjelder altså for random forest.\nOBS! Vend deg til å alltid bruke set.seed når du jobber i dette kurset, for du kommer til å trenge det på eksamen! Du kan gjøre ting riktig på eksamen likevel, men da blir ikke resultatene reproduserbare og sensor kan ikke sjekke resultatene. (Dere skal få nøyaktige instruksjoner senere)."
  },
  {
    "objectID": "introduksjon_R.html#prediksjon-med-predict",
    "href": "introduksjon_R.html#prediksjon-med-predict",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.7 Prediksjon med predict()",
    "text": "B.7 Prediksjon med predict()\nDere skal bruke funksjonen predict() ganske mye. Den tar et objekt fra en eller annen modell og predikerer fra denne. Merk at den bruker det objektet dere har lagret resultatene i, ser hva slags modell det er, og predikerer i henhold til det.\nI utgangspunktet bruker den det samme datasettet som modellen ble estimert med. Men kan også predikere på nye data. Da må argumentet newdata = ... angis. Det vil typisk være testing-datasettet eller helt nye observasjoner der du ikke vet utfallet. Det nye datasettet må alle de variablene som vari det opprinnelige datasettet for at det skal funke."
  },
  {
    "objectID": "introduksjon_R.html#bruke-formula-for-utfallsvariable-og-prediktorer",
    "href": "introduksjon_R.html#bruke-formula-for-utfallsvariable-og-prediktorer",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.8 Bruke formula for utfallsvariable og prediktorer",
    "text": "B.8 Bruke formula for utfallsvariable og prediktorer\nDe modellen vi skal bruke her angir utfallsvariabel og prediktorer med en formula som angir omtrent slik: utfallsvariabel ~ prediktor1 + prediktor2. Dette tilsvarer altså å skrive \\(y = x1 + x2\\). For lineær regresjon vil den så estimere de tilhørende regresjonsparametrene \\(\\alpha\\), \\(\\beta_1\\) og \\(\\beta_2\\).\nFor andre modeller der det ikke skal estimeres parametere på samme måte vil man angi variablene på samme måte.\nFor regresjon kan man angi spesifikasjonen som følger:\n\nflere variable: y ~ x + z + k + m\ninkludere alle variable: y ~ .\nannengradsledd: y ~ x + I(x^2)\ntredjegradsledd: y ~ x + I(x^2) + I(x^3)\ninteraksjoner: y ~ x + z + x*z\n\nDisse kan også kombineres."
  },
  {
    "objectID": "introduksjon_R.html#databehandling-dplyr-verb-tidyverse",
    "href": "introduksjon_R.html#databehandling-dplyr-verb-tidyverse",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.9 Databehandling: dplyr-verb / tidyverse",
    "text": "B.9 Databehandling: dplyr-verb / tidyverse\nDet som kalles tidyverse er en samling R-pakker som til sammen danner et konsistent system for databehandling og grafikk. Hvis du bruker R uten å laste noen pakker, kalles dette base-R. Tidyverse er slik sett en dialekt av R.3\nDatabehandling med dplyr (fra tidyverse) har som hovedgrep noen verb som kan settes sammen i lengre uttrykk.\n\nmutate() brukes til å lage nye variable eller endre på variable\nfilter() brukes til å filtrere data, f.eks. velge ut en undergruppe\nselect() brukes til å velge ut variable - eller velge bort variable\nsummarise() brukes til å summere verdier, f.eks. gjennomsnitt og standardavvik\ngroup_by() brukes hvis man skal summere over grupper av observasjoner med summarise() eller mutate().\n\narrange() sorterer et datasett\n\nAlle disse verbene starter med at man angir hvilket objekt man skal gjøre noe med (dvs datasett) og deretter hva man vil gjøre.\nFor eksempel kan du lage en ny variabel som er summen av variable med navn X og Y slik:\n\nnyedata <- mutate(dinedata, sumXY = X + y)\n\nDu kan lese mer om disse verbene i R4DS (Wickham and Grolemund 2017) kapittelet Transform\nI dette kurset skal vi ofte lage en ny variabel med predict() og det gjør vi da inni en mutate(), omtrentlig slik:\n\nendretdata <- dinedata %>% \n  mutate( nyvariabel = predict(modellobjekt))\n\nHer skal resultatet være et kopi av det opprinnelige datasettet, dinedata, som lages i et nytt objekt endretdata, der den andre linjen legger til en ny variabel som inneholder predikerte verdier fra en modell lagret i modellobjekt.\n\nB.9.1 Hva gjør ‘pipe-operatoren’ %>% ??\nDu kan sette sammen flere kombinsjoner av mutate(), select() og andre dplyr-verb med %>%. Les mer om den i R4DS (Wickham and Grolemund 2017) i et eget avsnitt om pipes.\nEnkelt sagt tar %>% og legger det som er til venstre over som første argument i neste dplyr-verb. Dermed kan man sette sammen en rekke av dplyr-verb der du både filtrerer, lager nye variable, summerer osv."
  },
  {
    "objectID": "introduksjon_R.html#grafikk-quickn-dirty-vs-ggplot",
    "href": "introduksjon_R.html#grafikk-quickn-dirty-vs-ggplot",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.10 Grafikk: quick’n dirty vs ggplot",
    "text": "B.10 Grafikk: quick’n dirty vs ggplot\nEn rekke modeller har noen standard funksjoner for å plotte. Funksjonen plot() vil kjenne igjen hva slags objekt det er snakk om og så lage en viss type plot. Bruker du dette på et objekt for lineær regresjon får du et annet type plot enn hvis du gjør det på et randomForest-objekt. Dette kan være helt utmerket for en kjapp titt på resultatene, men du har litt mindre kontroll på hva du ber om. Grafikken er ganske pen, men kanskje ikke publiseringsklar.\nI en del eksempler her brukes ggplot(). Dette er for avansert grafikk og er det som brukes i standard statistikkurs på bachelornivå på SV-fakultetet (på alle fag, tror jeg). Det er en viktig grunn til at det brukes her også. For en del visualisering av tre-baserte metoder er det vesentlig lettere å bruke spesialiserte funksjoner via plot(). Men for all del: ggplot() kan lage disse figurene også, det bare krever mer arbeid enn vi prioriterer her.\nDu kan lære mer om ggplot() i R4DS (Wickham and Grolemund 2017) i kapittelet om visualisering."
  },
  {
    "objectID": "introduksjon_R.html#hjelp-filer-og-dokumentasjon",
    "href": "introduksjon_R.html#hjelp-filer-og-dokumentasjon",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.11 Hjelp-filer og dokumentasjon",
    "text": "B.11 Hjelp-filer og dokumentasjon\nAlle funksjoner i R har en hjelp-fil som inneholder syntax, forklaring av argumentene, noen detaljer (ved behov), og eksempler. For å få tilgang til denne setter du et spørsmålstegn foran funksjonsnavnet slik:\n\n?confusionMatrix\n\nHjelpfilene kan være vanskelige å forstå hvordan fungerer. Det er ikke alltid selvforklarende, for å si det forsiktig. Men det viktige er at du ser hvilke argumenter som hører til funksjonen og hva de betyr.\n\n\n\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley."
  }
]