[
  {
    "objectID": "intro_fairness.html#hva-slags-rettferdighet",
    "href": "intro_fairness.html#hva-slags-rettferdighet",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.1 Hva slags rettferdighet",
    "text": "4.1 Hva slags rettferdighet\nI denne settingen kan rettferdighet kommer i betraktning på flere måter, herunder følgende:\n\nI hvilken grad maskiner vs mennesker tar avgjørelser, og herunder mulighet til å bli hørt og legge frem sin sak\nI hvilken grad dataene algoritmen er trent opp på inneholder skjevheter i utgangspunktet som så reproduseres i videre implementering\nI hvilken grad sluttresultatet har rimelig presisjon og akseptable feilrater, herunder vurdering av asymetriske feilrater\nI hvilken grad forrige punkt er avpasset mot hvilke tiltak man så setter i verk\nI hvilken grad feilrater og presisjon varierer systematisk med undergrupper i populasjonen\n\nDet er nok av ting å tak i her, men vi skal her fokusere på det som kan tallfestes gitt den modellen man har. Men for all del: Hvis datakvaliteten er det begrenset hvor bra det kan bli uansett. Selv om kjente skjevheter i dataene kan i prinsippet motarbeides, så er det vel i praksis slik at en skjevhet kommer sjelden alene?\nVurderinger av overordnet feilrater er et gjennomgående tema, så vi starter med det. Deretter skal vi se på mål på skjevheter over undergrupper. Prinsippet er relativt enkelt, uten at vurderingene blir enkle av den grunn."
  },
  {
    "objectID": "intro_fairness.html#mer-confusion-matrix",
    "href": "intro_fairness.html#mer-confusion-matrix",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.2 Mer confusion matrix",
    "text": "4.2 Mer confusion matrix\nEt utgangspunkt er det vi kaller confusion matrix. Det er rett og slett en krysstabell der vi sammenholder predikert og observert utfall. Å lage en slik tabell avhenger ikke av metoden vi bruker, bare at vi kan sammenlignet prediksjon med faktisk utfall.\nVi bruker eksempelet fra forrige kapittel med logistisk regresjon.\n\nest_multlogit &lt;- glm(Attrition ~ ., data = training, family = \"binomial\")\nsummary(est_multlogit)\n\n\nCall:\nglm(formula = Attrition ~ ., family = \"binomial\", data = training)\n\nCoefficients:\n                                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                      -1.090e+01  7.450e+02  -0.015 0.988322    \nAge                              -3.671e-02  1.637e-02  -2.243 0.024906 *  \nBusinessTravelTravel_Frequently   1.627e+00  4.663e-01   3.490 0.000483 ***\nBusinessTravelTravel_Rarely       8.847e-01  4.265e-01   2.074 0.038070 *  \nDailyRate                        -3.249e-04  2.657e-04  -1.223 0.221450    \nDepartmentResearch & Development  1.303e+01  7.450e+02   0.017 0.986048    \nDepartmentSales                   1.348e+01  7.450e+02   0.018 0.985565    \nDistanceFromHome                  4.325e-02  1.308e-02   3.307 0.000944 ***\nEducation                         2.259e-03  1.047e-01   0.022 0.982789    \nEducationFieldLife Sciences      -8.614e-01  1.036e+00  -0.832 0.405637    \nEducationFieldMarketing          -2.986e-01  1.085e+00  -0.275 0.783245    \nEducationFieldMedical            -9.341e-01  1.037e+00  -0.901 0.367673    \nEducationFieldOther              -8.090e-01  1.106e+00  -0.731 0.464508    \nEducationFieldTechnical Degree    6.014e-02  1.057e+00   0.057 0.954635    \nEmployeeNumber                   -3.297e-04  1.818e-04  -1.814 0.069727 .  \nEnvironmentSatisfaction          -4.976e-01  9.990e-02  -4.981 6.31e-07 ***\nGenderMale                        2.224e-01  2.157e-01   1.031 0.302405    \nHourlyRate                       -3.877e-03  5.392e-03  -0.719 0.472136    \nJobInvolvement                   -5.454e-01  1.458e-01  -3.741 0.000183 ***\nJobLevel                         -1.437e-02  3.834e-01  -0.037 0.970101    \nJobRoleHuman Resources            1.413e+01  7.450e+02   0.019 0.984868    \nJobRoleLaboratory Technician      1.579e+00  5.597e-01   2.822 0.004773 ** \nJobRoleManager                   -1.613e+00  1.280e+00  -1.260 0.207596    \nJobRoleManufacturing Director    -2.403e-01  6.135e-01  -0.392 0.695291    \nJobRoleResearch Director         -2.531e+00  1.243e+00  -2.035 0.041806 *  \nJobRoleResearch Scientist         3.845e-01  5.748e-01   0.669 0.503513    \nJobRoleSales Executive            3.167e-01  1.614e+00   0.196 0.844462    \nJobRoleSales Representative       1.478e+00  1.662e+00   0.890 0.373555    \nJobSatisfaction                  -3.238e-01  9.696e-02  -3.340 0.000839 ***\nMaritalStatusMarried              3.633e-01  3.130e-01   1.161 0.245800    \nMaritalStatusSingle               9.102e-01  4.057e-01   2.243 0.024875 *  \nMonthlyIncome                     9.730e-05  9.890e-05   0.984 0.325190    \nMonthlyRate                       1.173e-05  1.499e-05   0.783 0.433906    \nNumCompaniesWorked                1.705e-01  4.652e-02   3.665 0.000248 ***\nOverTimeYes                       1.892e+00  2.308e-01   8.195 2.50e-16 ***\nPercentSalaryHike                -6.513e-02  4.714e-02  -1.382 0.167122    \nPerformanceRating                 6.772e-01  4.816e-01   1.406 0.159676    \nRelationshipSatisfaction         -3.888e-01  9.884e-02  -3.934 8.37e-05 ***\nStockOptionLevel                 -2.737e-01  1.822e-01  -1.502 0.133202    \nTotalWorkingYears                -6.528e-02  3.587e-02  -1.820 0.068731 .  \nTrainingTimesLastYear            -2.136e-01  8.571e-02  -2.492 0.012712 *  \nWorkLifeBalance                  -2.117e-01  1.469e-01  -1.441 0.149470    \nYearsAtCompany                    6.602e-02  4.876e-02   1.354 0.175764    \nYearsInCurrentRole               -1.021e-01  5.548e-02  -1.840 0.065748 .  \nYearsSinceLastPromotion           2.056e-01  5.166e-02   3.979 6.91e-05 ***\nYearsWithCurrManager             -1.933e-01  6.078e-02  -3.180 0.001473 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 944.39  on 1101  degrees of freedom\nResidual deviance: 616.66  on 1056  degrees of freedom\nAIC: 708.66\n\nNumber of Fisher Scoring iterations: 15\n\n\nSå kan vi gjøre en prediksjon på testing-datasettet og lagre resultatet i et nytt objekt. Vi gjør en klassifisering ved å bestemme en cut-off på f.eks. en sannsynligheten over 50%.\n\nattrition_test &lt;- testing %&gt;% \n  mutate(prob = predict(est_multlogit, newdata = testing, type = \"response\")) %&gt;% \n    mutate(attrition_class = as.factor(ifelse(prob &lt; .5, \"No\", \"Yes\")))\n\nSå kan vi lage confusion matrix som følger. Vi bruker funksjonen confusionMatrix() for at diverse mål skal blir regnet ut automatisk for oss, men du kan godt regne ut dette for hånd også (hvis du gidder).\n\ncm &lt;- confusionMatrix(attrition_test$Attrition, attrition_test$attrition_class, positive = \"Yes\")\n\ncm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  288  12\n       Yes  42  26\n                                          \n               Accuracy : 0.8533          \n                 95% CI : (0.8129, 0.8878)\n    No Information Rate : 0.8967          \n    P-Value [Acc &gt; NIR] : 0.9965          \n                                          \n                  Kappa : 0.4128          \n                                          \n Mcnemar's Test P-Value : 7.933e-05       \n                                          \n            Sensitivity : 0.68421         \n            Specificity : 0.87273         \n         Pos Pred Value : 0.38235         \n         Neg Pred Value : 0.96000         \n             Prevalence : 0.10326         \n         Detection Rate : 0.07065         \n   Detection Prevalence : 0.18478         \n      Balanced Accuracy : 0.77847         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nHvorvidt dette er “rettferdig” eller ikke kommer jo an på hva man skal gjøre med denne prediksjonen. Så det er jo en første vurdering. Synes man feilratene er ok? Er evt. konsekvensene av å ikke gjøre noe ok?\nI dette eksempelet er positive predictive value 0.38 som altså er andelen av de som er predikert som positive som er rett. Det betyr at hvis vi setter i verk tiltak mot alle som er predikert positive, så vil 0.62 være bortkastet. På den annen side, vil 0.68 av de som faktisk er positive fanges opp (sensitivity).1"
  },
  {
    "objectID": "intro_fairness.html#mål-på-fairness",
    "href": "intro_fairness.html#mål-på-fairness",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.3 Mål på fairness",
    "text": "4.3 Mål på fairness\n\n4.3.1 Predictive rate parity\nOvenfor så vi blant annet at “positive predicted value” , altså andelen sanne positive av alle predikerte positive, er 0.382.\nMen det er ulike typer jobber i denne bedriften. Her er fordelingen for test-datasettet:\n\n\nWarning: package 'gtsummary' was built under R version 4.3.3\n\n\n#StandWithUkraine\n\n\n\n\n\n\n  \n    \n      Characteristic\n      Overall, N = 3681\n      No, N = 3001\n      Yes, N = 681\n    \n  \n  \n    JobRole\n\n\n\n        Healthcare Representative\n32 (100%)\n31 (97%)\n1 (3.1%)\n        Human Resources\n14 (100%)\n11 (79%)\n3 (21%)\n        Laboratory Technician\n64 (100%)\n47 (73%)\n17 (27%)\n        Manager\n27 (100%)\n24 (89%)\n3 (11%)\n        Manufacturing Director\n32 (100%)\n29 (91%)\n3 (9.4%)\n        Research Director\n18 (100%)\n17 (94%)\n1 (5.6%)\n        Research Scientist\n77 (100%)\n59 (77%)\n18 (23%)\n        Sales Executive\n84 (100%)\n70 (83%)\n14 (17%)\n        Sales Representative\n20 (100%)\n12 (60%)\n8 (40%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nFor illustrasjonens skyld kan vi da dele inn datamaterialet i to deler: lab-teknikkere og resten. For hver gruppe kan vi så lage en confusion matrix og undersøke verdiene.\n\nlabTech &lt;- attrition_test %&gt;% \n  filter(JobRole %in% c(\"Laboratory Technician\"))\n\nothers &lt;- attrition_test %&gt;% \n  filter( !(JobRole %in% c(\"Laboratory Technician\") ))\n\ncm1 &lt;- confusionMatrix(labTech$Attrition, labTech$attrition_class, positive = \"Yes\")\n\ncm2 &lt;- confusionMatrix(others$Attrition, others$attrition_class, positive = \"Yes\")\n\ncm1 \n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  39   8\n       Yes 10   7\n                                         \n               Accuracy : 0.7188         \n                 95% CI : (0.5924, 0.824)\n    No Information Rate : 0.7656         \n    P-Value [Acc &gt; NIR] : 0.8490         \n                                         \n                  Kappa : 0.251          \n                                         \n Mcnemar's Test P-Value : 0.8137         \n                                         \n            Sensitivity : 0.4667         \n            Specificity : 0.7959         \n         Pos Pred Value : 0.4118         \n         Neg Pred Value : 0.8298         \n             Prevalence : 0.2344         \n         Detection Rate : 0.1094         \n   Detection Prevalence : 0.2656         \n      Balanced Accuracy : 0.6313         \n                                         \n       'Positive' Class : Yes            \n                                         \n\ncm2\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  249   4\n       Yes  32  19\n                                          \n               Accuracy : 0.8816          \n                 95% CI : (0.8398, 0.9157)\n    No Information Rate : 0.9243          \n    P-Value [Acc &gt; NIR] : 0.997           \n                                          \n                  Kappa : 0.4569          \n                                          \n Mcnemar's Test P-Value : 6.795e-06       \n                                          \n            Sensitivity : 0.82609         \n            Specificity : 0.88612         \n         Pos Pred Value : 0.37255         \n         Neg Pred Value : 0.98419         \n             Prevalence : 0.07566         \n         Detection Rate : 0.06250         \n   Detection Prevalence : 0.16776         \n      Balanced Accuracy : 0.85610         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nPositive predicted value for lab-teknikker er 0.412 og for resten 0.373.\nForholdstallet mellom disse er 0.9047619, alså nesten likt. Slik sett kan vi si at modellen er rettferdig på dette målet ved at disse to gruppene er like.\nMen hvis du sjekker output fra confusionMatrix ovenfor, så er jo ikke alle tallene like. Så det kommer an på hvilke mål du sammenligner.\nPakken fairness gjør en tilsvarende beregning for deg og kan gi resultatet grafisk. Her er sammenligning av positive predicted value gjort for alle grupper av jobber:\n\npred_rate_parity(data = attrition_test,\n                 outcome = \"Attrition\", \n                 group = \"JobRole\", \n                 preds = \"attrition_class\", \n                 base = \"Laboratory Technician\"\n                 )\n\n$Metric\n                       Laboratory Technician Healthcare Representative\nPrecision                          0.4666667                  1.000000\nPredictive Rate Parity             1.0000000                  2.142857\nGroup size                        64.0000000                 32.000000\n                       Human Resources Manager Manufacturing Director\nPrecision                           NA      NA                     NA\nPredictive Rate Parity              NA      NA                     NA\nGroup size                          14      27                     32\n                       Research Director Research Scientist Sales Executive\nPrecision                             NA           1.000000       0.8181818\nPredictive Rate Parity                NA           2.142857       1.7532468\nGroup size                            18          77.000000      84.0000000\n                       Sales Representative\nPrecision                          0.600000\nPredictive Rate Parity             1.285714\nGroup size                        20.000000\n\n$Metric_plot\n\n\n\n\n\nNå er det vesentig større forskjeller. Utvilsomt er grunnen at gruppen av ‘andre’ var sammensatt av veldig ulike grupper som var veldig forskjellig innbyrdes, men som jevnet hverandre ut i snitt. Noen av disse gruppene var dessuten små.\nMan kan mene ulikt om slikt, men det er i hvert fall ikke likt på tvers av grupper.\nMen hvilke konsekvenser har dette? Treffsikkerheten er da lavere for laboratorie-teknikkerne enn for de andre gruppene. Ikke sikkert det er så nøye.\nMen la oss si at man bestemmer seg for å gi en solid lønnsforhøyelse (eller andre goder) til de man tror er i fare for å bytte jobb. Da vil bedriften bruke unødig mye midler på lab-teknikkerne (dvs. relativt mange falske positive) relativt til andre grupper .\nMen man kunne også tenke seg et negativt tiltak: de som er predikert å ville slutte vil ikke få lønnsforhøyelse eller andre goder. Hvis vurderingen er at de vil slutte uansett, så er det bortkastede ressurser. Flere blant lab-teknikerne ville da urettmessig få avslag.\nOk. Det ville uansett være en lite klok arbeidsgiver som baserer seg kun på dette. Det finnes bedre måter å beholde arbeidstakerne sine på. Men man kan tenke seg andre situasjoner der konsekvensene er tydeligere: Hva om det var en automatisert sjekk av kredittverdighet for å få boliglån? Eller kanskje opptak til et lederprogram? Eller risikovurdering for prøveløslatelse fra fengsel?\n\n\n4.3.2 Equalized odds\nEn annen variant er å se på andelen sanne positive av andelen som faktisk er positive. Altså: andelen som er predikert å slutte av de som faktisk slutter.\n(I følgende kode er det lagt på [[2]] på slutten for å bare vise figuren, altså droppe tabellen. Akkurat den dele av koden er ikke viktig).\n\nequal_odds(data = attrition_test,\n                 outcome = \"Attrition\", \n                 group = \"JobRole\", \n                 preds = \"attrition_class\", \n                 base = \"Laboratory Technician\"\n                 )[[2]] \n\n\n\n\n\n\n4.3.3 False positive rate parity\nEr falske positive rate i ulike grupper lik?\n\nfpr_parity(data = attrition_test,\n                 outcome = \"Attrition\", \n                 group = \"JobRole\", \n                 preds = \"attrition_class\", \n                 base = \"Laboratory Technician\"\n                 )[[2]]"
  },
  {
    "objectID": "intro_fairness.html#litt-oppsummerende",
    "href": "intro_fairness.html#litt-oppsummerende",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.4 Litt oppsummerende",
    "text": "4.4 Litt oppsummerende\nDen R-pakken vi bruker her har en hel rekke ulike mål innebygget. Se en oversikt på pakkens vignette.\nHvilket mål som er viktigst er det derimot ikke noe klart svar på. Det kommer an på hva man har tenkt til å bruke prediksjonen til, hvilke konsekvenser tiltaket har, og hvilke konsekvenser det har å ikke gjøre noe. Disse konsekvensene kan vurderes forskjellig for personer etter om det er riktig eller feil prediksjon.\nDet du må ta stilling til er egentlig hvor viktig du synes likebehandling er! Ofte er jo det åpenbart veldig viktig.\nSå bør det nevnes at noen ganger ville man gjort noe uansett. Altså gjort de samme tiltakene basert på skjønn eller andre typer vurderinger. Det vil også ha feilrater og forskjeller mellom undergrupper i slike tilfeller, selv om man ikke har et oppsett som gir testing-data å estimere dette på. Det betyr at du ikke bare må ta stilling til om algoritmen er “fair” eller ikke, men også om den er mer eller mindre “fair” enn den alternative fremgangsmåten."
  },
  {
    "objectID": "intro_fairness.html#oppgaver",
    "href": "intro_fairness.html#oppgaver",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.5 Oppgaver",
    "text": "4.5 Oppgaver\n\nExercise 4.1 Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer.\n\n\nExercise 4.2 Regn ut minst tre ulike mål på fairness og velg selv over hvilke grupper. Gi en forklaring på hva hver av dem betyr.\n\n\nExercise 4.3 Det er mange muligheter her: ulike mål og flere grupper. Man kan også kombinere grupper på flere måter. Gjør følgende vurderinger:\n\nEr det rimelig å gjøre en prediksjon som gir like resultater på tvers av alle mål og grupper? Kan du i det hele tatt få en “fair” modell?\nHvilke mål på “fairness” vil du si er viktigst i dette eksempelet? Hvorfor?\n\n\n\nExercise 4.4 Kanskje hjelper det å estimere en annen modell? Estimer en ny logistisk regresjon, men velg bare et fåtall variable som du velger selv. Hold det enkelt i første omgang. Se på resultatene og vurder:\n\nBle accuracy bedre eller verre?\nBle resultatet mer “fair”?\n\n\n\nExercise 4.5 Velg et nytt datasett, gjør en prediksjon med logistisk regresjon og regn ut mål på “fairness” igjen. Gjør tilsvarende som over."
  },
  {
    "objectID": "intro_fairness.html#refleksjonsoppgaver",
    "href": "intro_fairness.html#refleksjonsoppgaver",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.6 Refleksjonsoppgaver",
    "text": "4.6 Refleksjonsoppgaver\n\nExercise 4.6 Studien til Caspi et al. (2017) bruker regresjon for å predikere hvem som tilhører den gruppen med konsentrasjon av sosiale problemer. (Det er en litt annen type modell enn logisk regresjon, men det spiller egentlig liten rolle). Diskuter følgende:\n\nHva slags informasjon synes du mangler for å vurdere treffsikkerheten på prediksjonsmodellen?\nHva slags tiltak er det tenkt å settes i verk når man har identifisert hvem som får problemer i voksen alder?\nBasert på hvordan prediksjonen skal brukes hva tenker du er akseptable feilrater?\nEr det behov for å vurdere “fairness” grundigere her?\n\n\n\nExercise 4.7 Studien til Berk, Sorenson, and Barnes (2016) bruker andre typer modeller enn vi har sett på til nå. Se bort fra akkurat det tekniske i modeller og justeringer, men se diskusjonen av resultatet presentert som confusion matrix. Se for deg at dette blir de faktiske resultatene for fengsling eller ikke-fengsling og vurder følgende:\n\nSynes du at forholdstallet 1 til 10 for falske positive/negative er ok i denne settingen? Hvis du skal foreslå noe annet, hva vil du si da?\nEr det grunn til å tro at man bør undersøke “fairness” grundigere her? I så fall: hvilke undergrupper mener du er mest viktig å undersøke dette for?\n\n\n\n\n\n\n\n\nBerk, Richard A., Susan B. Sorenson, and Geoffrey Barnes. 2016. “Forecasting Domestic Violence: A Machine Learning Approach to Help Inform Arraignment Decisions.” Journal of Empirical Legal Studies 13: 94–115. https://doi.org/10.1111/jels.12098.\n\n\nCaspi, Avshalom, Renate M. Houts, Daniel W. Belsky, Honalee Harrington, Sean Hogan, Sandhya Ramrakha, Richie Poulton, and Terrie E. Moffitt. 2017. “Childhood Forecasting of a Small Segment of the Population with Large Economic Burden.” Nature Human Behavior 1 (5): 223–40. https://doi.org/https://doi-org.ezproxy.uio.no/10.1038/s41562-016-0005."
  },
  {
    "objectID": "intro_fairness.html#footnotes",
    "href": "intro_fairness.html#footnotes",
    "title": "4  En lett introduksjon til fairness",
    "section": "",
    "text": "For akkurat dette kurset er ikke disse tekniske begrepene som sensitivity, specificity osv sentrale. (Emneansvarlig går surr i disse selv). Men det forventes at du skal kunne formulere det på tilsvarende måte som her. Men du må huske accuracy, som er den enkleste.↩︎"
  },
  {
    "objectID": "cart.html#tuningpruning",
    "href": "cart.html#tuningpruning",
    "title": "5  Klassifikasjonstrær",
    "section": "5.1 Tuning/pruning",
    "text": "5.1 Tuning/pruning\nVi har vært inne på tidligere at vi kan styre hvordan algoritmen fungerer. Det er noen parametres om styrer prosessen, og disse kan vi justere. Her tar vi for oss de viktiste, men det finnes flere.\nKort fortalt styrer disse parametrene hvor komplekse trærne kan bli. Husk nå fra tidligere kapittel: mer kompleks modell gir bedre tilpassning til trainingdata - men kan gi dårligere tilpassning til testingdata. Målet er altså å finne en slags balansert kompleksitet. Med klassifikasjonstrær påvirker vi dette mer direkte enn ved regresjonsmodeller.\nNå er arbeidsflyten slik at man skrur litt på disse parametrene, sjekker resultatet og justerer på nytt og sjekker… osv. Da er det viktig at bruker trainingdata! Ikke bruke testingdata før du er rimelig fornøyd med resultatet. Først da bruker du testingdata.\n\n5.1.1 Bruk av minsplit = ...\nParameteren minsplit kontrollerer det miste antallet observasjoner som kan være i en node for at en ny split skal testes. Hvis det blir for få observasjoner i en node, så stopper splitten der. Forvalget for denne parameteren er 20, så hvis f.eks. en node har 19 observasjoner, så stopper forgreningen der.\nHer er et eksempel for å illustrere. Ved å sette minsplit = 50, som en god del høyere enn forvalget på 20, vil man få et mindre komplekst tre.\n\ncredit_tree &lt;- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing, \n                     data=training, method=\"class\", minsplit = 50)\n\nrpart.plot(credit_tree)\n\n\n\n\n\n\n5.1.2 Bruk av minbucket = ...\nParameterne minbucket = ... styrer hvor mange observasjoner det minst må være i den siste noden. Forvalget er en 1/3 av minsplit, altså 7 hvis man ikke har endret på minsplit. Hvis man endrer minsplit, så endres minbucket også automatisk. Men du kan altså også styre minbucket direkte også.\nDette ligner på hva minsplit gjør, men mens minsplit kan godt splitte en node med 20 i to grupper med 1 og 19, så vil minbucket ikke tillate en ny split med mindre den ene gruppen har minst 7.\nHer er et eksempel der det er satt minbucket = 15. Det skaper et mindre komplekst tre, og et lavere tall ville kunne gi et mer komplekst tre. Men det er andre valg som også spiller inn (forvalgte sådan) slik at du ikke nødvendigvis får et veldig mye mer komplisert tre ved å angi en lav verdi.\n\ncredit_tree &lt;- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing, \n                     data=training, method=\"class\", minbucket = 15)\n\nrpart.plot(credit_tree)\n\n\n\n\n\n\n5.1.3 Bruk av maxdepth = ...\nParameteren maxdepth setter rett og slett en grense for hvor mange splitter det kan gjøres i hver forgrening. Her er et eksempel der dybden på treet settes til maks 4 og treet får da altså ingen flere forgreininger etter det.\n\ncredit_tree &lt;- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing, \n                     data=training, method=\"class\", maxdepth = 4)\n\nrpart.plot(credit_tree)\n\n\n\n\n\n\n5.1.4 Bruk av cp = ...\ncp er complexity parameter som setter et krav på hvor mye hver split skal bidra til modellens tilpassning til data. Hvis en enkelt split ikke bidrar med mer enn dette, så stopper det der. Her angir du et tall mellom 0 og 1, der 0 er å tillate mest mulig split. Forvalget er 0.01. Her er et eksempel med tillate mest mulig compleksitet, så setter cp til et veldig lavt tall slik at denne restriksjonen blir tilnærmet borte.\n\ncredit_tree &lt;- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing, \n                     data=training, method=\"class\", cp = .00001)\n\nrpart.plot(credit_tree)\n\n\n\n\n\n\n5.1.5 Sette delene sammen\nDu kan så kombinere disse parametrene. Eller: du kan faktisk ikke unngå å kombinere dem, for alle har forvalgte verdier. Det betyr at hvis du ikke justerer på dem, så bruker du jo de forvalgte. Forskjellen er bare om du har tatt et eksplisitt valg eller overlater det hele til softwaren. Når det er sagt er jo de forvalgte verdiene ikke helt dumme.\nDu har sett at cp kan gi veldig komplekse trær, og du må være innstilt på at dette skaper overfitting. Det kan være at klassifikasjonstreet ditt i stor grad fanger opp støy, så et for lavt cp er neppe lurt. Men du kan f.eks. sette cp lavt og justere med de andre parametrene. Du har nå altså en del verktøy tilgjengelig for å styre resultatet. Altså i tillegg til å velge hvilke variable du tar med i modellen i utgangspunktet.\nHer er et eksempel der alle ovennevnte parametere er angitt. Merk at dette ikke nødvendigvis er et spesielt godt tre, men er for illustrasjonens skyld. Du kan selv prøve deg frem og se hvordan resultatet endres når du justerer de enkelte parametrene.\n\ncredit_tree &lt;- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing, \n                     data=training, method=\"class\", \n                     cp = .005, minbucket = 5, minsplit = 10, maxdepth = 7)\n\nrpart.plot(credit_tree)\n\n\n\n\n\n\n5.1.6 Pruning\nEn relatert teknikk er å beskjære treet basert på cp. Altså, når du har bygget et tre som du tenker er for komplekst, så kan du beskjære grenene slik at de minst viktige grenene kuttes. Algoritmen starter da nederst og kutter steg for steg til et mindre komplekst tre.3 Funksjonen prune() gjør jobben, og du må angi et tidligere bygget tre som første argument og deretter en angitt verdi for cp.\nHer er et eksempel der forrige tre beskjæres med en høyere verdi for cp.\n\npruned_credit_tree &lt;- prune(credit_tree, cp = .015)\nrpart.plot(pruned_credit_tree)\n\n\n\n\nMen altså: det er ikke meningen at man skal rote rundt på måfå med disse justeringene! Det vil nok være lurt å starte med forvalgte verdier, sjekke resultatet og så se om man ønsker justere noe. Det kan være for å bedre “accuracy” eller et annet mål basert på confusion matrix."
  },
  {
    "objectID": "cart.html#asymetriske-kostnader-med-loss-matrix-med-cost-...",
    "href": "cart.html#asymetriske-kostnader-med-loss-matrix-med-cost-...",
    "title": "5  Klassifikasjonstrær",
    "section": "5.2 Asymetriske kostnader med loss matrix med cost = ...",
    "text": "5.2 Asymetriske kostnader med loss matrix med cost = ...\nLoss matrix er forklart nøyere hos (Berk 2016) og krever litt innsats å venne hodet til å forstå. Utgangspunktet er følgende matrise for om observasjoner er klassifisert rett eller feil.\n\\[\nloss = \\begin{bmatrix}\n               TN & FN \\\\\n               FP & TP\n        \\end{bmatrix}\n\\]\nHver posisjon i matrisen kan gis et tall. Forvalget i rpart() er å vekte alle disse utfallene likt og da ser matrisen slik ut: \\[\nloss = \\begin{bmatrix}\n               0 & 0 \\\\\n               0 & 0\n        \\end{bmatrix}\n\\] Tallene angir vekter i følgende rekkefølge i øverste rad: sanne negative, falske negative, og i nederste rad: falske positive og sanne positive. Altså som angitt over.\nVi setter alltid vektingen av sanne positive og sanne negative til 0. Det er feilene som evt. skal vektes. Første steg er dermed å velge hvordan man vil vekte utfallet. La oss si at vi ønsker å angi at falske positive skal veie tyngre enn falske negative, med en faktor på 4 kan det gjøres ved å spesifisere matrisen som følger:\n\\[\nloss = \\begin{bmatrix}\n               0 & 1 \\\\\n               4 & 0\n        \\end{bmatrix}\n\\]\nI R gjør vi dette ved å lage en matrise. Rekken med tall angis fra øvre venstre hjørne og mot høye, og så samme fra nedre venstre hjørne. Matrisen lagres i et eget objekt, som jeg her har kalt for lossm.\n\nlossm &lt;- matrix(c(0, 4, 1, 0), ncol=2)\nlossm\n\n     [,1] [,2]\n[1,]    0    1\n[2,]    4    0\n\n\nNå kan loss matrisen angis i rpart() som et element under parms = ....\n\nrpart_loss &lt;- rpart(default ~ . , \n                  data = training, \n                  parms=list(loss = lossm),\n                  method = \"class\")\n\nDa kan man se på resultatet igjen på samme måte som før.\n\nrpart.plot(rpart_loss)"
  },
  {
    "objectID": "cart.html#fairness-omigjen",
    "href": "cart.html#fairness-omigjen",
    "title": "5  Klassifikasjonstrær",
    "section": "5.3 Fairness omigjen",
    "text": "5.3 Fairness omigjen\nNå er jo algoritmen endret, så confusion matrix er også endret. Da vil nødvendigvis mål på fairness ha endret seg også. Dette bør sjekkes, og evt gå tilbake og justere modellen igjen på ulike måter og sjekke igjen."
  },
  {
    "objectID": "cart.html#tester-justert-modell-med-testingdata",
    "href": "cart.html#tester-justert-modell-med-testingdata",
    "title": "5  Klassifikasjonstrær",
    "section": "5.4 Tester justert modell med testingdata",
    "text": "5.4 Tester justert modell med testingdata\nSå er ringen sluttet: Nå du tror du har endet opp med en god algoritme, så er det på tide å sjekke mot testingdata. Da får du så en mer realistisk forståelse av hvordan resultatene vil slå ut for nye data.\n\ntesting_pred &lt;- testing %&gt;% \n  mutate(default_pred = predict(rpart_loss, newdata=testing, type=\"class\"))\n\ntab &lt;- testing_pred %&gt;% \n  select(default_pred, default) %&gt;% \n  table()\nconfusionMatrix(tab)\n\nConfusion Matrix and Statistics\n\n            default\ndefault_pred no yes\n         no  77  13\n         yes 95  65\n                                          \n               Accuracy : 0.568           \n                 95% CI : (0.5041, 0.6303)\n    No Information Rate : 0.688           \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.2183          \n                                          \n Mcnemar's Test P-Value : 6.48e-15        \n                                          \n            Sensitivity : 0.4477          \n            Specificity : 0.8333          \n         Pos Pred Value : 0.8556          \n         Neg Pred Value : 0.4063          \n             Prevalence : 0.6880          \n         Detection Rate : 0.3080          \n   Detection Prevalence : 0.3600          \n      Balanced Accuracy : 0.6405          \n                                          \n       'Positive' Class : no"
  },
  {
    "objectID": "cart.html#oppgaver",
    "href": "cart.html#oppgaver",
    "title": "5  Klassifikasjonstrær",
    "section": "5.5 Oppgaver",
    "text": "5.5 Oppgaver\n\nExercise 5.1 Gjenta oppgave 1, men basert på dine vurderinger i e) se om du klarer å tune modellen mer i retning av ønsket cost-ratio. Bruk argumentene prior, cp, minbucket og maxdepth.\n\n\nBruk datasettet credit til å predikere kredittverdighet for nye kunder.\n\nSpesifiser en formel med et fåtall variable og lag et klassifikasjonstre.\nPlot med rpart.plot()\nBruk predict() til å klassifisere.\nLag en confusion matrix med table()\nGi en vurdering av resultatet.\n\nSi noe om forholdet mellom resultat for training og testing datasett.\nEr cost-ratio ok fra bankens perspektiv?\nEr cost-ratio ok fra kundens perspektiv?\nAndre hensyn som bør spille inn her?\n\n\n\n\nDatafilen credit_kunder.csv inneholder data om to lånesøkere: Ola Normann og Kari Hansen.\nSkal banken gi dem lån? Bruk foretrukne modell fra forrige oppgave.\n\n\nBanker bruker slike systemer i dag i større eller mindre grad til automatisere behandling av lånesøknader. (Men de bruker både rikere data og mer avanserte algoritmer). I hvilken grad synes du slike systemer kan/bør helautomatiseres? Bør det være reguleringer på hva slags data som benyttes til slike systemer? Bør kunden få innsyn i algoritmen ved avslag? Gi noen vurderinger av mulige fordeler og ulemper med tanke på hvordan det kan slå ut for enkeltindivider.\n\n\n\n\n\n\n\nBerk, Richard. 2016. Statistical Learning from a Regression Perspective. USA: Springer."
  },
  {
    "objectID": "cart.html#footnotes",
    "href": "cart.html#footnotes",
    "title": "5  Klassifikasjonstrær",
    "section": "",
    "text": "Begrepet “default” på engelsk kan bety å ikke holde en forpliktelse, men i software kan det bety forhåndsvalg. Dette kan være forvirrende akkurat her. Du kan godt endre variabelnavnet hvis du vil.↩︎\nArgumentet extra = 4 brukes for klassifikasjonstrær for å få andel i hver gruppe per node.↩︎\nFor vanlig lineær regresjon gjorde vi noe tilsvarende: automatisk seleksjon av variable etter hvor viktige de var for tilpassningen. Dette er en tilsvarende type logikk.↩︎"
  },
  {
    "objectID": "bagging.html",
    "href": "bagging.html",
    "title": "6  Bagging",
    "section": "",
    "text": "7 Introduksjon til bagging\nMerk at (Berk 2016) gjør et poeng av at med bagging gjør vi et større steg vekk fra mer vanlige statistiske prosedyrer. Regresjon og klassifikasjonstrær (og det meste annet vi er mer vant med) gir ett sett av resultater. Med bagging får vi en hel haug av resultater. Prinsippet er rett og slett at man trekker et tilfeldig utvalg av dataene, bygger et klassifikasjonstre og gjør klassifikasjonen. Så gjentar man dette med et nytt tilfeldig utvalg fra det opprinnelige datasettet.1 Så gjentar man dette mange ganger.2\nHver observasjon i det opprinnelige datasettet har da blitt klassifisert mange ganger, men ikke nødvendigvis likt i hvert tre. (Enkle klassifikasjonstrær er nemlig litt ustabile greier). Hvis man har gjort prosedyren 100 ganger, så vil hver observasjon bli klassifisert 100 ganger - en gang i hvert tre. For prediksjon på trainingdata brukes rett og slett en opptelling over alle trærne for hver observasjon. Når (Berk 2016) snakker om “votes”, så er dette som menes: hvert tre har en stemme og så stemmes det over hva som blir utfallet for den enkelte.\nDette betyr at antall trær kan ha noe å si. Forvalget for funksjonen bagging() er 25. Det er en god start, men flere trær gir jo mer stabile resultater.\nHusk at klassifikasjonstrær er litt ustabile greier, og små tilfeldige variasjoner kan påvirke en enkelt split. Ved å bruke bagging jevnes de tilfeldige feilene ut slik at man totalt sett skal få et mer stabilt resultat. Altså: at faren for overfitting reduseres. Hvor mange trær som trengs er litt verre å si noe om."
  },
  {
    "objectID": "bagging.html#empirisk-eksempel-mer-credit-scores",
    "href": "bagging.html#empirisk-eksempel-mer-credit-scores",
    "title": "6  Bagging",
    "section": "7.1 Empirisk eksempel: Mer credit scores",
    "text": "7.1 Empirisk eksempel: Mer credit scores\nVi bruker credit-dataene igjen. Man kan med fordel dele inn i training og testing datasett som før. Men litt nedenfor introduseres også ideen med “out-of-bag data” som på en måte gjør en slik split internt i funksjonen. Vi kommer altså tilbake til dette.\n\ncredit &lt;- read.csv(\"../data/credit.csv\", stringsAsFactors = TRUE) \n\nFunksjonen bagging() har tilsvarende oppbygning som tidligere modeller, dvs. utfallsvariabelen angis først, deretter ~ etterfugte av prediktorer, så angis hvilket datasett som brukes. Så kan man legge til ytterligere spesifikasjoner etter det, her er et eksempel der det angis å gjøre 100 tilfeldige utvalg (dvs antall trær) med nbagg = 100.\n\nset.seed(42)\nbaggedtree &lt;- bagging(default ~ . , data = credit, nbagg = 100)"
  },
  {
    "objectID": "bagging.html#tolkning-som-prediksjon",
    "href": "bagging.html#tolkning-som-prediksjon",
    "title": "6  Bagging",
    "section": "7.2 Tolkning som prediksjon",
    "text": "7.2 Tolkning som prediksjon\nEn mulig ulempe med bagging er at vi ikke får noe tolkbar output. Det finnes ingen summary-funksjon slik som for regresjon og selv om man forsåvidt kan plotte hvert enkelt klassifikasjonstre, så gir det lite mening å plotte 100 slike trær. Det hjelper lite på tolkbarheten, for å si det forsiktig. Ikke bruk summary() på objektet du har lagret resultatene fra bagging i. Det blir bare tull.\nVi er nå på vei inn i litt “black-box” metoder: Det er ingen direkte tolkbare parametre eller noe slikt. Men det er fremdeles egentlig ganske enkle metoder, basert på trær, så intuitivt er det mulig å se at man kan finne ut av hva som skjer selv om det er litt arbeidskrevende. 3\nDet er lettere å tolke resultatet som prediksjon. På samme måte som i tidligere metoder vi har sett på kan vi bruke predict(). Denne funksjonen kjenner igjen type objekt det predikeres ut fra og bruker da riktig prosedyre.\n\ncredit_pred &lt;- credit %&gt;% \n  mutate(default_pred = predict(baggedtree), type=\"class\")\n\n\ntab &lt;- credit_pred %&gt;% \n  select(default_pred, default) %&gt;% \n  table()\nconfusionMatrix(tab)\n\nConfusion Matrix and Statistics\n\n            default\ndefault_pred  no yes\n         no  610 147\n         yes  90 153\n                                          \n               Accuracy : 0.763           \n                 95% CI : (0.7354, 0.7891)\n    No Information Rate : 0.7             \n    P-Value [Acc &gt; NIR] : 5.274e-06       \n                                          \n                  Kappa : 0.4033          \n                                          \n Mcnemar's Test P-Value : 0.0002752       \n                                          \n            Sensitivity : 0.8714          \n            Specificity : 0.5100          \n         Pos Pred Value : 0.8058          \n         Neg Pred Value : 0.6296          \n             Prevalence : 0.7000          \n         Detection Rate : 0.6100          \n   Detection Prevalence : 0.7570          \n      Balanced Accuracy : 0.6907          \n                                          \n       'Positive' Class : no"
  },
  {
    "objectID": "bagging.html#out-of-bag-data-oob",
    "href": "bagging.html#out-of-bag-data-oob",
    "title": "6  Bagging",
    "section": "7.3 Out-of-bag data (OOB)",
    "text": "7.3 Out-of-bag data (OOB)\nBagging kan brukes på training data og testing data som vi har gjort før. Men en ulempe med dette er jo at man får et litt mindre datasett å tilpasse modellene med. Merk at bagging i utgangspunktet baserer seg på å trekke et tilfeldig utvalg fra de opprinnelige dataene. Så for hvert tre er det en del trær som ikke blir brukt til å bygge treet. Altså har vi et testing-datasett umiddelbart tilgjengelig! Altså: hvis man bruker 70% av dataene til å bygge hvert enkelt tre, så har man også 30% testingdata tilgjengelig for å gjøre klassifiseringen på det enkelte treet. Dette testing-datasettet kalles out-of-bag (OOB) data, men er altså i prinsippet det samme som et testingdatasett. For hvert enkelt tre er det da mulig å bare bruke OOB for prediksjonen. Så hvis bagging-algoritmen bruker 50% av data til å bygge treet, så vil 50% brukes til klassifikasjonen. Hvis det er 100 trær, så vil alle observasjonene bli brukt til klassifikasjon i omtrent 50 av dem. Dette er da OOB-estimatet og har da altså en innebygget training/testing splitting av data. Dette resultatet vil altså være en god indikasjon på resultatet på helt nye data.\nForvalget i bagging() er imidlertid å ikke bruke OOB. For å gjøre dette legges det til argumentet `coob = TRUE’ og man får utregnet klassifikasjonsfeilen i output.\n\nset.seed(42)\nbaggedtree_oob &lt;- bagging(default ~ . , data = credit, nbagg = 100, coob = TRUE)\n\nNår man deretter bruker predict() vil forvalget være å bruke OOB hvis newdata = ikke er spesifisert. Er det derimot spesifisert nye data, så brukes alle observasjonene for hvert tre.\n\ncredit_pred &lt;- credit %&gt;% \n  mutate(default_pred = predict(baggedtree_oob), type=\"class\")\n\n\ntab &lt;- credit_pred %&gt;% \n  select(default_pred, default) %&gt;% \n  table()\nconfusionMatrix(tab)\n\nConfusion Matrix and Statistics\n\n            default\ndefault_pred  no yes\n         no  610 146\n         yes  90 154\n                                        \n               Accuracy : 0.764         \n                 95% CI : (0.7364, 0.79)\n    No Information Rate : 0.7           \n    P-Value [Acc &gt; NIR] : 3.767e-06     \n                                        \n                  Kappa : 0.4064        \n                                        \n Mcnemar's Test P-Value : 0.0003433     \n                                        \n            Sensitivity : 0.8714        \n            Specificity : 0.5133        \n         Pos Pred Value : 0.8069        \n         Neg Pred Value : 0.6311        \n             Prevalence : 0.7000        \n         Detection Rate : 0.6100        \n   Detection Prevalence : 0.7560        \n      Balanced Accuracy : 0.6924        \n                                        \n       'Positive' Class : no"
  },
  {
    "objectID": "bagging.html#mer-tuning",
    "href": "bagging.html#mer-tuning",
    "title": "6  Bagging",
    "section": "7.4 Mer tuning",
    "text": "7.4 Mer tuning\nMan kan si at bagging består av to deler: 1) en grunnleggende klassifikasjonsteknikk (noen ganger omtalt som “base learner”), og 2) en bootstrapping med gjentatte estimeringer på utvalg av data. I tillegg kommer valget om å bruke OOB eller ikke.\nForvalget i bagging() er å bruke klassifikasjonstrær med rpart(). Det er altså vanlige klassifikasjonstrær av akkurat samme type som i forrige kapittel som bygges. Det betyr også at tuning som kan gjøres med bruk av rpart() også kan gjøres med bagging(). Dette gjøres ved å legge til argumentet control = rpart.control() og så oppgis ønskede tuning parametre innefor den parentesen. Her er et eksempel med å angi maks dybde på treet og complexity parameter.\n\nset.seed(42)\nbaggedtree_oob &lt;- bagging(default ~ . , data = credit, \n                          nbagg = 500, coob = TRUE, \n                          control = rpart.control(maxdepth = 6, cp = 0.0001))\n\n\ncredit_pred &lt;- credit %&gt;% \n  mutate(default_pred = predict(baggedtree_oob), type=\"class\")\n\ntab &lt;- credit_pred %&gt;% \n  select(default_pred, default) %&gt;% \n  table()\nconfusionMatrix(tab)\n\nConfusion Matrix and Statistics\n\n            default\ndefault_pred  no yes\n         no  639 185\n         yes  61 115\n                                          \n               Accuracy : 0.754           \n                 95% CI : (0.7261, 0.7804)\n    No Information Rate : 0.7             \n    P-Value [Acc &gt; NIR] : 8.596e-05       \n                                          \n                  Kappa : 0.3359          \n                                          \n Mcnemar's Test P-Value : 4.427e-15       \n                                          \n            Sensitivity : 0.9129          \n            Specificity : 0.3833          \n         Pos Pred Value : 0.7755          \n         Neg Pred Value : 0.6534          \n             Prevalence : 0.7000          \n         Detection Rate : 0.6390          \n   Detection Prevalence : 0.8240          \n      Balanced Accuracy : 0.6481          \n                                          \n       'Positive' Class : no              \n                                          \n\n\nMerk imidlertid at loss matrix ser ikke ut til å kunne brukes i funksjonen bagging().\nDet viktige poenget akkurat nå er egentlig ikke all tuning som er mulig å gjøre i bagging, men at det er bygget på en annen underliggende algoritme. Vi bruker i praksis ikke bagging noe særlig alene, men derimot er random forest en variant av bagging med litt ekstra saker. Slik sett er bagging å regne som en byggesten til random forest sammen med klassifikasjonstrær. Så derfor skal vi ikke bruke så mye tid på bagging, men gå raskt videre til random forest."
  },
  {
    "objectID": "bagging.html#footnotes",
    "href": "bagging.html#footnotes",
    "title": "6  Bagging",
    "section": "",
    "text": "Dette er altså det vi ofte kaller tilfeldig utvalg med tilbakelegging.↩︎\nBagging ligner altså veldig på det vi i vanlig statistikk kaller for bootstrapping. Men i bootstrapping er ofte formålet å korrigere standardfeilene eller noe slikt og ikke så mye punktestimatet. Skjønt, det går an å bruke bagging på regresjonsmodeller også, og da tror jeg forskjellen mot bootstrapping er mest semantisk.↩︎\nDet finnes imidlertid metoder for dette, som gjerne kalles variable importance og partial dependence. Dette er derimot ikke direkte innebygget i funksjonen for bagging som vi bruker her. Det er mulig å gjøre med bruk av noen andre R-pakker, men vi lar det ligge foreløpig. Derimot kommer vi tilbake til dette i kapittelet om random forest. Bagging er også en byggekloss i random forest, så er det blir helt tilsvarende.↩︎"
  },
  {
    "objectID": "randomForest.html",
    "href": "randomForest.html",
    "title": "7  Random forest",
    "section": "",
    "text": "8 Oppgaver\nDownload data as csv"
  },
  {
    "objectID": "randomForest.html#eksempel",
    "href": "randomForest.html#eksempel",
    "title": "7  Random forest",
    "section": "7.1 Eksempel",
    "text": "7.1 Eksempel\nLeser inn Compas-dataene.\n\ncompas &lt;- readRDS(\"../data/compas.rds\")\nglimpse(compas)\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    &lt;fct&gt; 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     &lt;int&gt; 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive &lt;fct&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive &lt;fct&gt; 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          &lt;fct&gt; 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            &lt;fct&gt; Other, African_American, African_American, Other,…\n$ Sex                  &lt;fct&gt; Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\nEstimerer random forest med alle variable.\n\nset.seed(4356)\nrf &lt;- randomForest(Two_yr_Recidivism ~ . , \n                    data = compas)\nrf\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.94%\nConfusion matrix:\n     0    1 class.error\n0 2462  901   0.2679156\n1 1132 1677   0.4029904\n\n\nFølgende plot gir en oversikt over feilrater for random forest etter hvor mange trær. Det siste tallet til høyre i plottet er de feilratene som vises i output fra randomForest som vist over. Den svarte linjen er altså den totale feilraten, den grønne er falske positive, og den røde er falske negative. I utgangspunktet bruker random forest 500 trær (slik den er implementert i R). Dette plottet viser når resultatene stabiliserer seg. Kort sagt: Hvis linjene er ganske stabile mot til høyre i plottet har man nok trær. Hvis det har stabilisert seg før kunne man forsåvidt klart seg med færre trær. Hvis grafen er ganske humpete mot høyre i plottet, så kan man øke antall trær og se om det bedrer seg.\n\nplot(rf)\n\n\n\n\nPrediksjon fungerer på tilsvarende måte som vi har gjort tidligere. For å predikerer på samme datasett bruker du bare predict().\n\ncompas_p &lt;- compas %&gt;% \n  mutate(pred_rf = predict(rf))\n\nLager enkel krysstabell med predikert mot observert (dvs confusion matrix)\n\ntab &lt;- table(compas_p$pred_rf, compas_p$Two_yr_Recidivism) \ntab\n\n   \n       0    1\n  0 2462 1132\n  1  901 1677\n\n\nLager bedre confusion matrix med alle øvrige utregninger. NB! Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei.\n\nconfusionMatrix(tab, positive=\"1\")\n\nConfusion Matrix and Statistics\n\n   \n       0    1\n  0 2462 1132\n  1  901 1677\n                                          \n               Accuracy : 0.6706          \n                 95% CI : (0.6587, 0.6823)\n    No Information Rate : 0.5449          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.3313          \n                                          \n Mcnemar's Test P-Value : 3.378e-07       \n                                          \n            Sensitivity : 0.5970          \n            Specificity : 0.7321          \n         Pos Pred Value : 0.6505          \n         Neg Pred Value : 0.6850          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2717          \n   Detection Prevalence : 0.4177          \n      Balanced Accuracy : 0.6645          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nEstimerer på nytt og øker antall trær og lager nytt plot. Her er det lagt inn en linje ved 500 trær for å markere tilsvarende resultat som ovenfor. Merk at det endelige resultatet endrer seg noe og mer stabilt mot slutten enn før, men kanskje ikke veldig vesentlig bedre. Merk at vi ikke kan forvente at linjene blir helt flate, og bedring i den ene feilraten går gjerne på bekostning av den andre.\n\nset.seed(4356)\nrf1 &lt;- randomForest(Two_yr_Recidivism ~ . , \n                    ntree = 1500, \n                   data = compas)\n\nplot(rf1)\nabline(v=500, col = \"gray\")\n\n\n\n\nVi kan justere resultatet med å endre antall variable som tas med i hver split (i hvert tre). I forrige eksempel valgte funksjonen å bruke kun to variable, men det kan settes til f.eks. fire. Merk at det er et poeng at det ikke skal være så mange variable i hver split! Dette endrer normalt ikke resultatene veldig mye.\n\nset.seed(4356)\nrf2 &lt;- randomForest(Two_yr_Recidivism ~ . , \n                    mtry=4,\n                    data = compas)\nrf2\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      mtry = 4) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 4\n\n        OOB estimate of  error rate: 34.36%\nConfusion matrix:\n     0    1 class.error\n0 2608  755   0.2245019\n1 1366 1443   0.4862941\n\n\n\n7.1.1 Variable importance\nFor å få ut variable importance må dette settes i estimeringen med importance = TRUE. Det tar nå litt lengre tid å estimere, så med store datasett bør du vente med dette til du ellers er fornøyd med modellen.\n\nset.seed(4356)\nrf &lt;- randomForest(Two_yr_Recidivism ~ . , \n                   importance = TRUE, \n                    data = compas)\nrf\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.42%\nConfusion matrix:\n     0    1 class.error\n0 2538  825   0.2453167\n1 1176 1633   0.4186543\n\n\nVi kan da plotte variable importance plot. Set type = 1 for at det skal vise gjennomsnittlig reduksjon i accuracy fremfor gini-koeffisienten. Endring i accuracy er lettest tolkbart og er oftest mest meningsfult.\n\nvarImpPlot(rf, type = 1)\n\n\n\n\nHer er det altså antall tidligere dommer som har størst betydning for prediksjon av tilbakefall, etterfulgt av alder og kjønn, og til sist om lovbruddet var en forseelse eller ikke.2\n\n\n7.1.2 Partial dependence\nHer må du velge hvilken variabel du ønsker å se på. Det er oftest de “viktigste variablene” fra variable importanc som er mest relevante å se på.\n\npartialPlot(rf, pred.data = compas, \n            x.var = Number_of_Priors, \n            which.class = \"1\")"
  },
  {
    "objectID": "randomForest.html#tuning-av-random-forest",
    "href": "randomForest.html#tuning-av-random-forest",
    "title": "7  Random forest",
    "section": "7.2 Tuning av random forest",
    "text": "7.2 Tuning av random forest\nRandom forest er altså en ganske stor samling av klassifikasjonstrær. For hvert enkelt tre er det parametre som kan justeres slik som angitt i tidligere kapittel. Man kan altså styre kompleksiteten av trærene.\nDet går forsåvidt også legge til loss matrix, men det er mer vanlig å justeres sampling skjemaet i baggingen: altså hvor mange observasjoner som trekkes til å bygge hvert tre. I utgangspunktet trekkes 70% av hele utvalget til å bygge hvert tre. Men ved å bruke argumentet sampsize = ... kan vi angi en annen andel. Hvis vi angir to tall er det antallet som trekkes fra hver kategori i utfallsvariabelen.3 Vi kan altså angi hvor mange som trekkes av de med og uten tilbakefall, men disse tallene bør ikke settes større enn 70% av hver kategori.\nI akkurat disse dataene er det 2809 med tilbakefall og 3364 uten tilbakefall. Vi kan da velge å trekke maks 1900 fra gruppen med tilbakefall.\nHensikten med å gjøre dette er at hvis det er et mindretall som har tilbakefall, så blir hvert tre bygget med mer informasjon om ikke-residivistene enn residivistene. Hvis vi vekter opp residivistene, så får disse større inflytelse på hvert tre. Dermed vil dette også påvirke resultatet. Det er imidlertid vanskelig å vite helt sikkert hvordan det vil slå ut, så man må prøve seg litt frem. Noen ganger vil man veie gruppene likt, andre ganger ulikt. Her er et eksempel der de veies likt:\n\nset.seed(4356)\nrf3 &lt;- randomForest(Two_yr_Recidivism ~ . , \n                    sampsize = c(1900, 1900),\n                    data = compas)\nrf3\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      sampsize = c(1900, 1900)) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.73%\nConfusion matrix:\n     0    1 class.error\n0 2321 1042   0.3098424\n1  978 1831   0.3481666\n\n\nHer er et eksempel der de veies ulikt:\n\nset.seed(4356)\nrf3 &lt;- randomForest(Two_yr_Recidivism ~ . , \n                    sampsize = c(1000, 1900),\n                   data = compas)\nrf3\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      sampsize = c(1000, 1900)) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 41.15%\nConfusion matrix:\n     0    1 class.error\n0 1170 2193   0.6520963\n1  347 2462   0.1235315\n\n\nDet viktige nå er at feilratene for falske positive og falske negative blir vesentlig forskjellig! Det betyr at ved hvordan vi estimerer modellen kan vi legge sterke føringer på resultatet. Vi bør derfor ta stilling til på forhånd hvilke feilrater vi er villig til å akseptere - og hvorvidt de to typer feil er like ille eller ikke. Det er dette Berk (2016) kaller asymetriske kostnader og må vurderes i henhold til konsekvenser av hva prediksjonen skal brukes til.\nPredikere for nye data:\n\ncompas_p &lt;- compas %&gt;% \n  mutate(pred_rf = predict(rf, newdata=compas))\n\nConfusion matrix:\n\ntab &lt;- compas_p %&gt;% \n  select(pred_rf, Two_yr_Recidivism) %&gt;% \n  table()\n\nconfusionMatrix(tab, positive=\"1\")\n\nConfusion Matrix and Statistics\n\n       Two_yr_Recidivism\npred_rf    0    1\n      0 2595 1156\n      1  768 1653\n                                          \n               Accuracy : 0.6883          \n                 95% CI : (0.6765, 0.6998)\n    No Information Rate : 0.5449          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.3642          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.5885          \n            Specificity : 0.7716          \n         Pos Pred Value : 0.6828          \n         Neg Pred Value : 0.6918          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2678          \n   Detection Prevalence : 0.3923          \n      Balanced Accuracy : 0.6800          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "randomForest.html#footnotes",
    "href": "randomForest.html#footnotes",
    "title": "7  Random forest",
    "section": "",
    "text": "Jeg har forstått det slik at de lærde strides noe om dette.↩︎\nI norsk straffelov var det et skille mellom forseelse og forbrytelse frem til 2015, og dette skillet finnes ikke lengre i norsk straffelov. Men med “forseelse” menes det jo i denne sammenheng de mindre alvorlige lovbruddene.↩︎\nHvis det er flere enn to utfallskategorier må det angis like mange tall.↩︎"
  },
  {
    "objectID": "fairness.html#introduksjon-til-fairness",
    "href": "fairness.html#introduksjon-til-fairness",
    "title": "8  Fairness og tuning",
    "section": "8.1 Introduksjon til fairness",
    "text": "8.1 Introduksjon til fairness\nDet blir litt repetisjon her nå. Det grunnleggende med fairness har vi vært innom før, men nå gjør vi det i kontekst av random forest. En ting er å avdekke bias og urettferdighet, en annen ting er å gjøre noe med det!\n\nlibrary(tidyverse)\nlibrary(randomForest)\nlibrary(caret)\nlibrary(fairness)\n\nCompas er et risikoverktøy brukt av amerikansk politi i flere stater som benyttes på individnivå. Bruken av dette verktøyet har vært kontroversielt i flere år og kraftig kritisert av flere. En viktig grunn er at prediksjonene slår forskjellig ut for ulike grupper og er slik sett “biased” mot bl.a. svarte borgere. Resultatet er at de blir mer utsatt for politiets oppmerksomhet enn andre.1 Et datasett er gjort tilgjengelig av Propublica her som vi skal bruke.\n\ncompas &lt;- readRDS(\"../data/compas.rds\")\n\nglimpse(compas)\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    &lt;fct&gt; 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     &lt;int&gt; 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive &lt;fct&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive &lt;fct&gt; 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          &lt;fct&gt; 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            &lt;fct&gt; Other, African_American, African_American, Other,…\n$ Sex                  &lt;fct&gt; Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\nVi tilpasser først en random forest modell.\n\nset.seed(4356)\nglimpse(compas)\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    &lt;fct&gt; 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     &lt;int&gt; 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive &lt;fct&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive &lt;fct&gt; 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          &lt;fct&gt; 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            &lt;fct&gt; Other, African_American, African_American, Other,…\n$ Sex                  &lt;fct&gt; Male, Male, Male, Male, Male, Male, Female, Male,…\n\nrf &lt;- randomForest(Two_yr_Recidivism ~ .,\n                   #importance = TRUE,\n                    data = compas)\n\nLager en prediksjon i en kopi av datasett, mest for å ikke blande sammen prediksjonene med det opprinnelige datasettet.\n\ncompas_p &lt;- compas %&gt;% \n  mutate(pred_rf = predict(rf))  \n\nDa kan vi lage en confusion matrix for å se hvordan modellen fungerer.\n\nconfusionMatrix(compas_p$pred_rf,\n                compas_p$Two_yr_Recidivism, positive=\"1\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2462 1132\n         1  901 1677\n                                          \n               Accuracy : 0.6706          \n                 95% CI : (0.6587, 0.6823)\n    No Information Rate : 0.5449          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.3313          \n                                          \n Mcnemar's Test P-Value : 3.378e-07       \n                                          \n            Sensitivity : 0.5970          \n            Specificity : 0.7321          \n         Pos Pred Value : 0.6505          \n         Neg Pred Value : 0.6850          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2717          \n   Detection Prevalence : 0.4177          \n      Balanced Accuracy : 0.6645          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nFor å få litt bedre grep om hvordan fairness-pakken fungerer kan gjøre det mer manuelt først. Vi kan f.eks. se på hvordan modellen slår ut for menn og kvinner.\nFørst kan vi da splitte datasettet i to etter kjønn. Her for menn.\n\ncompas_1 &lt;- compas_p %&gt;% \n  filter(Sex == \"Male\")\n\nConfusion matrix for menn blir da tilsvarende som tidligere.\n\nconfusionMatrix(compas_1$pred_rf,\n                compas_1$Two_yr_Recidivism, positive=\"1\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 1807  897\n         1  794 1499\n                                          \n               Accuracy : 0.6616          \n                 95% CI : (0.6483, 0.6747)\n    No Information Rate : 0.5205          \n    P-Value [Acc &gt; NIR] : &lt; 2e-16         \n                                          \n                  Kappa : 0.3209          \n                                          \n Mcnemar's Test P-Value : 0.01312         \n                                          \n            Sensitivity : 0.6256          \n            Specificity : 0.6947          \n         Pos Pred Value : 0.6537          \n         Neg Pred Value : 0.6683          \n             Prevalence : 0.4795          \n         Detection Rate : 0.3000          \n   Detection Prevalence : 0.4589          \n      Balanced Accuracy : 0.6602          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nMerk at vi her fikk en accuracy på 0.66 for menn. Splitter datasettet i to etter kjønn. Her for kvinner.\n\ncompas_2 &lt;- compas_p %&gt;% \n  filter(Sex == \"Female\")\n\nConfusion matrix for kvinner\n\nconfusionMatrix(compas_2$pred_rf,\n                compas_2$Two_yr_Recidivism, positive=\"1\")\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 655 235\n         1 107 178\n                                         \n               Accuracy : 0.7089         \n                 95% CI : (0.682, 0.7348)\n    No Information Rate : 0.6485         \n    P-Value [Acc &gt; NIR] : 6.251e-06      \n                                         \n                  Kappa : 0.3128         \n                                         \n Mcnemar's Test P-Value : 6.539e-12      \n                                         \n            Sensitivity : 0.4310         \n            Specificity : 0.8596         \n         Pos Pred Value : 0.6246         \n         Neg Pred Value : 0.7360         \n             Prevalence : 0.3515         \n         Detection Rate : 0.1515         \n   Detection Prevalence : 0.2426         \n      Balanced Accuracy : 0.6453         \n                                         \n       'Positive' Class : 1              \n                                         \n\n\nMerk at vi her fikk en accuracy på 0.71 for kvinner. Modellen er altså mer presis for kvinner enn for menn. Dette er et eksempel på bias i modellen. Forholdet mellom feilrater er da \\(.66/.71 = .93\\). Dette tallet sier at modellens accuracy for menn er 93% av accuracy for kvinner, og dette er et mål på bias i modellen. Om man synes det er mye eller lite er derimot en vurderingssak!\nMan kan også regne ut den andre veien, altså kvinner delt på menn. Da får vi 1.08, som sier at modellen er 8% mer presis for kvinner enn for menn. Det blir jo det samme, men motsatt vei. Vi må altså velge referansegruppe for sammenligningen.\nFunksjoner acc_parity fra fairness-pakken gjør akkurat dette: regner ut accuracy for ulike grupper og sammenligner dem. Her er koden:\n\nacc &lt;- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'pred_rf', \n                  base         = 'Female')\nacc$Metric\n\n                      Female        Male\nAccuracy           0.7089362    0.661597\nAccuracy Parity    1.0000000    0.933225\nGroup size      1175.0000000 4997.000000\n\n\nMen spesifiserer altså hvilke variable som er utfallsvariabel, hvilken som er gruppevariabel, hvilken som er prediksjonsvariabel og hvilken gruppe som skal være referanse.\nFairness-pakken har også noen innebygde funksjoner for grafiske fremstillinger.\n\nacc$Metric_plot"
  },
  {
    "objectID": "fairness.html#fairness-tuning-med-stratifisering",
    "href": "fairness.html#fairness-tuning-med-stratifisering",
    "title": "8  Fairness og tuning",
    "section": "8.2 Fairness: tuning med stratifisering",
    "text": "8.2 Fairness: tuning med stratifisering\nVi har lært litt om grunnleggende tuning. For å justere feilratene er den mest effektive måten i random forest å endre hvordan samplingen skjer ved sampsize.2 Dette hjelper imidlertid ikke nødvendigvis mot bias, altså ulike feilrater for undergrupper. Det vil jo være nyttig om man kunne gjøre noe med slike skjevheter! Heldigvis kan vi det, men det er ikke så lett som man skulle håpe.\nDet viktige punktet å huske på er at random forest trekker tilfeldige utvalg for hvert tre og parameteren sampsize justerer hvor mange observasjoner som trekkes. Vi kan nå justere algoritmen til å gjøre en stratifisert trekning. Med andre ord: det gjøres en tilfeldig trekning innenfor subgrupper. Ovenfor har vi altså sett at modellen ikke er helt rettferdig med hensyn på kjønn. La oss fikse det!\nFørst må vi lage en vektor for å stratifisere etter. Dette bør være variabelen for kjønn kombinert med utfallsvariabelen. Da får vi fire kategorier: menn med og uten tilbakefall, og kvinner med og uten tilbakefall. Så kan vi bruke sampsize til å angi hvor mange som skal trekkes fra hver av disse fire gruppene.\nHer er en kode for å lage en slik stratifiseringsvektor. Pussig nok skal denne vektoren ikke legges inn som en del av datasett, men i et eget objekt. I koden nedenfor bruker vi mutate() for å lage en ny variabel og paste0() for å “lime sammen” de to variabelene. Til sist bruker pull() for å trekke ut kun den variabelen i en egen vektor.3 Koden nedenfor gir også en tabell med antall observasjoner i hver kategori av denne vektoren.\n\nstrat &lt;- compas %&gt;% \n  mutate(strat = paste0(Sex, Two_yr_Recidivism)) %&gt;% \n  pull(strat)\n\ntable(strat)\n\nstrat\nFemale0 Female1   Male0   Male1 \n    762     413    2601    2396 \n\n\nMerk at denne vektoren har verdiene som er en kombinasjon av de opprinnelige variablene. Når vi nå angir tall i sampsize() så er det i denne samme rekkefølgen. Her blir det altså:\n\nKvinner uten tilbakefall\nKvinner med tilbakefall\nMenn uten tilbakefall\nMenn med tilbakefall\n\nMerk da at tallene som angis for sampsize ikke kan være høyere enn antallet i hver gruppe, og helst ikke høyere enn ca 70% av dette. Men det er primært forholdet mellom tallene som er viktig.\nHer er kode for random forest med stratifisert utvalg og angitte verdier av sampsize. Tallene oppgis i den rekkefølgen som er angitt i variabelen strata, altså som i tabellen ovenfor. Her er altså kvinner vektet lavere enn menn, som burde øke accuracy for menn. Samtidig er kvinner med tilbakefall vektet litt høyere enn kvinner uten tilbakefall.\n\nset.seed(45)\nrf &lt;- randomForest(Two_yr_Recidivism ~ .,\n                   data = compas,\n                   strata = strat, \n                   sampsize = c(215, 290, 1500, 1500), \n                   ntree=800)\n\nNå kan vi lage en prediksjon og se om modellen er mer rettferdig på samme måte som vi har gjort tidligere.\n\ncompas_p &lt;- compas %&gt;% \n  mutate(pred_rf = predict(rf))  \n\nacc &lt;- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'pred_rf', \n                  base         = 'Female')\nacc[[2]]\n\n\n\n\nMagisk! Plutselig har vi endret en modell med innebygde kjønnsforskjeller til en kjønnsnøytral modell. I hvert fall på akkurat dette målet, da. Man bør jo også sjekke andre relevante mål på fairness.\nNå lurer du helt sikkert på hvordan du skal velge verdier for sampsize i et slikt tilfelle. Det litt skuffende svaret er at du må prøve deg litt frem. Men det hjelper å vite hvilket tall som betyr hva. I dette eksempelet sikres det at det trekkes omtrent like mange kvinner med og uten tilbakefall, og tilsvarende for menn. Så er det justert litt for å oversample kvinner med tilbakefall. Men for å være ærlig: jeg testet en god del varianter her før jeg fikk det resultatet jeg ville ha.\n\n8.2.1 Hva andre subgrupper?\nSå er spørsmålet om den balansering vi nå har gjort slår ut på andre grupper også. La oss se på etnisitet. Vi bruker den samme modellen som over, men bytter ut variabelen for kjønn med variabelen for etnisitet.\n\nacc &lt;- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Ethnicity',\n                  preds        = 'pred_rf', \n                  base         = 'Caucasian')\nacc[[2]]\n\n\n\n\nDet er lov å bli litt skuffa nå. Dette ble jo ikke like pent balansert som for kjønn. Men det er jo ikke så rart, egentlig. Det er jo ikke gjort noe for å balansere på etnisitet.\nEn første mulighet er å gjøre en vurdering på om kjønnsbalanse eller etnisitet er viktigst. Kanskje man heller skulle fokusere på etnisitet? Det vil antakeligvis ikke være noen dum ide.\nEn annen mulighet er å stratifisere på begge variable samtidig. La oss undersøke muligheten ved å lage en tilsvarende stratifiserings-vektor og se på frekvensfordelingen.\n\nstrat &lt;- compas %&gt;% \n  mutate(strat = paste0(Sex, Ethnicity, Two_yr_Recidivism)) %&gt;% \n  pull(strat)\n\ntable(strat)\n\nstrat\nFemaleAfrican_American0 FemaleAfrican_American1            FemaleAsian0 \n                    346                     203                       1 \n           FemaleAsian1        FemaleCaucasian0        FemaleCaucasian1 \n                      1                     312                     170 \n        FemaleHispanic0         FemaleHispanic1  FemaleNative_American1 \n                     56                      26                       2 \n           FemaleOther0            FemaleOther1   MaleAfrican_American0 \n                     47                      11                    1168 \n  MaleAfrican_American1              MaleAsian0              MaleAsian1 \n                   1458                      22                       7 \n         MaleCaucasian0          MaleCaucasian1           MaleHispanic0 \n                    969                     652                     264 \n          MaleHispanic1    MaleNative_American0    MaleNative_American1 \n                    163                       6                       3 \n             MaleOther0              MaleOther1 \n                    172                     113 \n\n\nProblemet nå er jo at noen grupper er veldig, veldig små. Å stratifiser på disse vil ikke fungere rett og slett. Det er som i annen statistikk: Estimere på veldig små grupper innebærer at det blir bare støy og tilfeldigheter i estimatene.\n\nstrat &lt;- compas %&gt;% \n  mutate(caucasian = ifelse(Ethnicity == \"Caucasian\", \"Caucasian\", \"Other\")) %&gt;% \n  mutate(strat = paste0(Sex, caucasian, Two_yr_Recidivism)) %&gt;% \n  pull(strat)\n\ntable(strat)\n\nstrat\nFemaleCaucasian0 FemaleCaucasian1     FemaleOther0     FemaleOther1 \n             312              170              450              243 \n  MaleCaucasian0   MaleCaucasian1       MaleOther0       MaleOther1 \n             969              652             1632             1744 \n\n\nLa oss prøve med dette.\n\nset.seed(45)\nrf &lt;- randomForest(Two_yr_Recidivism ~ .,\n                   data = compas,\n                   strata = strat, \n                   sampsize = c(120, 120, \n                                200, 200, \n                                400, 400, \n                                900, 900), \n                   ntree=800)\n\n#rf\n\n\ncompas_p &lt;- compas %&gt;% \n  mutate(pred_rf = predict(rf))  \n\nacc &lt;- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'pred_rf', \n                  base         = 'Female')\nacc[[2]]\n\n\n\n\n\nacc &lt;- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Ethnicity',\n                  preds        = 'pred_rf', \n                  base         = 'Caucasian')\nacc[[2]]\n\n\n\n\nHer ble det i hvert fall annerledes, men ikke helt likt nå heller. Nå kan man drive på en stund å justere og se hva man får til. Hvis man har et veldig stort datasett (som vi ikke har her) så kan man i teorien justere for flere ulike egenskaper samtidig og i større detalj. Man er rett og slett litt begrenset av dataene.\nProblemet er selvsagt at det ikke går an å justere i det uendelige for alle variable. I tillegg kan det uansett være andre egenskaper du ikke har data for som det senere vil vise seg er urettferdig. Det kan f.eks. slå ut svært skjevt for type nabolag, sosioøkonomisk status, religiøs tilhørighet, lengde på håret - eller hva som helst annet. Man trenger data for å sjekke, men også data for å bygge algoritmen.\nJeg tror konklusjonen er at man justere for noe, men ikke alt. Men med nok data kan man justere for mer - men fremdeles ikke alt. I tillegg er som regel ikke justeringer gratis. Kanskje blir presisjonen i modellen totalt sett dårligere?\nSå da er vi tilbake til det litt ubehagelige gjennomgangstemaet om prioriteringer og valg: Vil du f.eks. ha en rettferdig modell eller en presis modell? Hvilke grupper bør den være rettferdig for - og hvilke grupper er det ikke så farlig om den er urettferdig for? Dette kan lett være umulige valg. Men hva er så alternativet? Det er jo heller ikke sikkert er bedre på noen av disse parametrene."
  },
  {
    "objectID": "fairness.html#oppgaver",
    "href": "fairness.html#oppgaver",
    "title": "8  Fairness og tuning",
    "section": "8.3 Oppgaver",
    "text": "8.3 Oppgaver\n\nExercise 8.1 Gå gjennom eksempelet over og sjekk at det fungerer og at du skjønner hvert steg.\n\n\nExercise 8.2 Velg deg et annet datasett og gjør tilsvarende analyse. Det er viktig at du nå gjør en vurdering av hvilke undergrupper du synes er viktigst å motvirke urettferdighet for. Her bør du ta hensyn også til hva slags tiltak og konsekvenser det er snakk om! Skriv ned dine vurderinger om dette som begrunnelse for hvordan du vil motvirke urettferdighet i modellen.\n\nVurder hvilke konsekvenser prediksjonen kan få, med henblikk på et tenkt praktisk tiltak. Hvilke feilrater vil du akseptere? Ta et valg.\nEstimer modellen som tidligere, lag en confusion matrix og vurder resultatet. Juster modellen til du er fornøyd med resultatet.\nVurder hvilken undergruppe du synes det er viktigst at ikke blir biased.\nHvilket mål på fairness synes du er viktigst i akkurat dette tilfellet? Velg ett mål, begrunn det valget og sjekk.\nEstimer modellen på nytt med stratifisert utvalg og justert sampsize. Prøv deg frem til du får et akseptabelt mål på fairness.\nSjekk confusion matrix og sammenlign med den første modellen. Modellen ble kanskje mer rettferdig, men gikk f.eks. accuracy ned eller endrede feilrater? Eller litt flåsete sagt: Var det verd å få en mer rettferdig modell?\nSjekk nå det samme målet på fairness med to andre undergrupper. Ble det like bra?\n\n\n\nExercise 8.3 Velg et annet datasett og gjør tilsvarende øvelse."
  },
  {
    "objectID": "fairness.html#footnotes",
    "href": "fairness.html#footnotes",
    "title": "8  Fairness og tuning",
    "section": "",
    "text": "Det er verd å minne på at politi i USA i stor grad er mer hardhendte enn norsk politi. Konsekvensene er altså litt mer alvorlig enn at unødig mange føler seg unødig mistenkte.↩︎\nDette er ikke eneste måten å tune på, men det vi dekker her. Det finnes andre funksjoner for random forest som inneholder mer funksjonalitet for tuning.↩︎\nFor de av dere som kan en del R fra før: select() ville gjort noe tilsvarende, men da ville objektet være en data.frame med én variabel fremfor en vektor. Forskjellen er minimal, men randomForest() vil ha det på denne måten.↩︎"
  },
  {
    "objectID": "boosting.html#stochastic-gradient-boosting",
    "href": "boosting.html#stochastic-gradient-boosting",
    "title": "9  Boosting",
    "section": "9.1 Stochastic gradient boosting",
    "text": "9.1 Stochastic gradient boosting\nGradient boosting for klassifisering bruker ikke vekter på samme måte som adaboost, men bruker residualene. For et binomisk utfall (to kategorier kodet 0 eller 1) er residualen, \\(r_i\\), er definert som\n\\[ r_i = y_i - \\frac{1}{e^{-f(x_i)}} \\] Litt forenklet kan vi si at dette er det observert utfallet minus det predikerte utfallet fra logistisk regresjon. “Gradienten” er da \\(f(x)\\).\nGradient boosting fungerer med flere andre fordelinger, men hvis vi begrenser oss til klassifikasjon kan vi angi distribution = \"bernoulli\". Merk at for gbm må utfallsvariabelen være numerisk, ikke factor.\n\nset.seed(542)\ngradboost1 &lt;- gbm(formula = Two_yr_Recidivism ~ .,\n                 data = training,\n                 distribution = \"bernoulli\",\n                 n.trees = 4000,\n                 interaction.depth = 3,\n                 n.minobsinnode = 1,\n                 shrinkage = 0.001,\n                 bag.fraction = 0.5)\n\nMerk angir argumentet bag.fraction = 0.5 i modellen (som forøvrig også er forvalget, så man behøver ikke skrive det, egentlig). I hver split brukes altså halve utvalget til å bestemme neste split slik at andre halvdel er out-of-bag data. Hvis dette argumentet settes til 1 brukes hele datasettet i hver split.\nStandard plot av gis ved gbm.perf() som nedenfor, og viser forbedring for hver iterasjon. Ytterligere forbedring stopper opp ved nærmere 2500 iterasjoner, markert ved den vertikale blå linjen.\n\ngbm.perf(gradboost1, oobag.curve = TRUE, method = \"OOB\", \n            plot.it=T, overlay = T) \n\n\n\n\n\n\n\n[1] 3322\nattr(,\"smoother\")\nCall:\nloess(formula = object$oobag.improve ~ x, enp.target = min(max(4, \n    length(x)/10), 50))\n\nNumber of Observations: 4000 \nEquivalent Number of Parameters: 39.99 \nResidual Standard Error: 2.048e-06 \n\n\nDenne estimeringen kan justeres ved å endre tuningparametrene.\n\nn.trees er antall iterasjoner, dvs. antall klassifikasjonstrær. Forvalget er 100, som er åpenbart altfor lavt, så sett noen tusen.\ninteraction.depth er antall split i hvert tre. Forvalget er 1, men Berk sier at 1-3 er ok.\nn.minobsinnode er minste antall observasjoner i siste node. Forvalg er 1, men Berk anslår at 5-15 fungerer bra. (Hvis modellen har bare en split er det ikke sikkert dette er så viktig)\nshrinkage er hvor store skritt langs gradienten som testes i hver iterasjon, og dette skal være lavt. Forvalget er 0.001. Kostnaden er at det tar lengre tid enn ved et høyere tall (opp til 10 kan testes).\nbag.fraction er hvor stor andel av data som brukes i hver iterasjon. Dette hjelper for å redusere overfitting. Forvalget er 0.5, som innebærer at andre del av data kan fungere som OOB. Merk at Berk understreker at OOB bare kan brukes til å vurdere tilpassingen slik som i figuren over."
  },
  {
    "objectID": "boosting.html#tolkbarhet",
    "href": "boosting.html#tolkbarhet",
    "title": "9  Boosting",
    "section": "9.2 Tolkbarhet",
    "text": "9.2 Tolkbarhet\nSom i random forest kan vi undersøke hvilke variable som er mest betydningsfulle i prediksjonen. I utgangspunktet gir summary() mot et gbm-objekt et plot, men dette er stygt og kan være vanskelig å lese skikkelig. Derfor inneholder koden nedenfor argumentet plotit=FALSE, så lages det et bedre plot med ggplot() etterpå.1\nResultatene er tolkbare tilsvarende som relative importance som vi så i random forest.\n\nsumboost &lt;- summary(gradboost1, method = permutation.test.gbm, normalize = T, \n                    plotit = F)\n\nggplot(sumboost, aes(x = reorder(var, rel.inf), y = rel.inf)) +\n  geom_col()+\n  ylab(\"Relative influence\")+\n  xlab(\"\")+\n  coord_flip()\n\n\n\n\nMerk at resultatet fra summary() her returnerer en data.frame som kan plottes direkte med ggplot. Eneste mystiske som skjer er at x er angitt som sortert etter verdier på y-variabelen. Så er plottet snudd om med coord_flip til slutt.\nMan kan også plotte hvordan resultatet endres med ulike verdier på prediktorene. Dette tilsvarer partial dependence. Her er det mest hensiktsmessig å bruke den innebygde funksjonen plot() som kaller en underliggende plot-funksjon for gbm-objekter.\n\nplot(gradboost1, \"Number_of_Priors\", type = \"response\")\n\n\n\nplot(gradboost1, \"Age_Below_TwentyFive\", type = \"response\")\n\n\n\nplot(gradboost1, \"Ethnicity\", type = \"response\")\n\n\n\nplot(gradboost1, \"Misdemeanor\", type = \"response\")"
  },
  {
    "objectID": "boosting.html#prediksjon-og-confusion-matrix",
    "href": "boosting.html#prediksjon-og-confusion-matrix",
    "title": "9  Boosting",
    "section": "9.3 Prediksjon og confusion matrix",
    "text": "9.3 Prediksjon og confusion matrix\nVi gjør prediksjon på tilsvarende måte som før, men det er et par viktige detaljer. Forvalget for predict() for gbm-objekter er \\(f(x)\\) som her er på log odds skalaen, men hvis vi setter type = \"response\" så får vi ut en sannsynlighet (dvs. et tall mellom 0 og 1). Da kan vi klassifisere etter hvilken gruppe som er mest sannsynlig, dvs. hvis høyere enn 0.5\n\ncompas_p &lt;- training %&gt;% \n  mutate(pred = predict(gradboost1, type = \"response\"), \n         p_klass = ifelse(pred &gt; 0.5, 1, 0))\n\nLager enkel krysstabell med predikert mot observert (dvs confusion matrix)\n\ntab &lt;- table(compas_p$p_klass, training$Two_yr_Recidivism) \ntab\n\n   \n       0    1\n  0 1936  850\n  1  583 1260\n\n\nLager bedre confusion matrix med alle øvrige utregninger. NB! Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei.\n\nconfusionMatrix(tab, positive=\"1\")\n\nConfusion Matrix and Statistics\n\n   \n       0    1\n  0 1936  850\n  1  583 1260\n                                          \n               Accuracy : 0.6904          \n                 95% CI : (0.6769, 0.7037)\n    No Information Rate : 0.5442          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.3695          \n                                          \n Mcnemar's Test P-Value : 2.113e-12       \n                                          \n            Sensitivity : 0.5972          \n            Specificity : 0.7686          \n         Pos Pred Value : 0.6837          \n         Neg Pred Value : 0.6949          \n             Prevalence : 0.4558          \n         Detection Rate : 0.2722          \n   Detection Prevalence : 0.3981          \n      Balanced Accuracy : 0.6829          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "boosting.html#asymetriske-kostnader",
    "href": "boosting.html#asymetriske-kostnader",
    "title": "9  Boosting",
    "section": "9.4 Asymetriske kostnader",
    "text": "9.4 Asymetriske kostnader\nVi har det vanlige problemet med å vurdere om falske positive og falske negative er like problematisk. Igjen er det slik at den vurderingen krever en vurdering av utfallet man ønsker gjøre noe med og konsekvensene av tiltaket som skal iverksettes. For credit-dataene kan det jo være at noen ikke vurderes som kredittverdige.2\nFor å håndtere asymetriske kostnader kan vi vekte utfallene forskjellig og angi denne vekten i prosedyren. Argumentet weights = ... tar en vektor med verdier (ét tall for hver observasjon i dataene) og skal ikke være en del av datasettet.\nHer er et eksempel der negative tillegges 2 ganger så mye vekt som positive i modellen. Når utfallene vektes ulikt i modellen vil det dermed slå ut på feilratene slik at det blir ulikt forhold for falske postive og falske negative (se mer i Berk kap. 6.4 og eksempel s. 277).\nVær obs på at det er ikke så lett å vite helt hvordan slik vekting slår ut på resultatene. Det er ikke et 1-til-1 forhold mellom vekting og feilrater. Som i annen justering kan dette gå ut over accuracy og andre mål, så det er vanligvis en trade-off her. Du må derfor sjekke resultatene og så evt. gå tilbake og justere vektene hvis det ikke ble slik du ønsket.\n\nwts &lt;- training %&gt;% \n  mutate(wts = ifelse(Two_yr_Recidivism == 1, 1, 2)) %&gt;%   # se begrunnelse s. 274 i Berk \n  pull(wts)\n\nset.seed(542)\ngradboost2 &lt;- gbm(formula = Two_yr_Recidivism ~ .,\n                 data = training,\n                 weights = wts, \n                 distribution = \"bernoulli\",\n                 n.trees = 4000,\n                 interaction.depth = 3,\n                 n.minobsinnode = 1,\n                 shrinkage = 0.001,\n                 bag.fraction = 0.5)\n\nSå kan vi gjøre prediksjon og confusion matrix på nytt.\n\ncompas_p &lt;- training %&gt;% \n  mutate(pred = predict(gradboost2, type = \"response\"), \n         p_klass = ifelse(pred &gt; 0.5, 1, 0))\n\nLager enkel krysstabell med predikert mot observert (dvs confusion matrix)\n\ntab &lt;- table(compas_p$p_klass, training$Two_yr_Recidivism) \ntab\n\n   \n       0    1\n  0 2329 1447\n  1  190  663\n\n\nSå kan vi legge tabellen inn i funksjonen confusionMatrix() for å også få diverse utregninger. (Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei.) Dette er altså akkurat samme prosedyre som vi har brukt ved tidligere prediksjoner.\n\nconfusionMatrix(tab, positive=\"1\")\n\nConfusion Matrix and Statistics\n\n   \n       0    1\n  0 2329 1447\n  1  190  663\n                                          \n               Accuracy : 0.6464          \n                 95% CI : (0.6324, 0.6601)\n    No Information Rate : 0.5442          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.2509          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.3142          \n            Specificity : 0.9246          \n         Pos Pred Value : 0.7773          \n         Neg Pred Value : 0.6168          \n             Prevalence : 0.4558          \n         Detection Rate : 0.1432          \n   Detection Prevalence : 0.1843          \n      Balanced Accuracy : 0.6194          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "boosting.html#hva-med-bias-og-fairness",
    "href": "boosting.html#hva-med-bias-og-fairness",
    "title": "9  Boosting",
    "section": "9.5 Hva med bias og fairness?",
    "text": "9.5 Hva med bias og fairness?\nDet er heller ingenting nytt når det gjelder om prediksjonen kan slå ut skjevt for ulike grupper. Selvfølgelig kan det skje, og det bør jo undersøkes. Vi kan bruke akkurat de samme funksjonene som før.\nHer er et eksempel med forskjeller i “accuracy” for menn og kvinner. Det er altså høyere andel riktig klassifiserte for kvinner enn for menn.\n\nacc &lt;- fairness::acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'p_klass', \n                  base         = 'Female')\n\nacc\n\n$Metric\n                     Female         Male\nAccuracy          0.6853933    0.6370687\nAccuracy Parity   1.0000000    0.9294937\nGroup size      890.0000000 3739.0000000\n\n$Metric_plot"
  },
  {
    "objectID": "boosting.html#justere-rettferdighet-med-vekting",
    "href": "boosting.html#justere-rettferdighet-med-vekting",
    "title": "9  Boosting",
    "section": "9.6 Justere rettferdighet med vekting",
    "text": "9.6 Justere rettferdighet med vekting\nVi har allerede sett at vi kan justere algoritmen for asymetriske kostnader ved å vekte utfallet forskjellig. Vi kan også justere slik at vi også vekter opp undergrupper. Igjen er det ikke helt åpenbart hvordan det vil slå ut å vekte en gruppe opp eller ned, så det må vi sjekke.\nHer er en kode for å lage vekter og legger den vekten inn i gbm. Tanken i koden her er å først angi vektingen for kostnader og undergrupper hver for seg, og så legge disse til per person i datasettet.\nLa oss først se på fordelingen av utfallet etter kjønn ved en enkel krysstabell. Her har jeg brukt funksjonen tbl_cross() for å få en penere tabell med summeringer, men en enklere tabell gjør også nytten.\n\ntraining %&gt;% \n   tbl_cross( row = Sex, col =  Two_yr_Recidivism)\n\n\n\n\n\n  \n    \n      \n      \n        Two_yr_Recidivism\n      \n      Total\n    \n    \n      0\n      1\n    \n  \n  \n    Sex\n\n\n\n        Female\n575\n315\n890\n        Male\n1,944\n1,795\n3,739\n    Total\n2,519\n2,110\n4,629\n  \n  \n  \n\n\n\n\nVi ser her at i datamaterialet er det lavere residiv blant kvinner enn menn, men det er også færre kvinner enn menn totalt. Dette kan jo være en indikator på hva som bør vektes opp. Her er et forslag der kvinner vektes opp generelt, men kvinner med residiv vektes opp enda mer. For menn vektes også residiv opp.\nVekten skal lages så det blir et tall per observasjon i datasettet, så utgangspunktet er trainingdataene. Så la oss lage en vekt som tar utgangpunktet i menn uten residiv og vekter det som 1. Hvis vi vil vekte opp residiv, så settes menn med residiv til 2. Tilsvarende for kvinner kan vi sette vektene høyere, f.eks. henholdsvis 2 og 4.\nI koden nedenfor lages også en krysstabell bare for å sjekke at det ble slik det var tenkt. Tabellen har bare funksjon for å sjekke at det ble riktig.\n\nwts &lt;- training %&gt;%  \n  mutate(wts1 = case_when(\n    Sex == \"Male\" & Two_yr_Recidivism == 0 ~ 1,\n    Sex == \"Male\" & Two_yr_Recidivism == 1 ~ 2, \n    Sex == \"Female\" & Two_yr_Recidivism == 0 ~ 2,\n    Sex == \"Female\" & Two_yr_Recidivism == 1 ~ 4)) %&gt;% \n    pull(wts1)\n\nlibrary(gtsummary)\ndf &lt;- training %&gt;% \n  mutate(wts = factor(wts))\n\ndf %&gt;%  \n  select(Sex, Two_yr_Recidivism, wts) %&gt;% \n tbl_strata(\n    strata = Sex,\n    ~.x %&gt;%\n      tbl_summary(\n        by = Two_yr_Recidivism, \n        #type = everything()~\"categorical\", \n        statistic = all_categorical() ~ \"{n}\"\n      )\n  )\n\n\n\n\n\n  \n    \n      Characteristic\n      \n        Female\n      \n      \n        Male\n      \n    \n    \n      0, N = 5751\n      1, N = 3151\n      0, N = 1,9441\n      1, N = 1,7951\n    \n  \n  \n    wts\n\n\n\n\n        1\n0\n0\n1,944\n0\n        2\n575\n0\n0\n1,795\n        4\n0\n315\n0\n0\n  \n  \n  \n    \n      1 n\n    \n  \n\n\n\n\nKodingen av vekten kan treng litt forklaring. Det er forsåvidt standard R-kode, men likevel:\n\ncase_when() brukes for gjentatt if-else i flere ledd. Altså først vurderes første kriterium og får tilskrevet den verdien som følger etter ~. For øvrige observasjoner sjekkes neste kriterium på samme måte.\npull() brukes når man bare skal beholde én variabel som en vektor (ikke ny data.frame)\ntbl_strata fra pakken gtsummary brukes til å lage en tre-veis tabell. Det spiller liten rolle hvordan tabellen lages, men denne gir en pen og lett lesbar tabell.\n\nDa kan vi gjøre en ny boostingmodell og sjekke resultatene. Koden er identisk som ovenfor, bare at vektene er endret\n\nset.seed(542)\ngradboost3 &lt;- gbm(formula = Two_yr_Recidivism ~ .,\n                 data = training,\n                 weights = wts, \n                 distribution = \"bernoulli\",\n                 n.trees = 4000,\n                 interaction.depth = 3,\n                 n.minobsinnode = 1,\n                 shrinkage = 0.001,\n                 bag.fraction = 0.5)\n\n\ncompas_p &lt;- training %&gt;% \n  mutate(pred = predict(gradboost3, type = \"response\"), \n         p_klass = ifelse(pred &gt; 0.5, 1, 0))\n\nLager enkel krysstabell med predikert mot observert (dvs confusion matrix)\n\ntab &lt;- table(compas_p$p_klass, training$Two_yr_Recidivism) \ntab\n\n   \n       0    1\n  0 1231  369\n  1 1288 1741\n\n\nLager bedre confusion matrix med alle øvrige utregninger. NB! Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei.\n\nconfusionMatrix(tab, positive=\"1\")\n\nConfusion Matrix and Statistics\n\n   \n       0    1\n  0 1231  369\n  1 1288 1741\n                                         \n               Accuracy : 0.642          \n                 95% CI : (0.628, 0.6559)\n    No Information Rate : 0.5442         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.3031         \n                                         \n Mcnemar's Test P-Value : &lt; 2.2e-16      \n                                         \n            Sensitivity : 0.8251         \n            Specificity : 0.4887         \n         Pos Pred Value : 0.5748         \n         Neg Pred Value : 0.7694         \n             Prevalence : 0.4558         \n         Detection Rate : 0.3761         \n   Detection Prevalence : 0.6544         \n      Balanced Accuracy : 0.6569         \n                                         \n       'Positive' Class : 1              \n                                         \n\n\n\nacc &lt;- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'p_klass', \n                  base         = 'Female')\nacc[[2]]"
  },
  {
    "objectID": "boosting.html#oppgaver",
    "href": "boosting.html#oppgaver",
    "title": "9  Boosting",
    "section": "9.7 Oppgaver",
    "text": "9.7 Oppgaver\n\nExercise 9.1 Se over de vurderingene du gjorde i tidligere analyser av compas-dataene, herunder hva slags feilrater du er villig til å akseptere og hva slags konsekvenser de ulike typene feil kan få. Vil du gjøre andre vurderinger nå? Ta stilling til om du fremdeles synes tidligere vurderinger var ok. Bestem deg for hvor mange falske positive du er villig til å godta per falske negative (dvs asymetriske kostnader). Bruk dette videre i neste oppgave.\n\n\nExercise 9.2 Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer. Men du må gjøre tre endringer:\n\nVurder asymetriske konstnader, spesielt cost-ratio (dvs. forholdet mellom falske positive og falske negative). Se om du klarer å justere modellen så du får dette resultatet.\nSjekk mål på fairness også for etnisitet. Test ut flere forskjellige mål fra fairness-pakken. Bruk fortsatt trainingdatasettet.\nEtter at du har kjørt gjennom alt med trainingdatasettet må du sjekke resultatet mot testingdatasettet. Ble det vesentlig endring i resultatene?\n\n\n\nExercise 9.3 Bruk et annet datasett og gjør tilsvarende analyser. Husk å få med følgende deler:\n\nVurdering av konsekvenser av feil: hva vil du godta? Begrunn svaret med et tenkt tiltak som skal settes i verk.\nTilpass modellen, og vurder om du har nok iterasjoner (antall runder i boostingen). Øk ved behov.\nPrediker, lag confusion matrix og sammenlign med hva du i utgangspunktet bestemte deg for å godta. Hvis det trengs endringer, juster modellen på nytt til du er mer fornøyd.\nKommenter hvilke variable som er mest betydningsfulle for prediksjonen og på hvilken måte.\nHvilke mål på fairness synes du er mest relevant her og for hvilke undergrupper? Sjekk dette empirisk.\nPrøv å justere modellen til et mer tilfredsstillende rettferdig resultat for valgte undergrupper.\nSjekk nå resultatene (inkl. fairness) for testingdataene også.\nVil du sette i verk tiltak basert på en slik prediksjonsmodell? Begrunn svaret."
  },
  {
    "objectID": "boosting.html#footnotes",
    "href": "boosting.html#footnotes",
    "title": "9  Boosting",
    "section": "",
    "text": "Estetikken er imidlertid underordet her. Sett gjerne plotit = TRUE for et mer quisk-and-dirty plot.↩︎\nDet er forresten også en implisitt vurdering her om hvem sitt problem dette er: banken behøver ikke synes det er problematisk å si nei til et boliglån, mens det fra samfunnets synsvinkel kan være uheldig at noen grupper sperres ute av boligmarkedet. Hvem som er “stakeholder” her er altså også et poeng, som vi lar ligge i denne sammenheng.↩︎"
  },
  {
    "objectID": "unsupervised.html#k-means-klustering",
    "href": "unsupervised.html#k-means-klustering",
    "title": "10  Unsupervised learning",
    "section": "10.1 K-means klustering",
    "text": "10.1 K-means klustering\nVi starter med et tenkt eksempel der det er to variable og tre klustre, men tilhørighet til kluster er ikke direkte observerbart (altså: det er ingen variable for kluster).\nHer ser du de første seks observasjonene i datasettet:\n\n\n           x         y\n1 -0.7708857  3.821888\n2  4.1734709  4.597204\n3  0.5497190  8.046265\n4 -0.2492836 -1.024751\n5 -0.4691657  5.556987\n6  3.9338419  6.738554\n\n\nVi kan så plotte x og y i et scatterplot. I dette tilfellet ser vi tydelig at det er tre klynger av datapunkter. Ofte vil det ikke være så lett å se, men disse dataene er laget slik at det skal være lettere å se hvordan algoritmen fungerer.\n\n\n\n\n\nI plottet er punktene nå lagt inn tre tilfeldige punkter som marker startpunktet for algoritmen. Disse punktene er tilfeldig valgt, og markerer et første steg som forsøksvis sentrum av tre klustre. Antall klustre må vi altså bestemme selv i forkant.\nFor hvert av øvrige datapunktene regnes det så avstanden til hvert av disse tre tilfeldige “klustrene”. Hvert datapunkt klassifiseres så til det klusteret de er nærmest.\n\n\n\n\n\nEtter at hvert datapunkt er klassifisert til det “klusteret” de er nærmest, kan det så regnes det ut midtpunktet for hvert kluster. Dette midtpunktet er så utgangspunktet for neste runde med klassifisering: avstanden fra alle datapunkter til midtpunktet regnes ut og ny klassifisering til det klusteret datapunktet er nærmest.\n\n\n\n\n\nEtter ny klassifisering, regnes det så ut et nytt midtpunkt og vi gjør det hele en gang til: regner ut avstanden og klassifiserer til nærmeste.\n\n\n\n\n\nEt nytt midtpunkt regnes ut og vi gjør det hele enda en gang.\n\n\n\n\n\nMerk nå at i siste runde var det ingen av punktene som byttet kluster. Da avsluttes algoritmen og alle punkter er klassifisert etter hvilket kluster de er mest lik de andre punktene.\nI dette eksempelet er klusterne tydelig separert og det er forholdsvis lett å gjøre klassifiseringen. I andre tilfeller er det ikke nødvendigvis like greit, og det må langt flere iterasjoner til før det landes på en løsning.\nDet er verd å merke seg at startpunktet (altså de tre tilfeldige punktene) kan ha betydning for løsningen. Det er derfor vanlig at software tester ut flere startverdier og velger den løsningen som passer best.\n\n10.1.1 K-means med kmeans()\nVi bruker eksempeldatasettet brukt ovenfor.\n\ndf &lt;- readRDS(\"data/kmeans_data.rds\")\nhead(df)\n\n           x         y\n1 -0.7708857  3.821888\n2  4.1734709  4.597204\n3  0.5497190  8.046265\n4 -0.2492836 -1.024751\n5 -0.4691657  5.556987\n6  3.9338419  6.738554\n\n\nDet er en del plunder med å gjøre kmeans manuelt. Heldigvis er det en funksjon som fikser hele saken for oss. Funksjonen kmeans() trenger primært tre imput: de dataene som skal klustres, antall klustere, og antall tilfeldige startverdier. Antall klustre må vi altså bestemme selv.\nHer er en kode som først kjører kmeans-algoritmen. I det objektet som kommer ut er det en vektor som heter ...$cluster som er selve klassifiseringen. Denne kan vi legge inn som en ny variabel i datasettet. Merk at rekkefølgen på observasjonene og output-objektet er den samme, så det blir riktig å bare legge til vektoren som en ny variabel. Dernest kan vi plotte resultatet.\n\nkm_df &lt;- kmeans(df, centers = 3, nstart=20)\n\ndf_p &lt;- df %&gt;% \n  mutate(cluster = km_df$cluster)\n\n\nggplot(df_p, aes(x=x, y = y, col = factor(cluster), shape = factor(cluster))) +\n  geom_point()\n\n\n\n\nDette ble selvfølgelig likt som i den trinnvise prosedyren vist ovenfor. Det kan være greit å være klar over at navnet på hvert kluster (1, 2 eller 3) er tilfeldig og du kan få en annen rekkefølge på navnene en annen gang. Det spiller ingen rolle, men er lett å bli forvirret av.\n\n\n10.1.2 Hvor mange klustre trenger man?\nTja. Hvis du har en god tanke om hvor mange klustre du trenger, så er jo saken grei. Da bruker du disse. Hvis du derimot ikke vet - og det er det vanlige - så kan du gå for det antallet som best oppsummerer dataene. Men hva er så det? Et mål er summen av avstandene til sentrum innenfor hver kluster. Omtales gjerne som “within total sum of squares”. Den løsningen (dvs. antall klustre) som gir lavest kvadratsummer er da den som er “best”.\nI praksis betyr det at man tilpasser modellen flere ganger, med trinnvis flere klustre. Så kan man sammenligne “within total sum of squares”.\nDen etterfølgende koden gjør dette. Den er litt krøkete, dessverre da den innebærer å skrive en loop.3 Her er i hvert fall full kode.\n\nwss &lt;- 0\n# For 1 to 15 cluster centers\nfor (i in 1:5) {\n  km.out &lt;- kmeans(df, centers = i, nstart=20)\n  # Save total within sum of squares to wss variable\n  wss[i] &lt;- km.out$tot.withinss\n}\n\n# Plot total within sum of squares vs. number of clusters\nplot(1:5, wss, type = \"b\", \n     xlab = \"Number of Clusters\", \n     ylab = \"Within groups sum of squares\")\n# Marker \"albuen\" med en linje i plottet \nabline(v=3, col=\"red\")\n\n\n\n\nKvadratsummen reduseres for antall klustre. Intuitivt er jo det rimelig: jo flere klustre - jo kortere er avstanden til et kluster-sentrum. Men merk at trenden flater ganske tydelig ut etter 3 klustre. Altså: forbedringen i tilpassning er minimal. Et slikt plot kalles “elbow method” eller “scree plot”. Beste modell er der hvor kurven får en “albue”, eller med andre ord: der reduksjonen avtar. Det er ikke alltid det er lett å bedømme, men her er det ikke en egentlig fasit. Det finnes ingen fasit hvis man ikke fra før av vet at det finnes et gitt antall klustre.\n\n\n10.1.3 Longitudinelle data\nDet er nok vanligst å klustre ulike variable. Men hvis variablene innholder verdier for ulike tidsenheter (f.eks. per år), så kan vi også analysere tidstrender på denne måten. Antall variable som klustres kan være flerdimensjonalt. Ovenfor er det brukt bare to variable, men det normale er jo at det er langt flere dimensjoner samtidig."
  },
  {
    "objectID": "unsupervised.html#datareduksjon-med-principal-component-analysis-pca",
    "href": "unsupervised.html#datareduksjon-med-principal-component-analysis-pca",
    "title": "10  Unsupervised learning",
    "section": "10.2 Datareduksjon med principal component analysis (PCA)",
    "text": "10.2 Datareduksjon med principal component analysis (PCA)\nEn annen form for unsupervised learning er principal component analysis (PCA). Dette er en teknikk som reduserer dimensjonaliteten i et datasett. Med dimensjonalitet mener vi i praksis antall variable. I et datasett med mange variable kan det være vanskelig å se sammenhenger og strukturer. PCA reduserer antall variable til et fåtall “hovedkomponenter” som forklarer mesteparten av variansen i datasettet. Det man får ut av PCA er nye variable som er lineære kombinasjoner av de opprinnelige variablene. Den første hovedkompenenten er den som forklarer mest av varians i variablene. Den andre forklarer nest mest osv. For den første principal component (PC1) får hver variabel en factor loading som forteller hvor mye variabelen bidrar til PC1.\nDet som noen ganger kalles principal component regression er en variant der man bruker den første hovedkomponenten som prediktor i en regresjonsanalyse. Dette tilsvarer å lage en indeks av de opprinnelige variablene.\n\n10.2.1 Empirisk eksempel\nVi starter med datasettet for kriminalitet i norske kommuner, og velger en enkelt årgang for enkelhets skyld. Vi beholder et begrenset sett av variable av ulik art.\n\nkommune &lt;- readRDS( \"data/kommunedata.rds\") %&gt;% \n  filter(year == 2020) %&gt;% \n    mutate(kommune = ifelse(kommune == \"Oslo municipality\", \"Oslo\", kommune)) %&gt;%\n  select(kommune, menn_18_25:menn_18min, inntekt_totalt_median:andre_lovbrudd) %&gt;% \n  select(-inntekt_eskatt_median) %&gt;% \n  column_to_rownames(var = \"kommune\")\n\nglimpse(kommune)\n\nRows: 251\nColumns: 15\n$ menn_18_25             &lt;int&gt; 38847, 857, 8743, 2288, 4520, 189, 1156, 1223, …\n$ menn_26_35             &lt;int&gt; 78059, 1045, 11750, 2811, 6635, 197, 1517, 1540…\n$ menn_36_67             &lt;int&gt; 150390, 3362, 32531, 8827, 18329, 715, 4230, 44…\n$ menn_67plus            &lt;int&gt; 42590, 1344, 10301, 2962, 5599, 293, 1475, 1474…\n$ menn_18min             &lt;int&gt; 36298, 916, 8710, 2238, 5422, 216, 1382, 1404, …\n$ inntekt_totalt_median  &lt;int&gt; 661000, 739000, 764000, 647000, 791000, 716000,…\n$ ant_husholdninger      &lt;int&gt; 348864, 6493, 64617, 17846, 33784, 1331, 7801, …\n$ shj_klienter           &lt;int&gt; 20182, 329, 3929, 1024, 1972, 49, 394, 269, 330…\n$ shj_unge               &lt;int&gt; 2488, 67, 844, 195, 393, 10, 80, 40, 68, 56, 79…\n$ vinningskriminalitet   &lt;dbl&gt; 31.9, 9.7, 22.3, 21.2, 18.1, 5.0, 6.4, 9.3, 19.…\n$ voldskriminalitet      &lt;dbl&gt; 11.0, 3.9, 7.0, 10.3, 6.4, 3.5, 6.5, 4.2, 6.1, …\n$ nark_alko_kriminalitet &lt;dbl&gt; 7.0, 6.9, 7.2, 10.7, 6.4, 3.2, 4.1, 5.3, 6.0, 4…\n$ ordenslovbrudd         &lt;dbl&gt; 10.8, 4.0, 4.9, 10.0, 4.6, 3.5, 3.3, 3.6, 5.0, …\n$ trafikklovbrudd        &lt;dbl&gt; 6.7, 10.2, 5.2, 5.6, 6.8, 5.0, 6.3, 7.1, 6.5, 6…\n$ andre_lovbrudd         &lt;dbl&gt; 18.3, 9.2, 11.5, 12.7, 9.2, 6.3, 8.7, 9.2, 13.4…\n\n\nSå et lite triks som ikke er viktig for resultatet som sådan, men hjelper i visualiseringen litt senere er å bruke radnavn. Vi er kjent med at kolonnene i et datasett har navn: altså variabelnavn. Men i R kan også radene ha navn. Det er ikke like vanlig å bruke til noe spesielt og kan med fordel unngås til vanlig. Men akkurat her gjør det at kommunenavnene vises når vi bruker funksjonen biplot nedenfor. Analyse vil ellers fungere like godt uten denne koden.\nKodesnutten column_to_rownames(var = \"kommune\") gjør om variabelen kommune til radnavn. Da er det bare de numeriske verdiene igjen som skal analyseres.^(Hvis ikke måtte første kollonne fjernes manuelt først før PCA.)\nHvis vi skal visualisere dataene kan man bruke et scatterplot matrise, der alle par av variable plottes mot hverandre. Dette kan gjøres med GGally-pakken, og her er det valgt ut bare noen få av variablene.\n\nlibrary(GGally)\nggpairs(kommune[ ,c(1, 3, 6, 7, 8, 10, 11)])\n\n\n\n\nDette var bare noen få variable, og det gir rett og slett ikke så mye sammenheng. Med flere variable blir det enda vanskeligere å få noe ut av dette.\nI stedet kan vi kjøre en principal component analyse med prcomp. Det er her viktig å sette scale = TRUE og center = TRUE. Dette er innebygde funksjoner som standardiserer dataene før algoritmen kjøres. Altså: dataene re-skaleres til en z-skår med gjennomsnitt 0 og standardavvik 1. Det skal veldig gode grunner for å gjøre noe annet, så gjør alltid dette. Koden nedenfor viser hvordan dette gjøres og gir en oppsummering av resultatet.\n\nlibrary(stats)\npr_komm &lt;- prcomp(kommune, scale = TRUE, center = TRUE)\n\nsummary(pr_komm)\n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5     PC6     PC7\nStandard deviation     2.9168 1.7360 1.0247 0.93725 0.76413 0.62529 0.52844\nProportion of Variance 0.5672 0.2009 0.0700 0.05856 0.03893 0.02607 0.01862\nCumulative Proportion  0.5672 0.7681 0.8381 0.89666 0.93559 0.96165 0.98027\n                           PC8     PC9    PC10    PC11    PC12    PC13    PC14\nStandard deviation     0.45542 0.22179 0.16826 0.09232 0.04158 0.02350 0.01383\nProportion of Variance 0.01383 0.00328 0.00189 0.00057 0.00012 0.00004 0.00001\nCumulative Proportion  0.99410 0.99738 0.99926 0.99983 0.99995 0.99998 1.00000\n                           PC15\nStandard deviation     0.006418\nProportion of Variance 0.000000\nCumulative Proportion  1.000000\n\n\nResultatet vises som en liste over de ulike komponentene. Den første komponenten forklarer mest av variansen, den andre nest mest osv. I dette tilfellet er det 15 komponenter. I praksis bryr vi oss mest om de første par komponentene hvis de forklarer tilstrekkelig av variansen. Her fanger de 3 første komponente opp over 80% av variansen.\nPCA-objektet inneholder flere elementer som vi skal bruke nedenfor. En enkelt måte å få innsikt på er å bruke names-funksjonen slik: names(pr_komm). Men det er først og fremst pr_komm$x og pr_komm$sdev som er interessante. x en matrise med de nye variablene som er lineære kombinasjoner av de opprinnelige variablene, altså et datasett men i matriseformat. sdev er standardavviket for de ulike komponentene, som vistes i første linjen i summary(pr_komm).\nDet er vanlig å undersøke dette visuelt med et såkalt biplot. Dette er et scatterplott av PC1 og PC2 der hver enhet plasseres i forhold til disse. I tillegg vises factor loadings for hver variabel som piler. Dette plottet kan lages manuelt med ggplot, men det er enklere å bruke biplot-funksjonen som er spesielt til dette formålet. Argumentene cex =, cex.axis = og cex.lab = er bare for å justere størrelsen på teksten.\n\npar(mar=c(2,1,2,1))\nbiplot(pr_komm, cex = .4, cex.axis = .6, cex.lab = .6)\n\n\n\n\nDet skal innrømmes at dette plottet er heller ikke så lett å tolke uten videre, men først og fremst fordi en del tekst kommer oppå hverandre. Så kanskje bør man ta en titt på tabellen for factor loadings for de to første komponentene i tillegg.\nDet er en del informasjon i dette plottet. Pilene viser factor loadings for hver variabel som retningen og lengden på pilen. Jo lengre pilen er, jo mer bidrar variabelen til den aktuelle komponenten. Navnet til hver enkelt kommune plassert i forhold til de ulike komponentene.^(Ovenfor var en kodesnutt som la kommunenvanene som radnavn. Hvis du ikke gjør dette kommer det punkter i stedet for navn.) Hvis to kommuner er plassert nærme hverandre, så er de like i forhold til de ulike komponentene. Hvis de er langt fra hverandre, så er de mer ulike. Vi ser bl.a. at Oslo skiller seg markant fra alle andre, men at Bergen og Trondheim er ganske like i samme retning. Eidskog og Storfjord ligger i en ganske annen retning.\nFactor loadings viser hvor mye hver variabel bidrar til den aktuelle komponenten. Dette kan hentes ut med pr_komm$rotation.\n\npr_komm$rotation[,1:2]\n\n                               PC1         PC2\nmenn_18_25             -0.33792095 -0.07587793\nmenn_26_35             -0.33237562 -0.07821625\nmenn_36_67             -0.33821683 -0.07861761\nmenn_67plus            -0.33780595 -0.07199199\nmenn_18min             -0.33784682 -0.08210436\ninntekt_totalt_median  -0.01193920 -0.29303956\nant_husholdninger      -0.33756612 -0.07461240\nshj_klienter           -0.33696954 -0.05772102\nshj_unge               -0.33526870 -0.04465173\nvinningskriminalitet   -0.22517571  0.15789636\nvoldskriminalitet      -0.13166583  0.30314878\nnark_alko_kriminalitet -0.07976900  0.47778643\nordenslovbrudd         -0.10983165  0.47841028\ntrafikklovbrudd         0.02793681  0.27213087\nandre_lovbrudd         -0.07347364  0.47456658\n\n\nVariablene knyttet til befolkningsstruktur, husholdninger og sosialhjelp er de som bidrar mest til PC1. Variablene knyttet til kriminalitet er de som bidrar mest til PC2. Dette er en ganske vanlig situasjon: at ulike typer variabler grupperer seg sammen.\nVinningskriminalitet og voldskriminalitet har ganske lik factor loading. Det samme gjelder for ordenslovbrudd og lovbrudd knyttet til narkotika eller alkohol. Trafikklovbrudd skiller seg derimot en del fra de andre.\nDet er også mulig å hente ut annen informasjon fra PCA-objektet. For å se på factor loadings for hver kommune kan vi undersøke x-matrisen i pca-objektet slik:\n\nhead(pr_komm$x)\n\n                  PC1        PC2         PC3        PC4         PC5        PC6\nOslo      -36.2152871 -3.3589170 -3.61987278  1.5796871  1.69548317 -1.5205907\nEigersund   0.3255626 -0.2584199 -0.03666622 -0.9807707 -0.02031745  0.4910471\nStavanger  -7.5958070 -0.6954589  0.85631587 -0.8439319 -0.55236111  0.6868140\nHaugesund  -2.2591243  3.0407132  2.45903993  0.3473917 -0.75265692  0.4190413\nSandnes    -3.6550792 -0.6421373  1.04457813 -1.1874560 -0.79853612  0.3761694\nLund        1.3080115 -1.3580525  0.07262183 -0.1467664  0.46478544  0.2748177\n                 PC7         PC8         PC9       PC10        PC11\nOslo       0.8429949 -0.13723957  1.59973261 0.34396760 -0.13713995\nEigersund -0.3297569  0.23264668  0.12130524 0.06690595  0.01749551\nStavanger -0.3576591 -0.38915833 -0.98765200 0.47566254 -0.15554017\nHaugesund  0.3222269  0.33884799  0.16635971 0.02685071  0.05791093\nSandnes   -0.1232278 -0.08447287 -0.19051611 0.07485071 -0.03172295\nLund       0.2711364  0.37422030  0.07565397 0.09404634  0.02400264\n                  PC12         PC13         PC14          PC15\nOslo       0.003217221  0.015726770  0.006527252  4.225039e-03\nEigersund  0.023459796  0.007227856  0.005629813 -6.671129e-03\nStavanger -0.272292222  0.046925140 -0.078905279  5.997904e-05\nHaugesund -0.018734038 -0.004144584 -0.048563010  4.208489e-03\nSandnes   -0.302434770  0.044195747  0.056770766 -2.383804e-02\nLund      -0.012819552 -0.005538676 -0.003225749  4.169959e-03\n\n\nDette er en matrise med de nye variablene som er lineære kombinasjoner av de opprinnelige variablene. Hver rad er en kommune, og hver kolonne er en utregnet komponent.\nStandardavviket for de ulike komponentene er gitt i pr_komm$sdev. Dette kan brukes til å regne ut andelen av variansen som forklares av hver komponent. Vi kan også plotte dette.\n\npvar &lt;- pr_komm$sdev^2   # kvadrerte standardavvik (dvs. variansen)\npve &lt;- pvar/sum(pvar)    # Hver komponents andel av variansen\n\n\n# Hver komponents andel av variansen lagres i en data.frame for å kunne plottes med ggplot\ndt &lt;- data.frame(components = 1:length(pve), prop_var_expl = pve)\n\nggplot(dt, aes(x = components, y = prop_var_expl))+ \n  geom_line()+\n  geom_point()\n\n\n\n\nDette er en visualisering av hvor mye hver komponent bidrar til å forklare variansen i datasettet. Vi ser at de første komponentene forklarer mest, og at det flater ut etter hvert. Der hvor kurven flates ut med en “albue” er et godt sted å stoppe. I dette tilfellet er det etter 3 komponenter som summerer opp det meste av dataene.\nSlik sett er datasettet redusert fra 15 variable til 3. Der de opprinnelige variablene var korrelerte i varierende grad, så er de tre nye variablene ikke korrelerte, men representerer ulike dimensjoner. Merk at de nye variablene beholder det aller meste av informasjonen i de opprinnelige dataene (jf. plottet over), og er mye mer effektivt enn å bruke alle de opprinnelige variablene i en regresjonsanalyse eller bare plukke ut noen få som tilsynelatende er viktigst isolert sett."
  },
  {
    "objectID": "unsupervised.html#footnotes",
    "href": "unsupervised.html#footnotes",
    "title": "10  Unsupervised learning",
    "section": "",
    "text": "OBS! Det spiller ingen rolle om disse gruppene er reelle som gruppe eller ikke. At de oppfører seg rimelig likt holder til formålet.↩︎\nAv høflighetsgrunner er referanser til eksempler utelatt. Men det er ikke vanskelig å finne. Eksemplene er heller ikke avgrenset til akkurat disse metodene, men gjelder også en rekke andre teknikker med tilsvarende formål.↩︎\nDet er muligens greit for de av dere som har lært en god del R tidligere. Ikke like greit for dere andre. ↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Berk, Richard. 2016. Statistical Learning from a Regression\nPerspective. USA: Springer.\n\n\nBerk, Richard A., Susan B. Sorenson, and Geoffrey Barnes. 2016.\n“Forecasting Domestic Violence: A Machine Learning Approach to\nHelp Inform Arraignment Decisions.” Journal of Empirical\nLegal Studies 13: 94–115. https://doi.org/10.1111/jels.12098.\n\n\nCaspi, Avshalom, Renate M. Houts, Daniel W. Belsky, Honalee Harrington,\nSean Hogan, Sandhya Ramrakha, Richie Poulton, and Terrie E. Moffitt.\n2017. “Childhood Forecasting of a Small Segment of the Population\nwith Large Economic Burden.” Nature Human Behavior 1\n(5): 223–40. https://doi.org/https://doi-org.ezproxy.uio.no/10.1038/s41562-016-0005.\n\n\nHsieh, John. 2008. “Receiver Operating Characteristic (ROC)\nCurve.” In Encyclopedia of Epidemiology, 895–98.\nThousand Oaks, California: Sage. https://doi.org/10.4135/9781412953948.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data\nScience. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley."
  },
  {
    "objectID": "datasets.html#credit",
    "href": "datasets.html#credit",
    "title": "Appendix A — Datasett",
    "section": "A.1 Credit",
    "text": "A.1 Credit\nUtfallsvariabel: “default” (misligholdelse av lån) Data er hentet fra datacamp.com, men du kan laste de ned fra denne lenken.\nDataene inneholder følgende variable:\n\ncredit &lt;- read.csv(\"data/credit.csv\", stringsAsFactors = TRUE)\n\nglimpse(credit)\n\nRows: 1,000\nColumns: 17\n$ checking_balance     &lt;fct&gt; &lt; 0 DM, 1 - 200 DM, unknown, &lt; 0 DM, &lt; 0 DM, unkn…\n$ months_loan_duration &lt;int&gt; 6, 48, 12, 42, 24, 36, 24, 36, 12, 30, 12, 48, 12…\n$ credit_history       &lt;fct&gt; critical, good, critical, good, poor, good, good,…\n$ purpose              &lt;fct&gt; furniture/appliances, furniture/appliances, educa…\n$ amount               &lt;int&gt; 1169, 5951, 2096, 7882, 4870, 9055, 2835, 6948, 3…\n$ savings_balance      &lt;fct&gt; unknown, &lt; 100 DM, &lt; 100 DM, &lt; 100 DM, &lt; 100 DM, …\n$ employment_duration  &lt;fct&gt; &gt; 7 years, 1 - 4 years, 4 - 7 years, 4 - 7 years,…\n$ percent_of_income    &lt;int&gt; 4, 2, 2, 2, 3, 2, 3, 2, 2, 4, 3, 3, 1, 4, 2, 4, 4…\n$ years_at_residence   &lt;int&gt; 4, 2, 3, 4, 4, 4, 4, 2, 4, 2, 1, 4, 1, 4, 4, 2, 4…\n$ age                  &lt;int&gt; 67, 22, 49, 45, 53, 35, 53, 35, 61, 28, 25, 24, 2…\n$ other_credit         &lt;fct&gt; none, none, none, none, none, none, none, none, n…\n$ housing              &lt;fct&gt; own, own, own, other, other, other, own, rent, ow…\n$ existing_loans_count &lt;int&gt; 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2…\n$ job                  &lt;fct&gt; skilled, skilled, unskilled, skilled, skilled, un…\n$ dependents           &lt;int&gt; 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ phone                &lt;fct&gt; yes, no, no, no, no, yes, no, yes, no, no, no, no…\n$ default              &lt;fct&gt; no, yes, no, no, yes, no, no, no, no, yes, yes, y…\n\n\n:::"
  },
  {
    "objectID": "datasets.html#attrition",
    "href": "datasets.html#attrition",
    "title": "Appendix A — Datasett",
    "section": "A.2 Attrition",
    "text": "A.2 Attrition\nUtfallsvariabel: “Attrition”, dvs om en arbeidstaker slutter i jobben.\nDatasettet er tilgjengelig fra Kaggle, men du kan laste de ned fra denne lenken\n\nattrition &lt;- readRDS(\"data/Attrition.rds\")\nglimpse(attrition)\n\nRows: 1,470\nColumns: 32\n$ Age                      &lt;int&gt; 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35, 2…\n$ Attrition                &lt;fct&gt; Yes, No, Yes, No, No, No, No, No, No, No, No,…\n$ BusinessTravel           &lt;fct&gt; Travel_Rarely, Travel_Frequently, Travel_Rare…\n$ DailyRate                &lt;int&gt; 1102, 279, 1373, 1392, 591, 1005, 1324, 1358,…\n$ Department               &lt;fct&gt; Sales, Research & Development, Research & Dev…\n$ DistanceFromHome         &lt;int&gt; 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26, …\n$ Education                &lt;int&gt; 2, 1, 2, 4, 1, 2, 3, 1, 3, 3, 3, 2, 1, 2, 3, …\n$ EducationField           &lt;fct&gt; Life Sciences, Life Sciences, Other, Life Sci…\n$ EmployeeNumber           &lt;int&gt; 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16,…\n$ EnvironmentSatisfaction  &lt;int&gt; 2, 3, 4, 4, 1, 4, 3, 4, 4, 3, 1, 4, 1, 2, 3, …\n$ Gender                   &lt;fct&gt; Female, Male, Male, Female, Male, Male, Femal…\n$ HourlyRate               &lt;int&gt; 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84, 4…\n$ JobInvolvement           &lt;int&gt; 3, 2, 2, 3, 3, 3, 4, 3, 2, 3, 4, 2, 3, 3, 2, …\n$ JobLevel                 &lt;int&gt; 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, …\n$ JobRole                  &lt;fct&gt; Sales Executive, Research Scientist, Laborato…\n$ JobSatisfaction          &lt;int&gt; 4, 2, 3, 3, 2, 4, 1, 3, 3, 3, 2, 3, 3, 4, 3, …\n$ MaritalStatus            &lt;fct&gt; Single, Married, Single, Married, Married, Si…\n$ MonthlyIncome            &lt;int&gt; 5993, 5130, 2090, 2909, 3468, 3068, 2670, 269…\n$ MonthlyRate              &lt;int&gt; 19479, 24907, 2396, 23159, 16632, 11864, 9964…\n$ NumCompaniesWorked       &lt;int&gt; 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5, …\n$ OverTime                 &lt;fct&gt; Yes, No, Yes, Yes, No, No, Yes, No, No, No, N…\n$ PercentSalaryHike        &lt;int&gt; 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13, 1…\n$ PerformanceRating        &lt;int&gt; 3, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, …\n$ RelationshipSatisfaction &lt;int&gt; 1, 4, 2, 3, 4, 3, 1, 2, 2, 2, 3, 4, 4, 3, 2, …\n$ StockOptionLevel         &lt;int&gt; 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, 0, …\n$ TotalWorkingYears        &lt;int&gt; 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5, 3…\n$ TrainingTimesLastYear    &lt;int&gt; 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, 4, …\n$ WorkLifeBalance          &lt;int&gt; 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, …\n$ YearsAtCompany           &lt;int&gt; 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, 4,…\n$ YearsInCurrentRole       &lt;int&gt; 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, 2, …\n$ YearsSinceLastPromotion  &lt;int&gt; 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0, …\n$ YearsWithCurrManager     &lt;int&gt; 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, 3, …"
  },
  {
    "objectID": "datasets.html#kommunedata",
    "href": "datasets.html#kommunedata",
    "title": "Appendix A — Datasett",
    "section": "A.3 Kommunedata",
    "text": "A.3 Kommunedata\nDisse dataene er hentet fra SSBs offisielle statistikk og koblet sammen på kommunenummer. Fra statistikkbanken tabeller nr. 06944 (inntekt), 12210 (sosialhjelp/KOSTRA), 07459 (befolkning), 08487 (anmeldte lovbrudd). Flere variable kan kobles på. Merk: det er flere endringer i kommunestruktur, særlig i 2020. Kommunene er altså ikke helt det samme over tid. Du kan laste de ned fra denne lenken\nAktuelle utfallsvariable: Flere variable kan være aktuell som utfallsvariable. Prediktorer må nok omarbeides noe etter egne vurderinger (f.eks. omregne til per 1000 eller prosent, summere totaltall etc).\n\nkommune &lt;- readRDS(\"data/kommunedata.rds\")\nglimpse(kommune)\n\nRows: 1,529\nColumns: 28\n$ kommune_nr             &lt;chr&gt; \"0101\", \"0101\", \"0101\", \"0101\", \"0104\", \"0104\",…\n$ kommune                &lt;chr&gt; \"Halden (-2019)\", \"Halden (-2019)\", \"Halden (-2…\n$ year                   &lt;dbl&gt; 2015, 2016, 2017, 2018, 2015, 2016, 2017, 2018,…\n$ bef_18min              &lt;int&gt; 3556, 3503, 3505, 3544, 3594, 3652, 3704, 3655,…\n$ bef_18_25              &lt;int&gt; 3575, 3585, 3432, 3438, 3405, 3404, 3355, 3370,…\n$ bef_26_35              &lt;int&gt; 3728, 3804, 3985, 4035, 4057, 4071, 4124, 4110,…\n$ bef_totalt             &lt;int&gt; 30328, 30544, 30790, 31037, 31802, 32182, 32407…\n$ menn_18_25             &lt;int&gt; 1847, 1865, 1813, 1819, 1789, 1802, 1789, 1810,…\n$ menn_26_35             &lt;int&gt; 1880, 1919, 2005, 2062, 2063, 2083, 2113, 2134,…\n$ menn_36_67             &lt;int&gt; 7067, 7051, 7085, 7057, 7418, 7453, 7408, 7407,…\n$ menn_67plus            &lt;int&gt; 2496, 2624, 2697, 2806, 2671, 2777, 2856, 2895,…\n$ menn_18min             &lt;int&gt; 1880, 1847, 1873, 1876, 1842, 1885, 1919, 1878,…\n$ kvinner_18_25          &lt;int&gt; 1728, 1720, 1619, 1619, 1616, 1602, 1566, 1560,…\n$ kvinner_26_35          &lt;int&gt; 1848, 1885, 1980, 1973, 1994, 1988, 2011, 1976,…\n$ kvinner_36_67          &lt;int&gt; 6880, 6832, 6844, 6848, 7479, 7519, 7537, 7596,…\n$ kvinner_67plus         &lt;int&gt; 3026, 3145, 3242, 3309, 3178, 3306, 3423, 3555,…\n$ kvinner_18min          &lt;int&gt; 1676, 1656, 1632, 1668, 1752, 1767, 1785, 1777,…\n$ inntekt_totalt_median  &lt;int&gt; 555000, 562000, 580000, 591000, 561000, 568000,…\n$ inntekt_eskatt_median  &lt;int&gt; 451000, 453000, 470000, 480000, 449000, 456000,…\n$ ant_husholdninger      &lt;int&gt; 13890, 14124, 14281, 14454, 15046, 15132, 15313…\n$ shj_klienter           &lt;int&gt; 1183, 1137, 1099, 1128, 1155, 1129, 1152, 1137,…\n$ shj_unge               &lt;int&gt; 262, 247, 248, 242, 267, 263, 238, 222, 307, 28…\n$ vinningskriminalitet   &lt;dbl&gt; 19.7, 18.7, 16.5, 14.5, 24.5, 21.5, 18.0, 18.0,…\n$ voldskriminalitet      &lt;dbl&gt; 11.2, 12.6, 12.3, 11.2, 7.8, 8.3, 8.7, 9.7, 6.8…\n$ nark_alko_kriminalitet &lt;dbl&gt; 21.0, 21.9, 21.0, 20.3, 12.0, 10.2, 10.9, 10.1,…\n$ ordenslovbrudd         &lt;dbl&gt; 18.5, 16.5, 14.9, 13.7, 8.9, 9.0, 9.1, 9.2, 8.2…\n$ trafikklovbrudd        &lt;dbl&gt; 15.5, 16.3, 16.7, 19.2, 7.4, 6.3, 6.9, 8.0, 9.6…\n$ andre_lovbrudd         &lt;dbl&gt; 25.5, 26.5, 26.1, 25.2, 12.1, 12.2, 11.9, 12.4,…"
  },
  {
    "objectID": "datasets.html#churn",
    "href": "datasets.html#churn",
    "title": "Appendix A — Datasett",
    "section": "A.4 Churn",
    "text": "A.4 Churn\nDisse dataene er simulerte, men omhandler kunder i et teleselskap og hvorvidt de går over til annen tilbyder. Du kan laste de ned i csv-format fra denne lenken\n\nchurn &lt;- read.csv(\"data/WA_Fn-UseC_-Telco-Customer-Churn.csv\", stringsAsFactors = TRUE)\nglimpse(churn)\n\nRows: 7,043\nColumns: 21\n$ customerID       &lt;fct&gt; 7590-VHVEG, 5575-GNVDE, 3668-QPYBK, 7795-CFOCW, 9237-…\n$ gender           &lt;fct&gt; Female, Male, Male, Male, Female, Female, Male, Femal…\n$ SeniorCitizen    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Partner          &lt;fct&gt; Yes, No, No, No, No, No, No, No, Yes, No, Yes, No, Ye…\n$ Dependents       &lt;fct&gt; No, No, No, No, No, No, Yes, No, No, Yes, Yes, No, No…\n$ tenure           &lt;int&gt; 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 58, 49, 2…\n$ PhoneService     &lt;fct&gt; No, Yes, Yes, No, Yes, Yes, Yes, No, Yes, Yes, Yes, Y…\n$ MultipleLines    &lt;fct&gt; No phone service, No, No, No phone service, No, Yes, …\n$ InternetService  &lt;fct&gt; DSL, DSL, DSL, DSL, Fiber optic, Fiber optic, Fiber o…\n$ OnlineSecurity   &lt;fct&gt; No, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Yes, No …\n$ OnlineBackup     &lt;fct&gt; Yes, No, Yes, No, No, No, Yes, No, No, Yes, No, No in…\n$ DeviceProtection &lt;fct&gt; No, Yes, No, Yes, No, Yes, No, No, Yes, No, No, No in…\n$ TechSupport      &lt;fct&gt; No, No, No, Yes, No, No, No, No, Yes, No, No, No inte…\n$ StreamingTV      &lt;fct&gt; No, No, No, No, No, Yes, Yes, No, Yes, No, No, No int…\n$ StreamingMovies  &lt;fct&gt; No, No, No, No, No, Yes, No, No, Yes, No, No, No inte…\n$ Contract         &lt;fct&gt; Month-to-month, One year, Month-to-month, One year, M…\n$ PaperlessBilling &lt;fct&gt; Yes, No, Yes, No, Yes, Yes, Yes, No, Yes, No, Yes, No…\n$ PaymentMethod    &lt;fct&gt; Electronic check, Mailed check, Mailed check, Bank tr…\n$ MonthlyCharges   &lt;dbl&gt; 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89.10, 29.7…\n$ TotalCharges     &lt;dbl&gt; 29.85, 1889.50, 108.15, 1840.75, 151.65, 820.50, 1949…\n$ Churn            &lt;fct&gt; No, No, Yes, No, Yes, Yes, No, No, Yes, No, No, No, N…"
  },
  {
    "objectID": "datasets.html#recidivism-from-iowa-prisons",
    "href": "datasets.html#recidivism-from-iowa-prisons",
    "title": "Appendix A — Datasett",
    "section": "A.5 Recidivism from Iowa prisons",
    "text": "A.5 Recidivism from Iowa prisons\nDatasettet inneholder data på 26020 personer løslatt fra fengsel i staten Iowa, USA mellom 2010 og 2015. For hver person er det informasjon om hvorvidt de har blitt fengslet på nytt innen 3 år (dvs. fulgt til mellom 2013 og 2018).\nAktuell utfallsvariabel: “Recidivism…Return.to.Prison.numeric” Endre gjerne variabelnavn til noe kortere.\nDatasettet er tilgjengelig fra Kaggle og er nærmere omtalt der. Du kan laste de ned i csv-format fra denne lenken.\n\nrecidivism &lt;- read.csv(\"data/3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated.csv\", stringsAsFactors = TRUE)\n\nglimpse(recidivism)\n\nRows: 26,020\nColumns: 12\n$ Fiscal.Year.Released                      &lt;int&gt; 2010, 2010, 2010, 2010, 2010…\n$ Recidivism.Reporting.Year                 &lt;int&gt; 2013, 2013, 2013, 2013, 2013…\n$ Race...Ethnicity                          &lt;fct&gt; White - Non-Hispanic, White …\n$ Age.At.Release                            &lt;fct&gt; Under 25, 55 and Older, 25-3…\n$ Convicting.Offense.Classification         &lt;fct&gt; D Felony, D Felony, D Felony…\n$ Convicting.Offense.Type                   &lt;fct&gt; Violent, Public Order, Prope…\n$ Convicting.Offense.Subtype                &lt;fct&gt; Assault, OWI, Burglary, Traf…\n$ Main.Supervising.District                 &lt;fct&gt; 4JD, 7JD, 5JD, 8JD, 3JD, , 3…\n$ Release.Type                              &lt;fct&gt; Parole, Parole, Parole, Paro…\n$ Release.type..Paroled.to.Detainder.united &lt;fct&gt; Parole, Parole, Parole, Paro…\n$ Part.of.Target.Population                 &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, No,…\n$ Recidivism...Return.to.Prison.numeric     &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…"
  },
  {
    "objectID": "datasets.html#compas",
    "href": "datasets.html#compas",
    "title": "Appendix A — Datasett",
    "section": "A.6 Compas",
    "text": "A.6 Compas\nUtfallsvariabel: “Two_yr_Revidvism”\nData er hentet fra R-pakken fairmodels, modifisert datsett fra ProPublica, men du kan laste de ned i rds-format fra denne lenken.\n\ncompas &lt;- readRDS(\"data/compas.rds\")\nglimpse(compas)\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    &lt;fct&gt; 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     &lt;int&gt; 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive &lt;fct&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive &lt;fct&gt; 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          &lt;fct&gt; 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            &lt;fct&gt; Other, African_American, African_American, Other,…\n$ Sex                  &lt;fct&gt; Male, Male, Male, Male, Male, Male, Female, Male,…"
  },
  {
    "objectID": "datasets.html#diabetes-rehospitalization",
    "href": "datasets.html#diabetes-rehospitalization",
    "title": "Appendix A — Datasett",
    "section": "A.7 Diabetes rehospitalization",
    "text": "A.7 Diabetes rehospitalization\nData er beskrevet nærmere i Strack et al (2014) (se særlig tabell 1) og er tilgjengelig fra UCI machine learning repository. Du kan laste ned datasettet fra denne lenken.\nUtfallsvariabelen av interesse er readmitted, altså om pasienten blir lagt inn på nytt på et eller annet tidspunkt etter utskrivning.\n\ndiabetic &lt;- read.csv(\"data/diabetic_data.csv\", stringsAsFactors = TRUE)\nglimpse(diabetic)\n\nRows: 101,766\nColumns: 50\n$ encounter_id             &lt;int&gt; 2278392, 149190, 64410, 500364, 16680, 35754,…\n$ patient_nbr              &lt;int&gt; 8222157, 55629189, 86047875, 82442376, 425192…\n$ race                     &lt;fct&gt; Caucasian, Caucasian, AfricanAmerican, Caucas…\n$ gender                   &lt;fct&gt; Female, Female, Female, Male, Male, Male, Mal…\n$ age                      &lt;fct&gt; [0-10), [10-20), [20-30), [30-40), [40-50), […\n$ weight                   &lt;fct&gt; ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, …\n$ admission_type_id        &lt;int&gt; 6, 1, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 1, 3, …\n$ discharge_disposition_id &lt;int&gt; 25, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 6, 1,…\n$ admission_source_id      &lt;int&gt; 1, 7, 7, 7, 7, 2, 2, 7, 4, 4, 7, 4, 7, 7, 2, …\n$ time_in_hospital         &lt;int&gt; 1, 3, 2, 2, 1, 3, 4, 5, 13, 12, 9, 7, 7, 10, …\n$ payer_code               &lt;fct&gt; ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, …\n$ medical_specialty        &lt;fct&gt; Pediatrics-Endocrinology, ?, ?, ?, ?, ?, ?, ?…\n$ num_lab_procedures       &lt;int&gt; 41, 59, 11, 44, 51, 31, 70, 73, 68, 33, 47, 6…\n$ num_procedures           &lt;int&gt; 0, 0, 5, 1, 0, 6, 1, 0, 2, 3, 2, 0, 0, 1, 5, …\n$ num_medications          &lt;int&gt; 1, 18, 13, 16, 8, 16, 21, 12, 28, 18, 17, 11,…\n$ number_outpatient        &lt;int&gt; 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ number_emergency         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ number_inpatient         &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ diag_1                   &lt;fct&gt; 250.83, 276, 648, 8, 197, 414, 414, 428, 398,…\n$ diag_2                   &lt;fct&gt; ?, 250.01, 250, 250.43, 157, 411, 411, 492, 4…\n$ diag_3                   &lt;fct&gt; ?, 255, V27, 403, 250, 250, V45, 250, 38, 486…\n$ number_diagnoses         &lt;int&gt; 1, 9, 6, 7, 5, 9, 7, 8, 8, 8, 9, 7, 8, 8, 8, …\n$ max_glu_serum            &lt;fct&gt; None, None, None, None, None, None, None, Non…\n$ A1Cresult                &lt;fct&gt; None, None, None, None, None, None, None, Non…\n$ metformin                &lt;fct&gt; No, No, No, No, No, No, Steady, No, No, No, N…\n$ repaglinide              &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ nateglinide              &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ chlorpropamide           &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ glimepiride              &lt;fct&gt; No, No, No, No, No, No, Steady, No, No, No, N…\n$ acetohexamide            &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ glipizide                &lt;fct&gt; No, No, Steady, No, Steady, No, No, No, Stead…\n$ glyburide                &lt;fct&gt; No, No, No, No, No, No, No, Steady, No, No, N…\n$ tolbutamide              &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ pioglitazone             &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ rosiglitazone            &lt;fct&gt; No, No, No, No, No, No, No, No, No, Steady, N…\n$ acarbose                 &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ miglitol                 &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ troglitazone             &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ tolazamide               &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ examide                  &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ citoglipton              &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ insulin                  &lt;fct&gt; No, Up, No, Up, Steady, Steady, Steady, No, S…\n$ glyburide.metformin      &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ glipizide.metformin      &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ glimepiride.pioglitazone &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ metformin.rosiglitazone  &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ metformin.pioglitazone   &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, N…\n$ change                   &lt;fct&gt; No, Ch, No, Ch, Ch, No, Ch, No, Ch, Ch, No, C…\n$ diabetesMed              &lt;fct&gt; No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Y…\n$ readmitted               &lt;fct&gt; NO, &gt;30, NO, NO, NO, &gt;30, NO, &gt;30, NO, NO, &gt;3…"
  },
  {
    "objectID": "datasets.html#absenteeism",
    "href": "datasets.html#absenteeism",
    "title": "Appendix A — Datasett",
    "section": "A.8 Absenteeism",
    "text": "A.8 Absenteeism\nDette er et syntetisk datasett som inneholder 8336 personer i en tenkt bedrift og hvor mange timer hver person har fravær fra jobben.\nData er tilgjengelig fra Kaggle, men du kan laste ned datasettet fra denne lenken.\n\nabsenteeism &lt;- read.csv(\"data/MFGEmployees4.csv\", stringsAsFactors = TRUE)\nglimpse(absenteeism)\n\nRows: 8,336\nColumns: 13\n$ EmployeeNumber &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ Surname        &lt;fct&gt; Gutierrez, Hardwick, Delgado, Simon, Delvalle, Jones, B…\n$ GivenName      &lt;fct&gt; Molly, Stephen, Chester, Irene, Edward, Ernie, Ralph, G…\n$ Gender         &lt;fct&gt; F, M, M, F, M, M, M, M, M, M, M, M, M, F, M, M, F, F, F…\n$ City           &lt;fct&gt; Burnaby, Courtenay, Richmond, Victoria, New Westminster…\n$ JobTitle       &lt;fct&gt; \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"…\n$ DepartmentName &lt;fct&gt; Bakery, Bakery, Bakery, Bakery, Bakery, Bakery, Account…\n$ StoreLocation  &lt;fct&gt; Burnaby, Nanaimo, Richmond, Victoria, New Westminster, …\n$ Division       &lt;fct&gt; Stores, Stores, Stores, Stores, Stores, Stores, Finance…\n$ Age            &lt;dbl&gt; 32.02882, 40.32090, 48.82205, 44.59936, 35.69788, 48.44…\n$ LengthService  &lt;dbl&gt; 6.018478, 5.532445, 4.389973, 3.081736, 3.619091, 2.717…\n$ AbsentHours    &lt;dbl&gt; 36.57731, 30.16507, 83.80780, 70.02017, 0.00000, 81.830…\n$ BusinessUnit   &lt;fct&gt; Stores, Stores, Stores, Stores, Stores, Stores, HeadOff…"
  },
  {
    "objectID": "datasets.html#human-resources-hr",
    "href": "datasets.html#human-resources-hr",
    "title": "Appendix A — Datasett",
    "section": "A.9 Human resources (HR)",
    "text": "A.9 Human resources (HR)\nData er tilgjengelig fra Kaggle og variable er beskrevet nærmere på denne lenken. Du kan laste ned datasettet fra denne lenken.\n\nhr &lt;- read.csv(\"data/HRDataset_v14.csv\", stringsAsFactors = TRUE)\nglimpse(hr)\n\nRows: 311\nColumns: 36\n$ Employee_Name              &lt;fct&gt; \"Adinolfi, Wilson  K\", \"Ait Sidi, Karthikey…\n$ EmpID                      &lt;int&gt; 10026, 10084, 10196, 10088, 10069, 10002, 1…\n$ MarriedID                  &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0…\n$ MaritalStatusID            &lt;int&gt; 0, 1, 1, 1, 2, 0, 0, 4, 0, 2, 1, 1, 2, 0, 2…\n$ GenderID                   &lt;int&gt; 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1…\n$ EmpStatusID                &lt;int&gt; 1, 5, 5, 1, 5, 1, 1, 1, 3, 1, 5, 5, 1, 1, 5…\n$ DeptID                     &lt;int&gt; 5, 3, 5, 5, 5, 5, 4, 5, 5, 3, 5, 5, 3, 5, 5…\n$ PerfScoreID                &lt;int&gt; 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3…\n$ FromDiversityJobFairID     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0…\n$ Salary                     &lt;int&gt; 62506, 104437, 64955, 64991, 50825, 57568, …\n$ Termd                      &lt;int&gt; 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1…\n$ PositionID                 &lt;int&gt; 19, 27, 20, 19, 19, 19, 24, 19, 19, 14, 19,…\n$ Position                   &lt;fct&gt; Production Technician I, Sr. DBA, Productio…\n$ State                      &lt;fct&gt; MA, MA, MA, MA, MA, MA, MA, MA, MA, MA, MA,…\n$ Zip                        &lt;int&gt; 1960, 2148, 1810, 1886, 2169, 1844, 2110, 2…\n$ DOB                        &lt;fct&gt; 07/10/83, 05/05/75, 09/19/88, 09/27/88, 09/…\n$ Sex                        &lt;fct&gt; M , M , F, F, F, F, F, M , F, M , F, M , M …\n$ MaritalDesc                &lt;fct&gt; Single, Married, Married, Married, Divorced…\n$ CitizenDesc                &lt;fct&gt; US Citizen, US Citizen, US Citizen, US Citi…\n$ HispanicLatino             &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, Yes…\n$ RaceDesc                   &lt;fct&gt; White, White, White, White, White, White, W…\n$ DateofHire                 &lt;fct&gt; 7/5/2011, 3/30/2015, 7/5/2011, 1/7/2008, 7/…\n$ DateofTermination          &lt;fct&gt; , 6/16/2016, 9/24/2012, , 9/6/2016, , , , ,…\n$ TermReason                 &lt;fct&gt; \"N/A-StillEmployed\", \"career change\", \"hour…\n$ EmploymentStatus           &lt;fct&gt; Active, Voluntarily Terminated, Voluntarily…\n$ Department                 &lt;fct&gt; Production       , IT/IS, Production       …\n$ ManagerName                &lt;fct&gt; Michael Albert, Simon Roup, Kissy Sullivan,…\n$ ManagerID                  &lt;int&gt; 22, 4, 20, 16, 39, 11, 10, 19, 12, 7, 14, 2…\n$ RecruitmentSource          &lt;fct&gt; LinkedIn, Indeed, LinkedIn, Indeed, Google …\n$ PerformanceScore           &lt;fct&gt; Exceeds, Fully Meets, Fully Meets, Fully Me…\n$ EngagementSurvey           &lt;dbl&gt; 4.60, 4.96, 3.02, 4.84, 5.00, 5.00, 3.04, 5…\n$ EmpSatisfaction            &lt;int&gt; 5, 3, 3, 5, 4, 5, 3, 4, 3, 5, 4, 3, 4, 4, 5…\n$ SpecialProjectsCount       &lt;int&gt; 0, 6, 0, 0, 0, 0, 4, 0, 0, 6, 0, 0, 5, 0, 0…\n$ LastPerformanceReview_Date &lt;fct&gt; 1/17/2019, 2/24/2016, 5/15/2012, 1/3/2019, …\n$ DaysLateLast30             &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Absences                   &lt;int&gt; 1, 17, 3, 15, 2, 15, 19, 19, 4, 16, 12, 15,…"
  },
  {
    "objectID": "datasets.html#nettverk",
    "href": "datasets.html#nettverk",
    "title": "Appendix A — Datasett",
    "section": "A.10 Nettverk",
    "text": "A.10 Nettverk\nDu kan laste ned datasettet fra denne lenken.\n\nload(\"data/networkExample.RData\")\nglimpse(dataset)\n\nRows: 926\nColumns: 26\n$ degree               &lt;dbl&gt; 0.006282723, 0.002094241, 0.002094241, 0.00104712…\n$ betweenness          &lt;dbl&gt; 0.0081438885, 0.0020810695, 0.0014569424, 0.00000…\n$ closeness            &lt;dbl&gt; 0.08535931, 0.08049562, 0.08226376, 0.07795282, 0…\n$ transitivity         &lt;dbl&gt; 0.13333333, 0.00000000, 0.00000000, 0.00000000, 0…\n$ triangles            &lt;dbl&gt; 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0…\n$ ChurnNeighbors       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ NonChurnNeighbors    &lt;dbl&gt; 6, 2, 2, 1, 3, 5, 2, 2, 2, 6, 2, 3, 6, 2, 3, 2, 2…\n$ Neighbors            &lt;dbl&gt; 6, 2, 2, 1, 3, 5, 2, 2, 3, 6, 2, 3, 6, 2, 3, 2, 2…\n$ RelationalNeighbor   &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.000…\n$ ChurnNeighbors2      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ NonChurnNeighbors2   &lt;dbl&gt; 18, 4, 8, 4, 5, 19, 6, 8, 11, 15, 7, 6, 27, 4, 6,…\n$ RelationalNeighbor2  &lt;dbl&gt; 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0…\n$ degree2              &lt;dbl&gt; 0.026178010, 0.006282723, 0.010471204, 0.00523560…\n$ averageDegree        &lt;dbl&gt; 0.004363002, 0.003141361, 0.005235602, 0.00523560…\n$ averageDegree2       &lt;dbl&gt; 0.004188482, 0.004973822, 0.004581152, 0.00549738…\n$ averageTransitivity  &lt;dbl&gt; 0.13888889, 0.05000000, 0.03333333, 0.10000000, 0…\n$ averageTransitivity2 &lt;dbl&gt; 0.11415344, 0.10833333, 0.22777778, 0.18511905, 0…\n$ averageBetweenness   &lt;dbl&gt; 0.005713676, 0.004259980, 0.008147263, 0.00623771…\n$ averageBetweenness2  &lt;dbl&gt; 0.006733850, 0.008557955, 0.007690396, 0.00625752…\n$ averageTriangles     &lt;dbl&gt; 0.8333333, 0.5000000, 0.5000000, 1.0000000, 0.000…\n$ averageTriangles2    &lt;dbl&gt; 0.7777778, 1.2500000, 0.7500000, 1.7500000, 0.400…\n$ pr_0.85              &lt;dbl&gt; 0.0016432968, 0.0008315249, 0.0006479747, 0.00040…\n$ pr_0.20              &lt;dbl&gt; 0.0011679051, 0.0010706518, 0.0009325680, 0.00088…\n$ perspr_0.85          &lt;dbl&gt; 0.0016432968, 0.0008315249, 0.0006479747, 0.00040…\n$ perspr_0.99          &lt;dbl&gt; 0.0017826047, 0.0006187399, 0.0006012571, 0.00030…\n$ Future               &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…"
  },
  {
    "objectID": "datasets.html#occupational-wage-data",
    "href": "datasets.html#occupational-wage-data",
    "title": "Appendix A — Datasett",
    "section": "A.11 Occupational wage data",
    "text": "A.11 Occupational wage data\nDu kan laste ned datasettet fra denne lenken.\n\noes &lt;- readRDS(\"data/oes.rds\")\nglimpse(oes)\n\n num [1:22, 1:15] 70800 50580 60350 56330 49710 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:22] \"Management\" \"Business Operations\" \"Computer Science\" \"Architecture/Engineering\" ...\n  ..$ : chr [1:15] \"2001\" \"2002\" \"2003\" \"2004\" ..."
  },
  {
    "objectID": "datasets.html#voters",
    "href": "datasets.html#voters",
    "title": "Appendix A — Datasett",
    "section": "A.12 Voters",
    "text": "A.12 Voters\nData er hentet fra 2016 Views of the Electorate Research Survey gjennomført av Voter study group. Full variabelliste er lastet opp i Canvas. Du kan laste ned datasettet fra denne lenken.\nAktuell problemstilling er å predikere hvilke velgere som støtter Clinton. En slik klassifisering kan brukes til f.eks. å målrette budskap. En relatert problemstilling er å klustre velgerne for å finne segmenter.\n\nvoters &lt;- read.csv(\"data/voters.csv\", stringsAsFactors = TRUE)\nglimpse(voters)\n\nRows: 6,426\nColumns: 42\n$ RIGGED_SYSTEM_1_2016 &lt;int&gt; 3, 2, 2, 1, 3, 3, 3, 2, 4, 2, 3, 3, 4, 4, 3, 3, 2…\n$ RIGGED_SYSTEM_2_2016 &lt;int&gt; 4, 1, 4, 4, 1, 3, 4, 3, 4, 3, 2, 2, 3, 2, 4, 3, 2…\n$ RIGGED_SYSTEM_3_2016 &lt;int&gt; 1, 3, 1, 1, 3, 2, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 3…\n$ RIGGED_SYSTEM_4_2016 &lt;int&gt; 4, 1, 4, 4, 1, 2, 1, 2, 3, 2, 4, 1, 3, 4, 2, 2, 1…\n$ RIGGED_SYSTEM_5_2016 &lt;int&gt; 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 3, 3, 2, 3, 2…\n$ RIGGED_SYSTEM_6_2016 &lt;int&gt; 2, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2…\n$ track_2016           &lt;int&gt; 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2…\n$ persfinretro_2016    &lt;int&gt; 2, 3, 3, 1, 2, 2, 2, 3, 2, 1, 2, 3, 2, 2, 2, 2, 2…\n$ econtrend_2016       &lt;int&gt; 1, 3, 3, 1, 2, 2, 1, 3, 1, 1, 1, 3, 2, 1, 4, 3, 2…\n$ Americatrend_2016    &lt;int&gt; 1, 1, 1, 3, 3, 1, 2, 3, 2, 1, 3, 3, 2, 1, 1, 3, 1…\n$ futuretrend_2016     &lt;int&gt; 4, 1, 1, 3, 4, 3, 1, 3, 1, 1, 3, 1, 1, 4, 3, 4, 3…\n$ wealth_2016          &lt;int&gt; 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1…\n$ values_culture_2016  &lt;int&gt; 2, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 2, 1, 1, 3, 8, 3…\n$ US_respect_2016      &lt;int&gt; 2, 3, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3…\n$ trustgovt_2016       &lt;int&gt; 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3…\n$ trust_people_2016    &lt;int&gt; 8, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 8, 8, 2, 2…\n$ helpful_people_2016  &lt;int&gt; 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 8, 1, 1…\n$ fair_people_2016     &lt;int&gt; 8, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 8, 2, 1…\n$ imiss_a_2016         &lt;int&gt; 2, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 2, 2, 2…\n$ imiss_b_2016         &lt;int&gt; 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1…\n$ imiss_c_2016         &lt;int&gt; 1, 2, 2, 3, 1, 2, 2, 1, 4, 2, 3, 1, 2, 2, 3, 1, 1…\n$ imiss_d_2016         &lt;int&gt; 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 3…\n$ imiss_e_2016         &lt;int&gt; 1, 1, 3, 1, 1, 3, 1, 2, 1, 1, 2, 2, 4, 1, 4, 2, 1…\n$ imiss_f_2016         &lt;int&gt; 2, 1, 1, 2, 1, 2, 1, 3, 2, 1, 1, 1, 2, 1, 3, 2, 2…\n$ imiss_g_2016         &lt;int&gt; 1, 4, 3, 3, 3, 1, 3, 4, 2, 2, 1, 4, 1, 2, 1, 1, 4…\n$ imiss_h_2016         &lt;int&gt; 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3…\n$ imiss_i_2016         &lt;int&gt; 2, 2, 4, 4, 2, 1, 1, 3, 2, 1, 1, 2, 1, 2, 2, 2, 3…\n$ imiss_j_2016         &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2…\n$ imiss_k_2016         &lt;int&gt; 1, 2, 1, 1, 2, 1, 1, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1…\n$ imiss_l_2016         &lt;int&gt; 1, 4, 1, 2, 4, 1, 1, 3, 1, 1, 1, 4, 2, 1, 1, 1, 3…\n$ imiss_m_2016         &lt;int&gt; 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1…\n$ imiss_n_2016         &lt;int&gt; 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1…\n$ imiss_o_2016         &lt;int&gt; 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1…\n$ imiss_p_2016         &lt;int&gt; 2, 1, 2, 3, 1, 3, 1, 1, 4, 1, 1, 1, 2, 3, 2, 3, 1…\n$ imiss_q_2016         &lt;int&gt; 1, 1, 1, 2, 2, 1, 1, 4, 2, 1, 1, 3, 1, 1, 2, 2, 3…\n$ imiss_r_2016         &lt;int&gt; 2, 1, 1, 2, 1, 2, 1, 2, 4, 2, 2, 1, 3, 2, 2, 2, 1…\n$ imiss_s_2016         &lt;int&gt; 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3…\n$ imiss_t_2016         &lt;int&gt; 1, 1, 3, 3, 1, 1, 3, 4, 1, 1, 1, 3, 1, 3, 1, 1, 3…\n$ imiss_u_2016         &lt;int&gt; 2, 2, 2, 2, 1, 3, 3, 1, 4, 2, 3, 2, 4, 3, 3, 3, 1…\n$ imiss_x_2016         &lt;int&gt; 1, 3, 1, 2, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 2, 3…\n$ imiss_y_2016         &lt;int&gt; 1, 4, 2, 3, 1, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 2, 2…\n$ Clinton_supp         &lt;fct&gt; Yes, No, Yes, No, No, Yes, Yes, No, Yes, Yes, Yes…"
  },
  {
    "objectID": "introduksjon_R.html#hjelp-filer-og-dokumentasjon",
    "href": "introduksjon_R.html#hjelp-filer-og-dokumentasjon",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.1 Hjelp-filer og dokumentasjon",
    "text": "B.1 Hjelp-filer og dokumentasjon\nAlle funksjoner i R har en hjelp-fil som inneholder syntax, forklaring av argumentene, noen detaljer (ved behov), og eksempler. For å få tilgang til denne setter du et spørsmålstegn foran funksjonsnavnet slik:\n\n?confusionMatrix\n\nHjelpfilene kan være vanskelige å forstå hvordan fungerer. Det er ikke alltid selvforklarende, for å si det forsiktig. Men det viktige er at du ser hvilke argumenter som hører til funksjonen og hva de betyr. Ofte er det like greit å gå til eksemplene nederst på siden."
  },
  {
    "objectID": "introduksjon_R.html#rstudio-projects",
    "href": "introduksjon_R.html#rstudio-projects",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.2 Rstudio projects",
    "text": "B.2 Rstudio projects\nDet anbefales sterkt å lage en mappestruktur egnet for Rstudio projects. Hensikten med dette er å ha en hensiktsmessig og ryddig mappestruktur for alt arbeidet ditt. Dette er forklart nærmere i (Wickham and Grolemund 2017), se kapittelet om workflow og særlig avsnittet om projects.\nLag en egen mappe for dette kurset og lag følgende undermapper:\n\nData\nScript\nOutput\nDokumenter\n\nDu kan også lage andre undermapper hvis du vil. Det vil være begrenset behov for å eksportere output, men det er selvsagt mulig."
  },
  {
    "objectID": "introduksjon_R.html#litt-begrepsbruk",
    "href": "introduksjon_R.html#litt-begrepsbruk",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.3 Litt begrepsbruk",
    "text": "B.3 Litt begrepsbruk\nI R er alt du gjør er med funksjoner og alt du gjør noe med er objekter.1\nAltså: Alle datasett som leses inn legger du i et objekt og du bruker ulike funksjoner for å estimere modeller. Men du kan også lagre resultater i nye objekter, som f.eks. resultatet av en regresjonsmodell. Objektene kan altså være av forskjellig type, og hvis du lurer på hva slags objekt du har kan du spørre R om det slik:\n\nclass(dittobjekt)\n\nDu gir objektene et navn som du kan referere til senere. Det spiller ingen rolle hva du kaller objektene, men kan ikke ha mellomrom. Bruk navn som gir en viss mening når du jobber med det.\nDu kan ha mange objekter i arbeidsminnet i R samtidig. Hvis du bruker et navn som er i bruk fra før, så overskriver du det gamle objektet.\nFunksjonene har også et navn og etterfølges av en parentes. Inni parentesen angis funksjonens argumenter. Noen slike argumenter er obligatoriske, mens andre er valgfrie. Ofte vil det være forhåndsvalg til en funksjon slik at du ikke behøver å oppgi mer enn et par ting. Et eksempel er å lese inn data med read.csv(), så trenger du bare angi filbanen til datasettet. Denne funksjonen antar at filen er kommaseparert, men hvis det er brukt semikolon kan du angi det med å legge til argumentet sep = \";\"."
  },
  {
    "objectID": "introduksjon_R.html#lese-inn-data",
    "href": "introduksjon_R.html#lese-inn-data",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.4 Lese inn data",
    "text": "B.4 Lese inn data\nData kommer generelt i mange ulike formater og noen ganger skaper det uforutsette utfordringer med å få data inn i R. I dette kurset er imidlertid dataene i formatene .rds eller .csv.\nAlle datasett laster du ned og lagrer i mappen for data (se forrige avsnitt) og leser inn i R derfra. For å lære mer om innlesning av data, se (Wickham and Grolemund 2017) i kapittelet om data import.\nMerk at csv-filer er tekstfiler der kollonnene er separert med komma eller semikolon. Hvis dataene ser veldig rare ut etter å lest de inn kan det være fordi det var et annet skilletegn enn du trodde.\ncsv-filer kan leses inn med funksjonen read.csv() for komma-separerte filer og read.csv2() for semikolon-separerte filer, mens rds-filer leses med readRDS().\nVær obs på at når man leser inn csv-filer så vil R gjette på hva slags variabeltyper det er. De vil i hovedsak være numeriske, tekst eller factor. I all hovedsak bør tekstvariable tolkes som factor. Dette kan du få til ved å spesifiser det når dataene leses inn slik:\n\nread.csv(\"data/navnpaadata.csv\", stringsAsFactors = TRUE)\n\nSe mer om factor-variable i neste avsnitt."
  },
  {
    "objectID": "introduksjon_R.html#variabeltyper",
    "href": "introduksjon_R.html#variabeltyper",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.5 Variabeltyper",
    "text": "B.5 Variabeltyper\nVariable kan være av forskjellige typer, primært numerisk eller kategoriske. Numeriske kan igjen være heltall eller lagret med et angitt presisjonsnivå (integer, numeric eller double), men forskjellen mellom disse har i praksis ikke noe å si for vårt bruk her. Datovariable er også numeriske, men vi skal ikke jobbe med datoer her.\nKategoriske variable er ‘string’ (dvs en tekst-streng) eller factor. Du kan lese mer om factor-variable i Wickham and Grolemund (2017) i kapittelet om factor. Kort sagt er factor-variable tekst-variable som har en tilhørende underliggende numerisk verdi som gjør at den kan benyttes i modeller og beregninger.\nEt alternativ er å kode om faktorvariable eller tekst-variable til dummy-variable med verdiene 0 eller 1.2"
  },
  {
    "objectID": "introduksjon_R.html#dele-et-datasett-i-training-og-testing",
    "href": "introduksjon_R.html#dele-et-datasett-i-training-og-testing",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.6 Dele et datasett i training og testing?",
    "text": "B.6 Dele et datasett i training og testing?\nVi bruker pakken rsample til å splitte datasettet. Funksjonen initial_split() markerer hvilke observasjoner som er i hvilken del. Så kan du trekke ut disse etterpå med training() og testing()."
  },
  {
    "objectID": "introduksjon_R.html#seed---gjør-koden-eksakt-reproduserbar",
    "href": "introduksjon_R.html#seed---gjør-koden-eksakt-reproduserbar",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.7 Seed - gjør koden eksakt reproduserbar",
    "text": "B.7 Seed - gjør koden eksakt reproduserbar\nEn tilfeldig inndeling som med initial_split() bruker tilfeldige tall som genereres av R. Det finnes ikke helt tilfeldige tall i en datamaskin, det bare ser sånn ut. Det er en slags algoritme som generer disse tallen, og det har et startpunkt som varierer med når du setter den igang. Med andre ord: en tilfeldig inndeling vil bli forskjellig hver eneste gang.\nFunksjonen set.seed() definerer startpunktet for neste sekvens av tilfeldige tall slik at du kan reprodusere nøyaktig samme resultat. Hvis dere jobber sammen på oppgaver er det en fordel å sette samme seed slik at dere kan sammenligne resultatet.\n\nset.seed(42)\n\nDette gjelder for alle funksjoner der det benyttes tilfeldige tall. Det gjelder altså for random forest.\nOBS! Vend deg til å alltid bruke set.seed når du jobber i dette kurset, for du kommer til å trenge det på eksamen! Du kan gjøre ting riktig på eksamen likevel, men da blir ikke resultatene reproduserbare og sensor kan ikke sjekke resultatene. (Dere skal få nøyaktige instruksjoner senere)."
  },
  {
    "objectID": "introduksjon_R.html#prediksjon-med-predict",
    "href": "introduksjon_R.html#prediksjon-med-predict",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.8 Prediksjon med predict()",
    "text": "B.8 Prediksjon med predict()\nDere skal bruke funksjonen predict() ganske mye. Den tar et objekt fra en eller annen modell og predikerer fra denne. Merk at den bruker det objektet dere har lagret resultatene i, ser hva slags modell det er, og predikerer i henhold til det.\nI utgangspunktet bruker den det samme datasettet som modellen ble estimert med. Men kan også predikere på nye data. Da må argumentet newdata = ... angis. Det vil typisk være testing-datasettet eller helt nye observasjoner der du ikke vet utfallet.\nDet nye datasettet må alle de variablene som var i det opprinnelige datasettet for at det skal funke. For kategoriske variable vil det også kunne oppstå et problem hvis testing-data inneholdere andre kategorier enn det var i training-data. I slike tilfeller vil man ikke kunne predikere for disse observasjonene, men du vil få prediksjoner for øvrige observasjoner som før.\nMan kan predikere forskjellige ting. Det kan være en kontinuerlig verdi, en sannsynlighet eller noe annet. Det kommer an på hva slags modell du estimerte i utgangspunktet. For eksempel vil lineær regresjon kun predikere forventet verdi på den skalaen \\(y\\)-variabel er på. Men for logistisk regresjon kan det predikeres på logit-skala, mens for å få en sannsynlighet må du angi type = response. For random forest vil vi primært bruke en kategorisk utfallsvariabel, og setter da også type = response eller evt type = class (som gir det samme), men det går også an å be om votes eller prob.\nTil hver type modell finnes det en egen predict-funksjon, og når man bruker predict() så finner den riktig funksjon basert på modelltype. Så hvis du slår opp i hjelp-filen for predict med ?predict så står det nesten ingenting. Derimot kan du slå opp i ?predict.lm for lineær regresjon, ?predict.glm for logistisk regresjon, og tilsvarende ?predict.randomForest, ?predict.xgb.Booster osv. I utgangspunktet skal du ikke trenge å slå opp disse, men hvis noe går helt galt kan det hende"
  },
  {
    "objectID": "introduksjon_R.html#bruke-formula-for-utfallsvariable-og-prediktorer",
    "href": "introduksjon_R.html#bruke-formula-for-utfallsvariable-og-prediktorer",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.9 Bruke formula for utfallsvariable og prediktorer",
    "text": "B.9 Bruke formula for utfallsvariable og prediktorer\nDe modellen vi skal bruke her angir utfallsvariabel og prediktorer med en formula som angir omtrent slik: utfallsvariabel ~ prediktor1 + prediktor2. Dette tilsvarer altså å skrive \\(y = x1 + x2\\). For lineær regresjon vil den så estimere de tilhørende regresjonsparametrene \\(\\alpha\\), \\(\\beta_1\\) og \\(\\beta_2\\).\nFor andre modeller der det ikke skal estimeres parametere på samme måte vil man angi variablene på samme måte.\nFor regresjon kan man angi spesifikasjonen som følger:\n\nflere variable: y ~ x + z + k + m\ninkludere alle variable: y ~ .\nannengradsledd: y ~ x + I(x^2)\ntredjegradsledd: y ~ x + I(x^2) + I(x^3)\ninteraksjoner: y ~ x + z + x*z\n\nDisse kan også kombineres."
  },
  {
    "objectID": "introduksjon_R.html#databehandling-dplyr-verb-tidyverse",
    "href": "introduksjon_R.html#databehandling-dplyr-verb-tidyverse",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.10 Databehandling: dplyr-verb / tidyverse",
    "text": "B.10 Databehandling: dplyr-verb / tidyverse\nDet som kalles tidyverse er en samling R-pakker som til sammen danner et konsistent system for databehandling og grafikk. Hvis du bruker R uten å laste noen pakker, kalles dette base-R. Tidyverse er slik sett en dialekt av R.3\nDatabehandling med dplyr (fra tidyverse) har som hovedgrep noen verb som kan settes sammen i lengre uttrykk.\n\nmutate() brukes til å lage nye variable eller endre på variable\nfilter() brukes til å filtrere data, f.eks. velge ut en undergruppe\nselect() brukes til å velge ut variable - eller velge bort variable\nsummarise() brukes til å summere verdier, f.eks. gjennomsnitt og standardavvik\ngroup_by() brukes hvis man skal summere over grupper av observasjoner med summarise() eller mutate().\n\narrange() sorterer et datasett\n\nAlle disse verbene starter med at man angir hvilket objekt man skal gjøre noe med (dvs datasett) og deretter hva man vil gjøre.\nFor eksempel kan du lage en ny variabel som er summen av variable med navn X og Y slik:\n\nnyedata &lt;- mutate(dinedata, sumXY = X + y)\n\nDu kan lese mer om disse verbene i R4DS (Wickham and Grolemund 2017) kapittelet Transform\nI dette kurset skal vi ofte lage en ny variabel med predict() og det gjør vi da inni en mutate(), omtrentlig slik:\n\nendretdata &lt;- dinedata %&gt;% \n  mutate( nyvariabel = predict(modellobjekt))\n\nHer skal resultatet være et kopi av det opprinnelige datasettet, dinedata, som lages i et nytt objekt endretdata, der den andre linjen legger til en ny variabel som inneholder predikerte verdier fra en modell lagret i modellobjekt.\n\nB.10.1 Hva gjør ‘pipe-operatoren’ %&gt;% ??\nDu kan sette sammen flere kombinsjoner av mutate(), select() og andre dplyr-verb med %&gt;%. Les mer om den i R4DS (Wickham and Grolemund 2017) i et eget avsnitt om pipes.\nEnkelt sagt tar %&gt;% og legger det som er til venstre over som første argument i neste dplyr-verb. Dermed kan man sette sammen en rekke av dplyr-verb der du både filtrerer, lager nye variable, summerer osv."
  },
  {
    "objectID": "introduksjon_R.html#grafikk-quickn-dirty-vs-ggplot",
    "href": "introduksjon_R.html#grafikk-quickn-dirty-vs-ggplot",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.11 Grafikk: quick’n dirty vs ggplot",
    "text": "B.11 Grafikk: quick’n dirty vs ggplot\nEn rekke modeller har noen standard funksjoner for å plotte. Funksjonen plot() vil kjenne igjen hva slags objekt det er snakk om og så lage en viss type plot. Bruker du dette på et objekt for lineær regresjon får du et annet type plot enn hvis du gjør det på et randomForest-objekt. Dette kan være helt utmerket for en kjapp titt på resultatene, men du har litt mindre kontroll på hva du ber om. Grafikken er ganske pen, men kanskje ikke publiseringsklar.\nI en del eksempler her brukes ggplot(). Dette er for avansert grafikk og er det som brukes i standard statistikkurs på bachelornivå på SV-fakultetet (på alle fag, tror jeg). Det er en viktig grunn til at det brukes her også. For en del visualisering av tre-baserte metoder er det vesentlig lettere å bruke spesialiserte funksjoner via plot(). Men for all del: ggplot() kan lage disse figurene også, det bare krever mer arbeid enn vi prioriterer her.\nDu kan lære mer om ggplot() i R4DS (Wickham and Grolemund 2017) i kapittelet om visualisering.\n\n\n\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley."
  },
  {
    "objectID": "introduksjon_R.html#footnotes",
    "href": "introduksjon_R.html#footnotes",
    "title": "Appendix B — Introduksjon til R",
    "section": "",
    "text": "Man kan si at dette ligner litt på subjekt og verb i vanlige språk.↩︎\nDette kalles også noen ganger for indikatorvariable eller one-hot-encoding, litt avhengig av fagfelt og tradisjoner, men er det samme.↩︎\nDet finnes flere slike dialekter av R, men som ikke er relevant her. Men greit å vite om, særlig hvis man søker på nettet etter hjelp for spesielle problemer. Tidyverse utvikles av firmaet Posit som også lager Rstudio. De leverer også et eget rammeverk for maskinlæring som heter tidymodels, som bl.a. pakken rsample er en del av. Vi holder oss til basis-pakkene for de spesifikke funksjonene på dette kurset.↩︎"
  }
]