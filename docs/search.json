[
  {
    "objectID": "linear_regresjon.html#lese-inn-data",
    "href": "linear_regresjon.html#lese-inn-data",
    "title": "2  Lineær regresjon",
    "section": "2.1 Lese inn data",
    "text": "2.1 Lese inn data\nVi illustrerer lineær regresjon med et empirisk eksempel. Her skal vi bruke data for norske kommuner i 2016. La oss si at vi er interessert i hvordan antall voldshendelser per 1000 innbyggere vil endre seg i en kommune. Dette kunne være relevant for langtidsplanlegging av forebygging, politibemanning, helsetjenester osv. Det kan være et område som er i stor endring slik at befolkningssammensetningen forventes å endre seg og/eller det er endrede lokale økonomiske utsikter.\nFørst leser vi inn dataene og tar en titt på variabellisten.\n\nkommune &lt;- readRDS( \"data/kommunedata.rds\")\nglimpse(kommune)\n\nRows: 1,529\nColumns: 28\n$ kommune_nr             &lt;chr&gt; \"0101\", \"0101\", \"0101\", \"0101\", \"0104\", \"0104\",…\n$ kommune                &lt;chr&gt; \"Halden (-2019)\", \"Halden (-2019)\", \"Halden (-2…\n$ year                   &lt;dbl&gt; 2015, 2016, 2017, 2018, 2015, 2016, 2017, 2018,…\n$ bef_18min              &lt;int&gt; 3556, 3503, 3505, 3544, 3594, 3652, 3704, 3655,…\n$ bef_18_25              &lt;int&gt; 3575, 3585, 3432, 3438, 3405, 3404, 3355, 3370,…\n$ bef_26_35              &lt;int&gt; 3728, 3804, 3985, 4035, 4057, 4071, 4124, 4110,…\n$ bef_totalt             &lt;int&gt; 30328, 30544, 30790, 31037, 31802, 32182, 32407…\n$ menn_18_25             &lt;int&gt; 1847, 1865, 1813, 1819, 1789, 1802, 1789, 1810,…\n$ menn_26_35             &lt;int&gt; 1880, 1919, 2005, 2062, 2063, 2083, 2113, 2134,…\n$ menn_36_67             &lt;int&gt; 7067, 7051, 7085, 7057, 7418, 7453, 7408, 7407,…\n$ menn_67plus            &lt;int&gt; 2496, 2624, 2697, 2806, 2671, 2777, 2856, 2895,…\n$ menn_18min             &lt;int&gt; 1880, 1847, 1873, 1876, 1842, 1885, 1919, 1878,…\n$ kvinner_18_25          &lt;int&gt; 1728, 1720, 1619, 1619, 1616, 1602, 1566, 1560,…\n$ kvinner_26_35          &lt;int&gt; 1848, 1885, 1980, 1973, 1994, 1988, 2011, 1976,…\n$ kvinner_36_67          &lt;int&gt; 6880, 6832, 6844, 6848, 7479, 7519, 7537, 7596,…\n$ kvinner_67plus         &lt;int&gt; 3026, 3145, 3242, 3309, 3178, 3306, 3423, 3555,…\n$ kvinner_18min          &lt;int&gt; 1676, 1656, 1632, 1668, 1752, 1767, 1785, 1777,…\n$ inntekt_totalt_median  &lt;int&gt; 555000, 562000, 580000, 591000, 561000, 568000,…\n$ inntekt_eskatt_median  &lt;int&gt; 451000, 453000, 470000, 480000, 449000, 456000,…\n$ ant_husholdninger      &lt;int&gt; 13890, 14124, 14281, 14454, 15046, 15132, 15313…\n$ shj_klienter           &lt;int&gt; 1183, 1137, 1099, 1128, 1155, 1129, 1152, 1137,…\n$ shj_unge               &lt;int&gt; 262, 247, 248, 242, 267, 263, 238, 222, 307, 28…\n$ vinningskriminalitet   &lt;dbl&gt; 19.7, 18.7, 16.5, 14.5, 24.5, 21.5, 18.0, 18.0,…\n$ voldskriminalitet      &lt;dbl&gt; 11.2, 12.6, 12.3, 11.2, 7.8, 8.3, 8.7, 9.7, 6.8…\n$ nark_alko_kriminalitet &lt;dbl&gt; 21.0, 21.9, 21.0, 20.3, 12.0, 10.2, 10.9, 10.1,…\n$ ordenslovbrudd         &lt;dbl&gt; 18.5, 16.5, 14.9, 13.7, 8.9, 9.0, 9.1, 9.2, 8.2…\n$ trafikklovbrudd        &lt;dbl&gt; 15.5, 16.3, 16.7, 19.2, 7.4, 6.3, 6.9, 8.0, 9.6…\n$ andre_lovbrudd         &lt;dbl&gt; 25.5, 26.5, 26.1, 25.2, 12.1, 12.2, 11.9, 12.4,…\n\n\nEn annen måte å få oversikt over dataene på er å bruke funksjonen skim(), som gir noe mer informasjon om fordelingen av hver enkelt variabel.\n\nskim(kommune)\n\n\nData summary\n\n\nName\nkommune\n\n\nNumber of rows\n1529\n\n\nNumber of columns\n28\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n26\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nkommune_nr\n0\n1\n4\n4\n0\n561\n0\n\n\nkommune\n0\n1\n2\n46\n0\n561\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n2017.17\n1.70\n2015.0\n2016.0\n2017.0\n2018.0\n2020.0\n▇▃▃▁▃\n\n\nbef_18min\n0\n1\n2051.72\n5134.84\n82.0\n478.0\n843.0\n1912.0\n71566.0\n▇▁▁▁▁\n\n\nbef_18_25\n0\n1\n2010.07\n5876.07\n90.0\n423.0\n772.0\n1723.0\n80730.0\n▇▁▁▁▁\n\n\nbef_26_35\n0\n1\n2637.60\n10179.34\n80.0\n466.0\n873.0\n2013.0\n156988.0\n▇▁▁▁▁\n\n\nbef_totalt\n0\n1\n17351.92\n48195.14\n934.0\n4062.0\n6952.0\n15656.0\n693494.0\n▇▁▁▁▁\n\n\nmenn_18_25\n0\n1\n1033.97\n2872.20\n45.0\n224.0\n404.0\n904.0\n38847.0\n▇▁▁▁▁\n\n\nmenn_26_35\n0\n1\n1348.18\n5122.76\n44.0\n240.0\n456.0\n1017.0\n78059.0\n▇▁▁▁▁\n\n\nmenn_36_67\n0\n1\n3940.48\n10521.30\n234.0\n939.0\n1630.0\n3650.0\n150390.0\n▇▁▁▁▁\n\n\nmenn_67plus\n0\n1\n1361.18\n3039.57\n56.0\n383.0\n639.0\n1330.0\n42590.0\n▇▁▁▁▁\n\n\nmenn_18min\n0\n1\n1050.44\n2618.78\n44.0\n244.0\n434.0\n974.0\n36298.0\n▇▁▁▁▁\n\n\nkvinner_18_25\n0\n1\n976.11\n3006.75\n38.0\n201.0\n365.0\n813.0\n41945.0\n▇▁▁▁▁\n\n\nkvinner_26_35\n0\n1\n1289.42\n5058.28\n35.0\n224.0\n420.0\n989.0\n78929.0\n▇▁▁▁▁\n\n\nkvinner_36_67\n0\n1\n3770.34\n9932.02\n200.0\n862.0\n1561.0\n3487.0\n140473.0\n▇▁▁▁▁\n\n\nkvinner_67plus\n0\n1\n1580.52\n3696.66\n64.0\n428.0\n729.0\n1488.0\n50757.0\n▇▁▁▁▁\n\n\nkvinner_18min\n0\n1\n1001.28\n2516.27\n38.0\n232.0\n405.0\n933.0\n35268.0\n▇▁▁▁▁\n\n\ninntekt_totalt_median\n0\n1\n654721.39\n75785.29\n463000.0\n601000.0\n646000.0\n697000.0\n898000.0\n▁▇▇▃▁\n\n\ninntekt_eskatt_median\n0\n1\n519417.92\n52786.68\n376000.0\n482000.0\n514000.0\n550000.0\n675000.0\n▁▆▇▃▁\n\n\nant_husholdninger\n0\n1\n7873.76\n23631.34\n426.0\n1831.0\n3137.0\n6896.0\n348864.0\n▇▁▁▁▁\n\n\nshj_klienter\n0\n1\n449.81\n1383.19\n11.0\n98.0\n179.0\n376.0\n20401.0\n▇▁▁▁▁\n\n\nshj_unge\n0\n1\n89.36\n197.02\n0.0\n20.0\n39.0\n89.0\n2488.0\n▇▁▁▁▁\n\n\nvinningskriminalitet\n0\n1\n9.19\n7.05\n1.5\n4.8\n7.2\n11.5\n91.2\n▇▁▁▁▁\n\n\nvoldskriminalitet\n0\n1\n5.61\n2.28\n1.3\n3.9\n5.2\n6.8\n18.8\n▇▇▂▁▁\n\n\nnark_alko_kriminalitet\n0\n1\n6.91\n4.60\n1.1\n3.9\n5.9\n8.9\n55.5\n▇▁▁▁▁\n\n\nordenslovbrudd\n0\n1\n4.91\n3.23\n1.1\n3.0\n4.1\n5.9\n34.9\n▇▁▁▁▁\n\n\ntrafikklovbrudd\n0\n1\n10.49\n11.36\n2.1\n6.0\n8.1\n11.7\n219.7\n▇▁▁▁▁\n\n\nandre_lovbrudd\n0\n1\n9.59\n4.34\n2.3\n7.1\n8.8\n10.8\n52.5\n▇▁▁▁▁\n\n\n\n\n\n\n2.1.1 Training og testing data\nVi starter med å dele datasettet i training og testing. Her kan vi bruke pakken ‘rsample’ og funksjonen initial_split() etterfulgt av funksjonene training() og testing(). Forhåndsvalget for splitten er 0.75, så dermed brukes 75% til training og resten til testing. Du kan også legge til argumentet prop = og sette en annen andel, f.eks. 0.7 for 70%.\nMerk bruken av set.seed(). For å splitte genererer R tilfeldige tall, og seed styrer hvor den algoritmen starter. Når seed er satt vil du få nøyaktig samme resultatet som gjort her. Dette vil du trenge på eksamen for at sensor skal kunne sjekke resultatene dine, så begynn å bruke det med en gang. Tallet inni parentesen betyr ingenting1 og bare sørger for reproduserbarhet der hvor det er tilfeldige tall involvert.\n\nlibrary(rsample)\n\nset.seed(42)\nkommune_split &lt;- initial_split(kommune, prop = .7)\n\nkommune_train &lt;- training(kommune_split)\nkommune_test &lt;- testing(kommune_split)\n\n\n\n2.1.2 Enkel lineær regresjon i R\nEn ganske åpenbar faktor som forklarer forekomsten av vold er andel unge menn i kommunen. Rett og slett fordi dette er den demografiske gruppen som begår mest vold - og kriminalitet generelt, faktisk. Hvis befolkningssammensetningen forventes å bli yngre vil det medføre flere unge menn, og da kan vi kanskje forvente at det blir flere voldshendelser bare av den grunn? Sammenhengen mellom unge menn og voldsrate kan estimeres med helt vanlig lineær regresjon.\nEn god start på de fleste empiriske analyser er å beskrive sammenhengen med et plot. Her legger vi på en lineær regresjonslinje med geom_smooth() der vi presiserer lineær modell med method = \"lm\" og lar være å ta med konfidensintervallet se = FALSE.\n\nkommune_train &lt;- kommune_train %&gt;% \n  mutate(prop_unge_menn = (menn_18_25 + menn_26_35)/bef_totalt*100) \n\nggplot(kommune_train, aes(x = prop_unge_menn, \n                     y = voldskriminalitet)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) \n\n\n\n\nLineær regresjon estimeres med lm() og du kan få en enkel output med bruk av summary().\n\nest &lt;- lm(voldskriminalitet ~ prop_unge_menn, data = kommune_train)\nsummary(est)\n\n\nCall:\nlm(formula = voldskriminalitet ~ prop_unge_menn, data = kommune_train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0302 -1.5764 -0.3951  1.1826 11.3367 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     0.50954    0.63482   0.803    0.422    \nprop_unge_menn  0.41329    0.05097   8.109  1.4e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.248 on 1068 degrees of freedom\nMultiple R-squared:  0.05799,   Adjusted R-squared:  0.05711 \nF-statistic: 65.75 on 1 and 1068 DF,  p-value: 1.395e-15\n\n\nMan kan også hente ut kun \\(r^2\\) med følgende kode:\n\nsummary(est)$r.squared\n\n[1] 0.05799176\n\n\nFor ordens skyld: I tidligere metodekurs har du kanskje lært å få ut en penere regresjonstabell med f.eks. gtsummary-pakken. (Det finnes andre pakker også som gjør tilsvarende). Da vil de samme resultatene se ut som følger. Hvordan output er formatert spiller ingen rolle. I denne sammenhengen har vi lite bruk for en pen regresjonstabell da \\(\\beta\\) ikke er av primær interesse.\n\nlibrary(gtsummary)\n\ntbl_regression(est, intercept = TRUE)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n0.51\n-0.74, 1.8\n0.4\n    prop_unge_menn\n0.41\n0.31, 0.51\n&lt;0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nMed andre ord kan voldsraten beskrives som:\n\\[\n\\operatorname{\\widehat{voldskriminalitet}} = 0.51 + 0.41(\\operatorname{prop\\_unge\\_menn})\n\\]\nMen vi har også sett at \\(r^2\\) er ganske lav, bare 0.058. Denne koeffisienten kalles også “coefficient of determination” og sier noe om i hvor stor grad modellen fanger opp variasjoenen i dataene. En lav \\(r^2\\) betyr at modellen i liten grad gjør det. Vi må altså forvente at modellen vil bomme ganske kraftig i sine prediksjoner. Vi kan velge å ta modellen seriøst likevel, men ikke ha for store forventninger for prediksjonene!\nEt annet mål på hvor godt modellen treffer er “Root mean square error”, RMSE. Dette kan skrives som:\n\\[ rmse = \\sqrt{ \\frac{ \\sum{(O_i-P_i)^2} }{N} }  \\]\nder \\(O\\) er de observerte verdiene og \\(P\\) er de predikerte verdiene for observasjon \\(i\\). Merk at \\((O_i-P_i)\\) er residualene. I R kan vi hente ut residualene fra regresjons-objektet med dollartegnet ...$res etter objektnavnet. Da kan du regne ut RMSE som følger:\n\nrmse &lt;- sqrt(mean(est$res^2))\nrmse\n\n[1] 2.245685\n\n\nRMSE sier altså omtrentlig hvor mye modellen i gjennomsnitt bommer på de observerte verdiene. 2. Hvorvidt det er presist nok eller ikke vil vel strengt tatt komme an på behovet for presisjon, altså: hva man skal bruke det til.\nFor å få litt bedre tak på hva RMSE betyr kan vi se på et plot av de predikerte og observerte verdiene. Vi kan predikere vold for hver enkelt kommune basert på denne modellen, som altså er den forventede voldsraten hvis modellen er sann. Funksjonen predict() gir oss hva vi trenger.\n\nkom &lt;- kommune_train %&gt;% \n  mutate(pred = predict(est))\n\nMerk at koden her lagde en kopi av datasettet der vi har alle de opprinnelige variablene pluss en variabel med de predikerte verdiene. Vi kan nå sammenlignet prediksjonene med de observerte utfallene.\n\nggplot(kom, aes(x = voldskriminalitet, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nHvis prediksjonen hadde vært perfekt ville disse punktene ligget på linja, noe den jo ikke gjør. Modellen bommer altså ganske mye.\nHva hvis vi vil vite forventet voldsrate for en kommune for en gitt andel unge menn? Løsningen er å lage et nytt datasett med de verdiene vi er interessert i og så predikere for dette datasettet med å spesifisere newdata = dt. Her er et eksempel der vi ønsker å vite voldsraten hvis andelen unge menn er 15%.[^](OBS! I en tidligere versjon stod det 0.15 i koden under, men merk at variabelen er på skalaen prosentpoeng og ikke anderl. Hivs du stusset på dette, så var det altså riktig tenkt.)\n\ndt &lt;- data.frame(prop_unge_menn = 15)\np &lt;- predict(est, newdata = dt)\np\n\n       1 \n6.708919 \n\n\nI følge modellen vil altså en kommune der 15% av populasjonen er unge menn ha en 6.709 voldshendelser per 1000 innbyggere. Fra tradisjonell statistikk vet vi jo at det er usikkerhet knyttet til dette estimatet og vi kan også ta det med i beregningen her. Vanligvis vil man estimere med et konfidensintervall, som gjelder hvis man estimerer et gjennomsnitt i en gruppe. Her skal vi derimot predikere for en enkelt kommune, som da har større usikkerhet enn om man estimerer for en enkelt observasjon. Dette kalles prediksjonsintervall og må spesifiseres i koden. Hvis det ikke er gitt vil R gi konfidensintervallet.\n\np_ki &lt;- predict(est, newdata = dt, interval = \"prediction\")\np_ki\n\n       fit      lwr      upr\n1 6.708919 2.288514 11.12932\n\n\nTolkningen er ellers tilsvarende som for konfidensintervall: vi forventer med “95% sannsynlighet”3 at voldsraten vil være mellom 2.3 og 11.1 per 1000 innbyggere.\n\n\n2.1.3 Multippel regresjon\nEnkel regresjon er nettopp enkel og prediksjonen blir ikke så god. Men vi kan komplisere vesentlig ved å inkludere flere variable og bruke alle triksene man evt. har lært om multippel regresjon tidligere, primært interaksjonsledd, polynomer og transformasjoner osv. (Det er ok om du ikke har lært alt dette tidligere).\nI R vil vi da bare legge til flere variabelnavn i formelen. Ellers er det meste likt som for enkel lineær regresjon.\n\nest_m &lt;- lm(voldskriminalitet ~ prop_unge_menn + inntekt_totalt_median + shj_unge + \n                   ant_husholdninger , \n            data = kommune_train)\nsummary(est_m)\n\n\nCall:\nlm(formula = voldskriminalitet ~ prop_unge_menn + inntekt_totalt_median + \n    shj_unge + ant_husholdninger, data = kommune_train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6862 -1.3599 -0.2042  1.0689 12.4822 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            7.421e+00  7.333e-01  10.121  &lt; 2e-16 ***\nprop_unge_menn         4.177e-01  5.328e-02   7.840 1.09e-14 ***\ninntekt_totalt_median -1.099e-05  8.539e-07 -12.871  &lt; 2e-16 ***\nshj_unge               4.461e-03  1.016e-03   4.392 1.23e-05 ***\nant_husholdninger     -2.163e-05  8.361e-06  -2.587  0.00983 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.037 on 1065 degrees of freedom\nMultiple R-squared:  0.2288,    Adjusted R-squared:  0.2259 \nF-statistic:    79 on 4 and 1065 DF,  p-value: &lt; 2.2e-16\n\n\nMerk at \\(r^2\\) nå har gått betraktelig opp, til ca 0.23. Gitt at vi tolker dette som i hvor stor grad vi kan predikere utfallet fra datasettet, så er det kanskje likevel ikke imponerende høyt: vi vil fremdeles forvente mye feil prediksjon.\nHer er et scatterplot av observert mot forventet voldsrater:\n\nkom_pred &lt;- kommune_train %&gt;% \n  mutate(pred = predict(est_m))\n\nggplot(kom_pred, aes(x = voldskriminalitet, y = pred)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nLa oss inkludere alle aktuelle variable i datasettet. Et lite triks her er å fjerne alle variable vi ikke er interessert i og lagre det i et nytt datasett. I lm() kan vi da presisere formelen som Vold ~ . som i denne sammenhengen betyr å ta med alle variabelene i stedet for å liste opp hver enkelt variabel.\n\nkom_s &lt;- kommune_train %&gt;% \n  select(-c(kommune, kommune_nr, ordenslovbrudd,  \n            nark_alko_kriminalitet, trafikklovbrudd, andre_lovbrudd, \n            prop_unge_menn))\n\nfull_mod &lt;- lm(voldskriminalitet ~ . , data = kom_s)\nsummary(full_mod)\n\n\nCall:\nlm(formula = voldskriminalitet ~ ., data = kom_s)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9650 -1.2333 -0.1813  0.8919 12.2114 \n\nCoefficients: (4 not defined because of singularities)\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           -1.198e+02  9.309e+01  -1.287  0.19851    \nyear                   6.234e-02  4.646e-02   1.342  0.17998    \nbef_18min              3.156e-03  1.839e-03   1.716  0.08637 .  \nbef_18_25             -1.885e-05  1.513e-03  -0.012  0.99006    \nbef_26_35              1.180e-03  1.006e-03   1.173  0.24109    \nbef_totalt            -2.272e-03  7.130e-04  -3.187  0.00148 ** \nmenn_18_25             3.698e-03  2.136e-03   1.731  0.08373 .  \nmenn_26_35            -1.481e-03  2.013e-03  -0.736  0.46197    \nmenn_36_67             2.710e-03  9.461e-04   2.865  0.00425 ** \nmenn_67plus            1.654e-03  1.339e-03   1.236  0.21676    \nmenn_18min             2.461e-03  2.875e-03   0.856  0.39223    \nkvinner_18_25                 NA         NA      NA       NA    \nkvinner_26_35                 NA         NA      NA       NA    \nkvinner_36_67         -1.269e-04  9.021e-04  -0.141  0.88816    \nkvinner_67plus                NA         NA      NA       NA    \nkvinner_18min                 NA         NA      NA       NA    \ninntekt_totalt_median -4.693e-05  7.600e-06  -6.176 9.40e-10 ***\ninntekt_eskatt_median  5.580e-05  1.108e-05   5.037 5.55e-07 ***\nant_husholdninger      1.555e-03  3.169e-04   4.908 1.07e-06 ***\nshj_klienter           2.170e-03  9.967e-04   2.177  0.02968 *  \nshj_unge               2.191e-03  3.054e-03   0.718  0.47322    \nvinningskriminalitet   1.066e-01  1.014e-02  10.513  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.891 on 1052 degrees of freedom\nMultiple R-squared:  0.343, Adjusted R-squared:  0.3324 \nF-statistic:  32.3 on 17 and 1052 DF,  p-value: &lt; 2.2e-16\n\n\n\\(r^2\\) gikk noe opp, til 0.343.\nMen vi kan gjøre modellen ekstra komplisert ved inkludere alle mulige interaksjonsledd. En åpenbar ulempe med dette er at hver enkelt koeffisent blir svært mye vanskeligere å tolke. Vi fokuserer derfor kun på \\(r^2\\) som kan hentes ut uten å ta med resten av output.\n\nfull_mod2 &lt;- lm( voldskriminalitet ~ .^2, data = kom_s)\nsummary(full_mod2)$r.squared\n\n[1] 0.5224374\n\n\n\\(r^2\\) gikk vesentlig opp. Men når vi først driver med kompliserte modellspesifikasjoner som uansett er vanskelige å tolke - hvorfor begrense seg til 2-veis interaksjoner? Her er en versjon med alle 3-veis interaksjoner, og nå begynner \\(r^2\\) virkelig å bli høy!\n\nfull_mod3 &lt;- lm( voldskriminalitet ~ .^3, data = kom_s)\nsummary(full_mod3)$r.squared\n\n[1] 0.8145801\n\n\nVi kan trimme modellen så den ikke har med så voldsomt mange parametre. En mulighet er å overlate dette til datamaskinen ved å la den gjøre en trinnvis test av hvorvidt modellene blir signifikant bedre av å legge til hver av de parametrene, og stopper når modellen ikke blir bedre. Så beholdes den “beste” av disse modellene, ikke nødvendigvis den som er mest komplisert.\nOBS! Merk at dette er en rent mekanisk seleksjon, og frarådes i de fleste samfunnsvitenskapelige sammenhenger. Tolkning av parametre og statistisk usikkerhet er nå på svært tynn is. Men det kan gi god prediksjon likevel.\n\nstep_mod &lt;- MASS::stepAIC(full_mod3, direction=\"forward\", \n                          trace = FALSE)\nsummary(step_mod)$r.squared\n\n[1] 0.8145801\n\n\nHvis vi nå predikerer for hver enkelt kommune og plotter forventet mot observert, så får vi et svært mye bedre sammenfall enn tidligere.\n\nkom_pred &lt;- kom_s %&gt;% \n  mutate(pred = predict(step_mod))\n\nggplot(kom_pred, aes(x = voldskriminalitet, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nNå kan vi også regne ut RMSE, som altså er “root mean squared error”. Med andre ord: regn ut residualene (dvs. “error”), og kvadrer denne, og så ta kvadratroten av gjennomsnittet av denne. Her er en kode skrevet litt omstendelig så den er litt lettere å forstå:\n\nkom_s %&gt;% \n  mutate(pred = predict(step_mod), \n         residual = pred - voldskriminalitet) %&gt;% \n  mutate(sq.resid = residual^2) %&gt;% \n  summarise(sqrt(mean(sq.resid)))\n\n  sqrt(mean(sq.resid))\n1            0.9963221\n\n\nDette betyr omtrentlig at modellen i gjennomsnitt vil bomme med 1.38 prosentpoeng på voldsraten i kommunen. 4 Hvorvidt det er presist nok eller ikke vil vel strengt tatt komme an på behovet for presisjon, altså: hva man skal bruke det til.\n\n\n2.1.4 Predikere for nye data\nMen nå har vi bare sett på hvordan prediksjonen fungerer på training-datasettet. Vi må sjekke med testing-datasettet. Det lagde vi i begynnelsen, så nå henter vi det frem og gjør det samme som over. I ‘predict()’ må vi nå angi ‘newdata =’.\n\nkom_pred2 &lt;- kommune_test %&gt;% \n  mutate(pred = predict(step_mod, newdata = .), \n         residual = pred - voldskriminalitet)\n\nggplot(kom_pred2, aes(x = voldskriminalitet, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nSer dette rart ut? Det er to observasjoner som har pedikert skyhøy voldsrate! Disse to prediksjonene bommer voldsomt, og med litt erfaring vil man se at dette her går aldri bra for \\(r^2\\), som regnes ut slik:\n\nkom_pred2  %&gt;% \n  mutate(residual_total = voldskriminalitet - mean(voldskriminalitet)) %&gt;% \n  summarise(SSres = sum(residual^2), \n            SStot = sum(residual_total^2)) %&gt;% \n  mutate(r_squared = 1 - (SSres/SStot))\n\n        SSres    SStot r_squared\n1 23202558409 2238.179 -10366712\n\n\nGanske riktig! Dette ble bare tull. Kvadratsummen til residualene ble mye høyere enn total kvadratsum. Dermed blir \\(r^2\\) helt fjerne.\nDette er en ganske ekstrem variant av overfitting. Ved å formulere en veldig komplisert modell som passer veldig godt til training-dataene kan vi ende opp med en modell som passer veldig, veldig dårlig til nye data. Hvis man skulle utforme f.eks. politikktiltak på grunnlag av en slik prediksjon vil det kunne gå riktig så dårlig.\nDet er i dette tilfellet kanskje ikke så rart: modellen ble formulert kun for å maksimere \\(r^2\\) og uten så mye andre tanker bak.\nDet er nok bedre med en enklere modell. Vi prøver heller å bruke modellen der alle prediktorene er med, men uten alle de kompliserende interaksjonene:\n\nkom_pred3 &lt;- kommune_test %&gt;% \n  mutate(pred = predict(full_mod, newdata = .), \n         residual = pred - voldskriminalitet)\n\nggplot(kom_pred3, aes(x = voldskriminalitet, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nkom_pred3  %&gt;% \n  mutate(residual_total = voldskriminalitet - mean(voldskriminalitet)) %&gt;% \n  summarise(SSres = sum(residual^2), \n            SStot = sum(residual_total^2)) %&gt;% \n  mutate(r_squared = 1 - (SSres/SStot))\n\n     SSres    SStot r_squared\n1 1507.998 2238.179 0.3262389\n\n\nSammenlignet med \\(r^2\\) på trainingdata, ‘r summary(full_mod)$r.squared’, er dette ikke så værst. Litt dårligere tilpassning må man regne med.\nRMSE regnes ut slik:\n\nkom_pred3 %&gt;% \n  mutate(sq.resid = residual^2) %&gt;% \n  summarise(sqrt(mean(sq.resid)))\n\n  sqrt(mean(sq.resid))\n1             1.812567\n\n\nDet er altså slik at en enklere modell kan passe til nye data langt bedre enn en veldig komplisert modell. Grunnen er overfitting: modellen fanger opp vel så mye tilfeldig støy som det underliggende mønsteret. Støyen vil jo være annerledes i de nye dataene.\n\n\n2.1.5 Oppsummerende kommentar\nDette gjelder generelt: mer komplisert regresjonsmodell vil gi tilsynelatende bedre tilpassning til data enten man måler med \\(r^2\\) eller RMSE. Man kan riktignok bruke mål på tilpassning som justerer for antall parametre etc (f.eks. justert \\(r^2\\), AIC eller BIC), som kanskje kan bedre dette noe, men det vil ofte lede til overfitting likevel.\nDet er derfor veldig viktig å teste modellen mot nye data. I praksis testing-dataene man lagde til å begynne med.\nI resten av kurset skal vi unngå å bruke latterlige kompliserte modeller som ble demonstret ovenfor. Man kan godt bruke interaksjonsledd, polynomer, splines og andre fancy ting. Men med måte."
  },
  {
    "objectID": "linear_regresjon.html#oppgaver",
    "href": "linear_regresjon.html#oppgaver",
    "title": "2  Lineær regresjon",
    "section": "2.2 Oppgaver",
    "text": "2.2 Oppgaver\n\nExercise 2.1 Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer.\n\n\nExercise 2.2 Velg et datasettet og formuler hva en prediksjonsmodell kan kunne brukes til. Se for deg at tiltak du foreslår vil altså ha faktiske konsekvenser, så gjør en vurdering av hvorvidt feilprediksjoner vil være problematiske og i så fall på hvilken måte. Vurder mulighetene for feil opp mot gevinst ved riktig prediksjon.\nMerk: det er ikke viktig at anvendelsen skal være realistisk, men du må alltid ta konsekvensen i vurderingene.\n\n\nExercise 2.3 Last inn valgte datasett og splitt i et training og et testing datasett. Sett splitten ved .70. Bruk training-data til å gjøre deg kjent med dataene og estimere modellene. Ikke bruk testing-dataene inntil du får beskjed om det.\n\n\nExercise 2.4 Gjør deg kjent med innholdet i disse training-dataene. Du kan gjøre f.eks. følgende:\n\nBruk glimpse() og skim() til å få oversikt over innholdet i datasettet\nHvis det er noen variable du ikke kommer til å bruke, slett gjerne disse med en gang\nLag noen tabeller og plot som viser hvordan utfallsvariabelen er fordelt etter andre variable\n\n\n\nExercise 2.5 Estimer flere lineær regresjonsmodeller med et fåtall prediktorer. Gjør et utvalg av de variablene du mener er mest relevant for å forklare utfallet. Estimer flere lineære regresjonsmodeller for å predikere utfallet, og sammenlign hvor gode prediksjoner disse gir. Mest relevante statistikker er \\(r^2\\) og RMSE.\n\nVelg ut tre forklaringsvariable og estimer en regresjonsmodell\nEstimer en ny modell med alle variable i datasettet\nEstimer en ny modell og inkluder noen få polynomer og/eller interaksjonsledd\nGjør et automatisk modellsøk\n\nPlot også predikert verdi mot observert verdi og gjør en vurdering av RMSE.\n\n\nExercise 2.6 I forrige oppgave brukte du testing-datasettet til både å estimere modellene og vurdere resultatet. Nå skal du bruke testing-datasettet til å vurdere de samme resultatene. Dette gjør du ved å predikere på testing-datasettet og regne ut \\(r^2\\) og RMSE for disse dataene. For hver modell i forrige oppgave, gjør som følger:\n\nPrediker utfallet på testing-datasettet\nRegn ut \\(r^2\\) og RMSE\nHvor stor er endringen i \\(r^2\\) og RMSE fra resultatene når du brukte training-datasettet?\n\nVurdering: En mer komplisert modell beskriver dataene bedre. Men er det like stor endring i \\(r^2\\) og RMSE for enkle og mer kompliserte modeller? Beskriv hva du ser og gi en forklaring."
  },
  {
    "objectID": "linear_regresjon.html#footnotes",
    "href": "linear_regresjon.html#footnotes",
    "title": "2  Lineær regresjon",
    "section": "",
    "text": "Bortsett fra for dem som mener det er svaret på “the Ultimate Question of Life, the Universe, and Everything”↩︎\nDenne formuleringen er ganske omtrentlig. RMSE er egentlig kvadratroten av gjennomsnittet til de kvadrerte residualene, som er noe litt annet enn gjennomsnittet av de absolutte verdiene av residualene. Det gir bl.a. litt mer vekt til store residualer enn et vanlig gjennomsnitt.↩︎\nDette er en omtrentelig formulering. Alle sannsynligheter gjelder i det lange løp: altså hvis man gjør undersøkelsen veldig mange ganger.↩︎\nDenne formuleringen er ganske omtrentlig. RMSE er egentlig kvadratroten av gjennomsnittet til de kvadrerte residualene, som er noe litt annet enn gjennomsnittet av de absolutte verdiene av residualene. Det gir bl.a. litt mer vekt til store residualer enn et vanlig gjennomsnitt↩︎"
  }
]