[
  {
    "objectID": "intro_fairness.html#hva-slags-rettferdighet",
    "href": "intro_fairness.html#hva-slags-rettferdighet",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.1 Hva slags rettferdighet",
    "text": "4.1 Hva slags rettferdighet\nI denne settingen kan rettferdighet kommer i betraktning på flere måter, herunder følgende:\n\nI hvilken grad maskiner vs mennesker tar avgjørelser, og herunder mulighet til å bli hørt og legge frem sin sak\nI hvilken grad dataene algoritmen er trent opp på inneholder skjevheter i utgangspunktet som så reproduseres i videre implementering\nI hvilken grad sluttresultatet har rimelig presisjon og akseptable feilrater, herunder vurdering av asymetriske feilrater\nI hvilken grad forrige punkt er avpasset mot hvilke tiltak man så setter i verk\nI hvilken grad feilrater og presisjon varierer systematisk med undergrupper i populasjonen\n\nDet er nok av ting å tak i her, men vi skal her fokusere på det som kan tallfestes gitt den modellen man har. Men for all del: Hvis datakvaliteten er det begrenset hvor bra det kan bli uansett. Selv om kjente skjevheter i dataene kan i prinsippet motarbeides, så er det vel i praksis slik at en skjevhet kommer sjelden alene?\nVurderinger av overordnet feilrater er et gjennomgående tema, så vi starter med det. Deretter skal vi se på mål på skjevheter over undergrupper. Prinsippet er relativt enkelt, uten at vurderingene blir enkle av den grunn."
  },
  {
    "objectID": "intro_fairness.html#mer-confusion-matrix",
    "href": "intro_fairness.html#mer-confusion-matrix",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.2 Mer confusion matrix",
    "text": "4.2 Mer confusion matrix\n\n\nCode\nest_multlogit <- glm(Attrition ~ ., data = training, family = \"binomial\")\nsummary(est_multlogit)\n\n\n\nCall:\nglm(formula = Attrition ~ ., family = \"binomial\", data = training)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6886  -0.4840  -0.2374  -0.0862   3.3170  \n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                      -1.090e+01  7.450e+02  -0.015 0.988322    \nAge                              -3.671e-02  1.637e-02  -2.243 0.024906 *  \nBusinessTravelTravel_Frequently   1.627e+00  4.663e-01   3.490 0.000483 ***\nBusinessTravelTravel_Rarely       8.847e-01  4.265e-01   2.074 0.038070 *  \nDailyRate                        -3.249e-04  2.657e-04  -1.223 0.221450    \nDepartmentResearch & Development  1.303e+01  7.450e+02   0.017 0.986048    \nDepartmentSales                   1.348e+01  7.450e+02   0.018 0.985565    \nDistanceFromHome                  4.325e-02  1.308e-02   3.307 0.000944 ***\nEducation                         2.259e-03  1.047e-01   0.022 0.982789    \nEducationFieldLife Sciences      -8.614e-01  1.036e+00  -0.832 0.405637    \nEducationFieldMarketing          -2.986e-01  1.085e+00  -0.275 0.783245    \nEducationFieldMedical            -9.341e-01  1.037e+00  -0.901 0.367673    \nEducationFieldOther              -8.090e-01  1.106e+00  -0.731 0.464508    \nEducationFieldTechnical Degree    6.014e-02  1.057e+00   0.057 0.954635    \nEmployeeNumber                   -3.297e-04  1.818e-04  -1.814 0.069727 .  \nEnvironmentSatisfaction          -4.976e-01  9.990e-02  -4.981 6.31e-07 ***\nGenderMale                        2.224e-01  2.157e-01   1.031 0.302405    \nHourlyRate                       -3.877e-03  5.392e-03  -0.719 0.472136    \nJobInvolvement                   -5.454e-01  1.458e-01  -3.741 0.000183 ***\nJobLevel                         -1.437e-02  3.834e-01  -0.037 0.970101    \nJobRoleHuman Resources            1.413e+01  7.450e+02   0.019 0.984868    \nJobRoleLaboratory Technician      1.579e+00  5.597e-01   2.822 0.004773 ** \nJobRoleManager                   -1.613e+00  1.280e+00  -1.260 0.207596    \nJobRoleManufacturing Director    -2.403e-01  6.135e-01  -0.392 0.695291    \nJobRoleResearch Director         -2.531e+00  1.243e+00  -2.035 0.041806 *  \nJobRoleResearch Scientist         3.845e-01  5.748e-01   0.669 0.503513    \nJobRoleSales Executive            3.167e-01  1.614e+00   0.196 0.844462    \nJobRoleSales Representative       1.478e+00  1.662e+00   0.890 0.373555    \nJobSatisfaction                  -3.238e-01  9.696e-02  -3.340 0.000839 ***\nMaritalStatusMarried              3.633e-01  3.130e-01   1.161 0.245800    \nMaritalStatusSingle               9.102e-01  4.057e-01   2.243 0.024875 *  \nMonthlyIncome                     9.730e-05  9.890e-05   0.984 0.325190    \nMonthlyRate                       1.173e-05  1.499e-05   0.783 0.433906    \nNumCompaniesWorked                1.705e-01  4.652e-02   3.665 0.000248 ***\nOverTimeYes                       1.892e+00  2.308e-01   8.195 2.50e-16 ***\nPercentSalaryHike                -6.513e-02  4.714e-02  -1.382 0.167122    \nPerformanceRating                 6.772e-01  4.816e-01   1.406 0.159676    \nRelationshipSatisfaction         -3.888e-01  9.884e-02  -3.934 8.37e-05 ***\nStockOptionLevel                 -2.737e-01  1.822e-01  -1.502 0.133202    \nTotalWorkingYears                -6.528e-02  3.587e-02  -1.820 0.068731 .  \nTrainingTimesLastYear            -2.136e-01  8.571e-02  -2.492 0.012712 *  \nWorkLifeBalance                  -2.117e-01  1.469e-01  -1.441 0.149470    \nYearsAtCompany                    6.602e-02  4.876e-02   1.354 0.175764    \nYearsInCurrentRole               -1.021e-01  5.548e-02  -1.840 0.065748 .  \nYearsSinceLastPromotion           2.056e-01  5.166e-02   3.979 6.91e-05 ***\nYearsWithCurrManager             -1.933e-01  6.078e-02  -3.180 0.001473 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 944.39  on 1101  degrees of freedom\nResidual deviance: 616.66  on 1056  degrees of freedom\nAIC: 708.66\n\nNumber of Fisher Scoring iterations: 15\n\n\n\n\nCode\nattrition_test <- testing %>% \n  mutate(prob = predict(est_multlogit, newdata = testing, type = \"response\")) %>% \n    mutate(attrition_class = as.factor(ifelse(prob < .5, \"No\", \"Yes\")))\n\n\n\n\nCode\ncm <- confusionMatrix(attrition_test$Attrition, attrition_test$attrition_class, positive = \"Yes\")\n\ncm\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  288  12\n       Yes  42  26\n                                          \n               Accuracy : 0.8533          \n                 95% CI : (0.8129, 0.8878)\n    No Information Rate : 0.8967          \n    P-Value [Acc > NIR] : 0.9965          \n                                          \n                  Kappa : 0.4128          \n                                          \n Mcnemar's Test P-Value : 7.933e-05       \n                                          \n            Sensitivity : 0.68421         \n            Specificity : 0.87273         \n         Pos Pred Value : 0.38235         \n         Neg Pred Value : 0.96000         \n             Prevalence : 0.10326         \n         Detection Rate : 0.07065         \n   Detection Prevalence : 0.18478         \n      Balanced Accuracy : 0.77847         \n                                          \n       'Positive' Class : Yes"
  },
  {
    "objectID": "intro_fairness.html#mål-på-fairness",
    "href": "intro_fairness.html#mål-på-fairness",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.3 Mål på fairness",
    "text": "4.3 Mål på fairness\nOvenfor så vi blant annet at “positive predicted value” , altså andelen sanne positive av alle predikerte positive, er 0.382.\nMen det er ulike typer jobber i denne bedriften. Her er fordelingen for test-datasettet:\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      No, N = 3001\n      Yes, N = 681\n    \n  \n  \n    JobRole\n\n\n        Healthcare Representative\n31 (10%)\n1 (1.5%)\n        Human Resources\n11 (3.7%)\n3 (4.4%)\n        Laboratory Technician\n47 (16%)\n17 (25%)\n        Manager\n24 (8.0%)\n3 (4.4%)\n        Manufacturing Director\n29 (9.7%)\n3 (4.4%)\n        Research Director\n17 (5.7%)\n1 (1.5%)\n        Research Scientist\n59 (20%)\n18 (26%)\n        Sales Executive\n70 (23%)\n14 (21%)\n        Sales Representative\n12 (4.0%)\n8 (12%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nFor illustrasjonens skyld kan vi da dele inn datamaterialet i to deler: lab-teknikkere og resten. For hver gruppe kan vi så lage en confusion matrix og undersøke verdiene.\n\n\nCode\nlabTech <- attrition_test %>% \n  filter(JobRole %in% c(\"Laboratory Technician\"))\n\nothers <- attrition_test %>% \n  filter( !(JobRole %in% c(\"Laboratory Technician\") ))\n\ncm1 <- confusionMatrix(labTech$Attrition, labTech$attrition_class, positive = \"Yes\")\n\ncm2 <- confusionMatrix(others$Attrition, others$attrition_class, positive = \"Yes\")\n\ncm1 \n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  39   8\n       Yes 10   7\n                                         \n               Accuracy : 0.7188         \n                 95% CI : (0.5924, 0.824)\n    No Information Rate : 0.7656         \n    P-Value [Acc > NIR] : 0.8490         \n                                         \n                  Kappa : 0.251          \n                                         \n Mcnemar's Test P-Value : 0.8137         \n                                         \n            Sensitivity : 0.4667         \n            Specificity : 0.7959         \n         Pos Pred Value : 0.4118         \n         Neg Pred Value : 0.8298         \n             Prevalence : 0.2344         \n         Detection Rate : 0.1094         \n   Detection Prevalence : 0.2656         \n      Balanced Accuracy : 0.6313         \n                                         \n       'Positive' Class : Yes            \n                                         \n\n\nCode\ncm2\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  249   4\n       Yes  32  19\n                                          \n               Accuracy : 0.8816          \n                 95% CI : (0.8398, 0.9157)\n    No Information Rate : 0.9243          \n    P-Value [Acc > NIR] : 0.997           \n                                          \n                  Kappa : 0.4569          \n                                          \n Mcnemar's Test P-Value : 6.795e-06       \n                                          \n            Sensitivity : 0.82609         \n            Specificity : 0.88612         \n         Pos Pred Value : 0.37255         \n         Neg Pred Value : 0.98419         \n             Prevalence : 0.07566         \n         Detection Rate : 0.06250         \n   Detection Prevalence : 0.16776         \n      Balanced Accuracy : 0.85610         \n                                          \n       'Positive' Class : Yes             \n                                          \n\n\nPositive predicted value for lab-teknikker er 0.412 og for resten 0.373.\nForholdstallet mellom disse er 0.9047619, alså nesten likt. Slik sett kan vi si at modellen er rettferdig på dette målet ved at disse to gruppene er like.\nMen hvis du sjekker output fra confusionMatrix ovenfor, så er jo ikke alle tallene like. Så det kommer an på hvilke mål du sammenligner.\nPakken fairness gjør en tilsvarende beregning for deg og kan gi resultatet grafisk. Her er sammenligning av positive predicted value gjort for alle grupper av jobber:\n\n\nCode\npred_rate_parity(data = attrition_test,\n                 outcome = \"Attrition\", \n                 group = \"JobRole\", \n                 preds = \"attrition_class\", \n                 base = \"Laboratory Technician\"\n                 )[[2]]\n\n\n\n\n\nNå er det vesentig større forskjeller. Utvilsomt er grunnen at gruppen av ‘andre’ var sammensatt av veldig ulike grupper som var veldig forskjellig innbyrdes, men som jevnet hverandre ut i snitt. Noen av disse gruppene var dessuten små."
  },
  {
    "objectID": "intro_fairness.html#oppgaver",
    "href": "intro_fairness.html#oppgaver",
    "title": "4  En lett introduksjon til fairness",
    "section": "4.4 Oppgaver",
    "text": "4.4 Oppgaver\n\nExercise 4.1 Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer.\n\n\nExercise 4.2 Regn ut minst tre ulike mål på fairness og velg selv over hvilke grupper. Gi en forklaring på hva hver av dem betyr.\n\n\nExercise 4.3 Det er mange muligheter her: ulike mål og flere grupper. Man kan også kombinere grupper på flere måter. Gjør følgende vurderinger:\n\nEr det rimelig å gjøre en prediksjon som gir like resultater på tvers av alle mål og grupper? Kan du i det hele tatt få en “fair” modell?\nHvilke mål på “fairness” vil du si er viktigst i dette eksempelet? Hvorfor?\n\n\n\nExercise 4.4 Kanskje hjelper det å estimere en annen modell? Estimer en ny logistisk regresjon, men velg bare et fåtall variable som du velger selv. Hold det enkelt i første omgang. Se på resultatene og vurder:\n\nBle accuracy bedre eller verre?\nBle resultatet mer “fair”?\n\n\n\nExercise 4.5 Velg et nytt datasett, gjør en prediksjon med logistisk regresjon og regn ut mål på “fairness” igjen. Gjør tilsvarende som over."
  },
  {
    "objectID": "introduksjon_R.html#rstudio-projects",
    "href": "introduksjon_R.html#rstudio-projects",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.1 Rstudio projects",
    "text": "B.1 Rstudio projects\nDet anbefales sterkt å lage en mappestruktur egnet for Rstudio projects. Hensikten med dette er å ha en hensiktsmessig og ryddig mappestruktur for alt arbeidet ditt. Dette er forklart nærmere i (Wickham and Grolemund 2017), se kapittelet om workflow og særlig avsnittet om projects.\nLag en egen mappe for dette kurset og lag følgende undermapper:\n\nData\nScript\nOutput\nDokumenter\n\nDu kan også lage andre undermapper hvis du vil. Det vil være begrenset behov for å eksportere output, men det er selvsagt mulig. Lag"
  },
  {
    "objectID": "introduksjon_R.html#litt-begrepsbruk",
    "href": "introduksjon_R.html#litt-begrepsbruk",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.2 Litt begrepsbruk",
    "text": "B.2 Litt begrepsbruk\nI R er alt du gjør er med funksjoner og alt du gjør noe med er objekter.1\nAltså: Alle datasett som leses inn legger du i et objekt og du bruker ulike funksjoner for å estimere modeller. Men du kan også lagre resultater i nye objekter, som f.eks. resultatet av en regresjonsmodell. Objektene kan altså være av forskjellig type, og hvis du lurer på hva slags objekt du har kan du spørre R om det slik:\n\nclass(dittobjekt)\n\nDu gir objektene et navn som du kan referere til senere. Det spiller ingen rolle hva du kaller objektene, men kan ikke ha mellomrom. Bruk navn som gir en viss mening når du jobber med det.\nDu kan ha mange objekter i arbeidsminnet i R samtidig. Hvis du bruker et navn som er i bruk fra før, så overskriver du det gamle objektet.\nFunksjonene har også et navn og etterfølges av en parentes. Inni parentesen angis funksjonens argumenter. Noen slike argumenter er obligatoriske, mens andre er valgfrie. Ofte vil det være forhåndsvalg til en funksjon slik at du ikke behøver å oppgi mer enn et par ting. Et eksempel er å lese inn data med read.csv(), så trenger du bare angi filbanen til datasettet. Denne funksjonen antar at filen er kommaseparert, men hvis det er brukt semikolon kan du angi det med å legge til argumentet sep = \";\"."
  },
  {
    "objectID": "introduksjon_R.html#lese-inn-data",
    "href": "introduksjon_R.html#lese-inn-data",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.3 Lese inn data",
    "text": "B.3 Lese inn data\nData kommer generelt i mange ulike formater og noen ganger skaper det uforutsette utfordringer med å få data inn i R. I dette kurset er imidlertid dataene i formatene .rds eller .csv.\nAlle datasett laster du ned og lagrer i mappen for data (se forrige avsnitt) og leser inn i R derfra. For å lære mer om innlesning av data, se (Wickham and Grolemund 2017) i kapittelet om data import.\nMerk at csv-filer er tekstfiler der kollonnene er separert med komma eller semikolon. Hvis dataene ser veldig rare ut etter å lest de inn kan det være fordi det var et annet skilletegn enn du trodde.\ncsv-filer kan leses inn med funksjonen read.csv() for komma-separerte filer og read.csv2() for semikolon-separerte filer, mens rds-filer leses med readRDS().\nVær obs på at når man leser inn csv-filer så vil R gjette på hva slags variabeltyper det er. De vil i hovedsak være numeriske, tekst eller factor. I all hovedsak bør tekstvariable tolkes som factor. Dette kan du få til ved å spesifiser det når dataene leses inn slik:\n\nread.csv(\"data/navnpaadata.csv\", stringsAsFactors = TRUE)\n\nSe mer om factor-variable i neste avsnitt."
  },
  {
    "objectID": "introduksjon_R.html#variabeltyper",
    "href": "introduksjon_R.html#variabeltyper",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.4 Variabeltyper",
    "text": "B.4 Variabeltyper\nVariable kan være av forskjellige typer, primært numerisk eller kategoriske. Numeriske kan igjen være heltall eller lagret med et angitt presisjonsnivå (integer, numeric eller double), men forskjellen mellom disse har i praksis ikke noe å si for vårt bruk her. Datovariable er også numeriske, men vi skal ikke jobbe med datoer her.\nKategoriske variable er ‘string’ (dvs en tekst-streng) eller factor. Du kan lese mer om factor-variable i Wickham and Grolemund (2017) i kapittelet om factor. Kort sagt er factor-variable tekst-variable som har en tilhørende underliggende numerisk verdi som gjør at den kan benyttes i modeller og beregninger.\nEt alternativ er å kode om faktorvariable eller tekst-variable til dummy-variable med verdiene 0 eller 1.2"
  },
  {
    "objectID": "introduksjon_R.html#dele-et-datasett-i-training-og-testing",
    "href": "introduksjon_R.html#dele-et-datasett-i-training-og-testing",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.5 Dele et datasett i training og testing?",
    "text": "B.5 Dele et datasett i training og testing?\nVi bruker pakken rsample til å splitte datasettet. Funksjonen initial_split() markerer hvilke observasjoner som er i hvilken del. Så kan du trekke ut disse etterpå med training() og testing()."
  },
  {
    "objectID": "introduksjon_R.html#seed---gjør-koden-eksakt-reproduserbar",
    "href": "introduksjon_R.html#seed---gjør-koden-eksakt-reproduserbar",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.6 Seed - gjør koden eksakt reproduserbar",
    "text": "B.6 Seed - gjør koden eksakt reproduserbar\nEn tilfeldig inndeling som med initial_split() bruker tilfeldige tall som genereres av R. Det finnes ikke helt tilfeldige tall i en datamaskin, det bare ser sånn ut. Det er en slags algoritme som generer disse tallen, og det har et startpunkt som varierer med når du setter den igang. Med andre ord: en tilfeldig inndeling vil bli forskjellig hver eneste gang.\nFunksjonen set.seed() definerer startpunktet for neste sekvens av tilfeldige tall slik at du kan reprodusere nøyaktig samme resultat. Hvis dere jobber sammen på oppgaver er det en fordel å sette samme seed slik at dere kan sammenligne resultatet.\n\nset.seed(42)\n\nDette gjelder for alle funksjoner der det benyttes tilfeldige tall. Det gjelder altså for random forest.\nOBS! Vend deg til å alltid bruke set.seed når du jobber i dette kurset, for du kommer til å trenge det på eksamen! Du kan gjøre ting riktig på eksamen likevel, men da blir ikke resultatene reproduserbare og sensor kan ikke sjekke resultatene. (Dere skal få nøyaktige instruksjoner senere)."
  },
  {
    "objectID": "introduksjon_R.html#prediksjon-med-predict",
    "href": "introduksjon_R.html#prediksjon-med-predict",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.7 Prediksjon med predict()",
    "text": "B.7 Prediksjon med predict()\nDere skal bruke funksjonen predict() ganske mye. Den tar et objekt fra en eller annen modell og predikerer fra denne. Merk at den bruker det objektet dere har lagret resultatene i, ser hva slags modell det er, og predikerer i henhold til det.\nI utgangspunktet bruker den det samme datasettet som modellen ble estimert med. Men kan også predikere på nye data. Da må argumentet newdata = ... angis. Det vil typisk være testing-datasettet eller helt nye observasjoner der du ikke vet utfallet. Det nye datasettet må alle de variablene som vari det opprinnelige datasettet for at det skal funke."
  },
  {
    "objectID": "introduksjon_R.html#bruke-formula-for-utfallsvariable-og-prediktorer",
    "href": "introduksjon_R.html#bruke-formula-for-utfallsvariable-og-prediktorer",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.8 Bruke formula for utfallsvariable og prediktorer",
    "text": "B.8 Bruke formula for utfallsvariable og prediktorer\nDe modellen vi skal bruke her angir utfallsvariabel og prediktorer med en formula som angir omtrent slik: utfallsvariabel ~ prediktor1 + prediktor2. Dette tilsvarer altså å skrive \\(y = x1 + x2\\). For lineær regresjon vil den så estimere de tilhørende regresjonsparametrene \\(\\alpha\\), \\(\\beta_1\\) og \\(\\beta_2\\).\nFor andre modeller der det ikke skal estimeres parametere på samme måte vil man angi variablene på samme måte.\nFor regresjon kan man angi spesifikasjonen som følger:\n\nflere variable: y ~ x + z + k + m\ninkludere alle variable: y ~ .\nannengradsledd: y ~ x + I(x^2)\ntredjegradsledd: y ~ x + I(x^2) + I(x^3)\ninteraksjoner: y ~ x + z + x*z\n\nDisse kan også kombineres."
  },
  {
    "objectID": "introduksjon_R.html#databehandling-dplyr-verb-tidyverse",
    "href": "introduksjon_R.html#databehandling-dplyr-verb-tidyverse",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.9 Databehandling: dplyr-verb / tidyverse",
    "text": "B.9 Databehandling: dplyr-verb / tidyverse\nDet som kalles tidyverse er en samling R-pakker som til sammen danner et konsistent system for databehandling og grafikk. Hvis du bruker R uten å laste noen pakker, kalles dette base-R. Tidyverse er slik sett en dialekt av R.3\nDatabehandling med dplyr (fra tidyverse) har som hovedgrep noen verb som kan settes sammen i lengre uttrykk.\n\nmutate() brukes til å lage nye variable eller endre på variable\nfilter() brukes til å filtrere data, f.eks. velge ut en undergruppe\nselect() brukes til å velge ut variable - eller velge bort variable\nsummarise() brukes til å summere verdier, f.eks. gjennomsnitt og standardavvik\ngroup_by() brukes hvis man skal summere over grupper av observasjoner med summarise() eller mutate().\n\narrange() sorterer et datasett\n\nAlle disse verbene starter med at man angir hvilket objekt man skal gjøre noe med (dvs datasett) og deretter hva man vil gjøre.\nFor eksempel kan du lage en ny variabel som er summen av variable med navn X og Y slik:\n\nnyedata <- mutate(dinedata, sumXY = X + y)\n\nDu kan lese mer om disse verbene i R4DS (Wickham and Grolemund 2017) kapittelet Transform\nI dette kurset skal vi ofte lage en ny variabel med predict() og det gjør vi da inni en mutate(), omtrentlig slik:\n\nendretdata <- dinedata %>% \n  mutate( nyvariabel = predict(modellobjekt))\n\nHer skal resultatet være et kopi av det opprinnelige datasettet, dinedata, som lages i et nytt objekt endretdata, der den andre linjen legger til en ny variabel som inneholder predikerte verdier fra en modell lagret i modellobjekt.\n\nB.9.1 Hva gjør ‘pipe-operatoren’ %>% ??\nDu kan sette sammen flere kombinsjoner av mutate(), select() og andre dplyr-verb med %>%. Les mer om den i R4DS (Wickham and Grolemund 2017) i et eget avsnitt om pipes.\nEnkelt sagt tar %>% og legger det som er til venstre over som første argument i neste dplyr-verb. Dermed kan man sette sammen en rekke av dplyr-verb der du både filtrerer, lager nye variable, summerer osv."
  },
  {
    "objectID": "introduksjon_R.html#grafikk-quickn-dirty-vs-ggplot",
    "href": "introduksjon_R.html#grafikk-quickn-dirty-vs-ggplot",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.10 Grafikk: quick’n dirty vs ggplot",
    "text": "B.10 Grafikk: quick’n dirty vs ggplot\nEn rekke modeller har noen standard funksjoner for å plotte. Funksjonen plot() vil kjenne igjen hva slags objekt det er snakk om og så lage en viss type plot. Bruker du dette på et objekt for lineær regresjon får du et annet type plot enn hvis du gjør det på et randomForest-objekt. Dette kan være helt utmerket for en kjapp titt på resultatene, men du har litt mindre kontroll på hva du ber om. Grafikken er ganske pen, men kanskje ikke publiseringsklar.\nI en del eksempler her brukes ggplot(). Dette er for avansert grafikk og er det som brukes i standard statistikkurs på bachelornivå på SV-fakultetet (på alle fag, tror jeg). Det er en viktig grunn til at det brukes her også. For en del visualisering av tre-baserte metoder er det vesentlig lettere å bruke spesialiserte funksjoner via plot(). Men for all del: ggplot() kan lage disse figurene også, det bare krever mer arbeid enn vi prioriterer her.\nDu kan lære mer om ggplot() i R4DS (Wickham and Grolemund 2017) i kapittelet om visualisering."
  },
  {
    "objectID": "introduksjon_R.html#hjelp-filer-og-dokumentasjon",
    "href": "introduksjon_R.html#hjelp-filer-og-dokumentasjon",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.11 Hjelp-filer og dokumentasjon",
    "text": "B.11 Hjelp-filer og dokumentasjon\nAlle funksjoner i R har en hjelp-fil som inneholder syntax, forklaring av argumentene, noen detaljer (ved behov), og eksempler. For å få tilgang til denne setter du et spørsmålstegn foran funksjonsnavnet slik:\n\n?confusionMatrix\n\nHjelpfilene kan være vanskelige å forstå hvordan fungerer. Det er ikke alltid selvforklarende, for å si det forsiktig. Men det viktige er at du ser hvilke argumenter som hører til funksjonen og hva de betyr.\n\n\n\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley."
  }
]