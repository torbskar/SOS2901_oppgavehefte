[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SOS2901 Maskinlæring for samfunnsvitere",
    "section": "",
    "text": "Dette dokumentet gir en oversikt over hva vi skal dekke i løpet av semesteret. Det lages delvis underveis, så det vil bli oppdateringer jevnlig.\nDessuten skriver jeg disse oppgavene i Quarto som jeg ikke er så god i, så jeg prøver meg litt frem. Det kan derfor hende layout og andre ting endres underveis.\n\n\nDu må installere både R og Rstudio på din datamaskin. Hvis du har Windows-maskin trenger du også installere Rtools. Hvis du har Mac OS X kan det hende du må installere XQuartz.\nSe ellers video fra SICSS\n\n\n\n\nR er basert på bruk av “pakker” som må installeres for å få tilgang til funksjoner vi skal bruke. Disse installeres med bruk av kommandoen install.packages(). F.eks. kan man installere pakken Tidyverse med følgende: install.packages(\"tidyverse\").\nFor å installere flere pakker kan man kjøre install.packages() flere ganger, men det er enklere å liste opp alle pakkene i et objekt og så kjøre install.packages() på dette objektet. Noe slikt:\n\n\nCode\npkgs <- c(\"tidyverse\", \"skimr\", \"randomForest\")\n#install.packages(pkgs)\n\n\nMen for at du skal kunne bruke pakkene må du aktivere dem i R ved library(). Dette må du gjøre hver gang du starter opp R. Det kan se slik ut:\n\n\nCode\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(randomForest)\nlibrary(caret)\nlibrary(AUC)\n\n\n\n\n\nDette kurset forutsetter at man har grunnleggende ferdigheter i kvantitative metoder og har brukt R før. Hvis du vet du trenger det: frisk opp litt fra tidligere kurs.\nNår det er sagt, så er det begrenset hvor mye man bør kunne fra før og er du motivert til å jobbe med stoffet skal du nok få til dette.\nHvis du trenger oppfriskning av hvordan R fungerer, så er Wickham & Grolemunds bok “R for data science” et utmerket oppslagsverk. Men merk at vi i begrenset grad vil bruke “Tidyverse” til annet enn datahåndtering og noe grafikk."
  },
  {
    "objectID": "bagging.html",
    "href": "bagging.html",
    "title": "6  Bagging",
    "section": "",
    "text": "Code\n# Kilde: https://www.statology.org/bagging-in-r/ \n\nlibrary(e1071)       #for calculating variable importance\nlibrary(caret)       #for general model fitting\nlibrary(rpart)       #for fitting decision trees\nlibrary(ipred)       #for fitting bagged decision trees\n\ncredit <- read.csv(\"../data/credit.csv\", stringsAsFactors = TRUE) \n\n\n\n\n\nExercise 7.1 Bruk bagging til å forbedre prediksjonene. Bruk samme formel, men bygg 150 trær.\n\n\n\nSolution. \n\nCode\nfmla <- default ~ age + amount + percent_of_income + purpose + employment_duration + housing \n\nfmla\n\n\ndefault ~ age + amount + percent_of_income + purpose + employment_duration + \n    housing\n\n\nCode\nset.seed(1)\nbag <- bagging(\n  formula = fmla,\n  data = credit,\n  nbagg = 150,   \n  coob = TRUE,\n  control = rpart.control(minsplit = 2, cp = 0)\n)\nbag\n\n\n\nBagging classification trees with 150 bootstrap replications \n\nCall: bagging.data.frame(formula = fmla, data = credit, nbagg = 150, \n    coob = TRUE, control = rpart.control(minsplit = 2, cp = 0))\n\nOut-of-bag estimate of misclassification error:  0.342"
  },
  {
    "objectID": "randomForest.html",
    "href": "randomForest.html",
    "title": "7  Random forest",
    "section": "",
    "text": "Random forest bruker klassifikasjonstrær og bagging som byggestener. I prinsippet er det “bagged trees”, men i stedet for å bagge samme type trær, så gjøres det en endring i hvert tre."
  },
  {
    "objectID": "randomForest.html#tuning-av-random-forest",
    "href": "randomForest.html#tuning-av-random-forest",
    "title": "7  Random forest",
    "section": "7.2 Tuning av random forest",
    "text": "7.2 Tuning av random forest\nDet som faktisk endrer resultatene en god del er sampling prosedyren, altså hvor mange observasjoner som trekkes til å bygge hvert tre. I utgangspunktet trekkes 70% av hele utvalget. Men ved å bruke argumentet sampsize = ... kan vi angi en annen andel. Hvis vi angir to tall er det antallet som trekkes fra hver kategori i utfallsvariabelen. Vi kan altså angi hvor mange som trekkes av de med og uten tilbakefall, men disse tallene bør ikke settes større enn 70% av hver kategori. I disse dataene er det 2809 med tilbakefall og 3364 uten tilbakefall. Vi kan da velge å trekke maks 1900 fra gruppen med tilbakefall.\nHensikten med å gjøre dette er at hvis det er et mindretall som har tilbakefall, så blir hvert tre bygget med mer informasjon om ikke-residivistene enn residivistene. Hvis vi vekter opp residivistene, så får disse større inflytelse på hvert tre. Dermed vil dette også påvirke resultatet. Det er imidlertid vanskelig å vite helt sikkert hvordan det vil slå ut, så man må prøve seg litt frem. Noen ganger vil man veie gruppene likt, andre ganger ulikt. Her er et eksempel der de veies likt:\n\n\nCode\nset.seed(4356)\nrf3 <- randomForest(Two_yr_Recidivism ~ . , \n                    sampsize = c(1900, 1900),\n                    data = compas)\nrf3\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      sampsize = c(1900, 1900)) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.73%\nConfusion matrix:\n     0    1 class.error\n0 2321 1042   0.3098424\n1  978 1831   0.3481666\n\n\nHer er et eksempel der de veies ulikt:\n\n\nCode\nset.seed(4356)\nrf3 <- randomForest(Two_yr_Recidivism ~ . , \n                    sampsize = c(1000, 1900),\n                   data = compas)\nrf3\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      sampsize = c(1000, 1900)) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 41.15%\nConfusion matrix:\n     0    1 class.error\n0 1170 2193   0.6520963\n1  347 2462   0.1235315\n\n\nDet viktige nå er at feilratene for falske positive og falske negative blir vesentlig forskjellig! Det betyr at ved hvordan vi estimerer modellen kan vi legge sterke føringer på resultatet. Vi bør derfor ta stilling til på forhånd hvilke feilrater vi er villig til å akseptere - og hvorvidt de to typer feil er like ille eller ikke. Det er dette Berk (2016) kaller asymetriske kostnader og må vurderes i henhold til konsekvenser av hva prediksjonen skal brukes til.\nPredikere for nye data:\n\n\nCode\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf, newdata=compas))\n\n\nConfusion matrix:\n\n\nCode\nconfusionMatrix(compas_p$pred_rf, compas_p$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2595 1156\n         1  768 1653\n                                          \n               Accuracy : 0.6883          \n                 95% CI : (0.6765, 0.6998)\n    No Information Rate : 0.5449          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.3642          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n                                          \n            Sensitivity : 0.5885          \n            Specificity : 0.7716          \n         Pos Pred Value : 0.6828          \n         Neg Pred Value : 0.6918          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2678          \n   Detection Prevalence : 0.3923          \n      Balanced Accuracy : 0.6800          \n                                          \n       'Positive' Class : 1"
  },
  {
    "objectID": "randomForest.html#oppgaver",
    "href": "randomForest.html#oppgaver",
    "title": "7  Random forest",
    "section": "7.3 Oppgaver",
    "text": "7.3 Oppgaver\n\nExercise 7.1 Bruk datasettet credit som i forrige oppgave.\n\nBruk random forest til å gjøre en tilsvarende klassifisering som du gjorde med klassifikasjonstre. Bruk default instillinger i randomForest().\nBruk predict() til å klassifisere\nLag en confusion matrix med table() og gjenta med confusionMatrix()\nGjør en vurdering av resultatet og sammenlign med resultat fra klassifikasjonstre\n\n\n\nExercise 7.2 Gjenta oppgave 1, men se om du kan justere modellen til et mer tilfredsstillende resultat. Gjør deg først opp en mening om hvordan du vil at confusion matrix skal se ut (f.eks. cost-ratio) og prøv å nærme deg dette. Bruk parameterne sampsize, mtry og ntree.\n\n\nExercise 7.3 Tolk random forest a) Hvilke variable har størst prediktiv verdi? Lag et variable importance plot og gi en tolkning. a) Velg noen av variablene (gjerne f.eks. de med størst prediktiv verdi) og lag partial dependence plot.\n\n\nExercise 7.4 Datafilen credit_kunder.csv inneholder data om to lånesøkere: Ola Normann og Kari Hansen. Skal banken gi dem lån? Bruk foretrukne modell fra forrige oppgave. Hvis du virkelig vil at begge skal få lån kan du kanskje justere modellen? Legge til/fjerne variable fra formelen og justere tuning parametrene. Prøv deg frem."
  },
  {
    "objectID": "fairness.html",
    "href": "fairness.html",
    "title": "8  Fairness",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(randomForest)\nlibrary(caret)\nlibrary(fairness)\n\n\nCompas er et risikoverktøy brukt av amerikansk politi i flere stater som benyttes på individnivå. Bruken av dette verktøyet har vært kontroversielt i flere år og kraftig kritisert av flere. En viktig grunn er at prediksjonene slår forskjellig ut for ulike grupper og er slik sett “biased” mot bl.a. svarte borgere. Resultatet er at de blir mer utsatt for politiets oppmerksomhet enn andre.1 Et datasett er gjort tilgjengelig av Propublica her som vi skal bruke.\n\n\nCode\ncompas <- readRDS(\"../data/compas.rds\")\n\nglimpse(compas)\n\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\nVi tilpasser først en random forest modell.\n\n\nCode\nset.seed(4356)\nglimpse(compas)\n\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\nCode\nrf <- randomForest(Two_yr_Recidivism ~ .,\n                   #importance = TRUE,\n                    data = compas)\n\n\nLager en prediksjon i nytt datasett\n\n\nCode\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf))  \n\n\nConfusion matrix\n\n\nCode\nconfusionMatrix(compas_p$pred_rf,\n                compas_p$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2462 1132\n         1  901 1677\n                                          \n               Accuracy : 0.6706          \n                 95% CI : (0.6587, 0.6823)\n    No Information Rate : 0.5449          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.3313          \n                                          \n Mcnemar's Test P-Value : 3.378e-07       \n                                          \n            Sensitivity : 0.5970          \n            Specificity : 0.7321          \n         Pos Pred Value : 0.6505          \n         Neg Pred Value : 0.6850          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2717          \n   Detection Prevalence : 0.4177          \n      Balanced Accuracy : 0.6645          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nSplitter datasettet i to etter kjønn. Her for menn.\n\n\nCode\ncompas_1 <- compas_p %>% \n  filter(Sex == \"Male\")\n\n\nConfusion matrix for menn\n\n\nCode\nconfusionMatrix(compas_1$pred_rf,\n                compas_1$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 1807  897\n         1  794 1499\n                                          \n               Accuracy : 0.6616          \n                 95% CI : (0.6483, 0.6747)\n    No Information Rate : 0.5205          \n    P-Value [Acc > NIR] : < 2e-16         \n                                          \n                  Kappa : 0.3209          \n                                          \n Mcnemar's Test P-Value : 0.01312         \n                                          \n            Sensitivity : 0.6256          \n            Specificity : 0.6947          \n         Pos Pred Value : 0.6537          \n         Neg Pred Value : 0.6683          \n             Prevalence : 0.4795          \n         Detection Rate : 0.3000          \n   Detection Prevalence : 0.4589          \n      Balanced Accuracy : 0.6602          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nSplitter datasettet i to etter kjønn. Her for kvinner.\n\n\nCode\ncompas_2 <- compas_p %>% \n  filter(Sex == \"Female\")\n\n\nConfusion matrix for kvinner\n\n\nCode\nconfusionMatrix(compas_2$pred_rf,\n                compas_2$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 655 235\n         1 107 178\n                                         \n               Accuracy : 0.7089         \n                 95% CI : (0.682, 0.7348)\n    No Information Rate : 0.6485         \n    P-Value [Acc > NIR] : 6.251e-06      \n                                         \n                  Kappa : 0.3128         \n                                         \n Mcnemar's Test P-Value : 6.539e-12      \n                                         \n            Sensitivity : 0.4310         \n            Specificity : 0.8596         \n         Pos Pred Value : 0.6246         \n         Neg Pred Value : 0.7360         \n             Prevalence : 0.3515         \n         Detection Rate : 0.1515         \n   Detection Prevalence : 0.2426         \n      Balanced Accuracy : 0.6453         \n                                         \n       'Positive' Class : 1              \n                                         \n\n\nBruker funksjoner i fairness-pakken til å gjøre det samme:\n\n\nCode\nacc <- acc_parity(data = compas_p, \n                  outcome      = 'Two_yr_Recidivism', \n                  group        = 'Sex',\n                  preds        = 'pred_rf', \n                  base         = 'Female')\nacc$Metric\n\n\n                      Female        Male\nAccuracy           0.7089362    0.661597\nAccuracy Parity    1.0000000    0.933225\nGroup size      1175.0000000 4997.000000\n\n\nHer er en grafisk fremstilling av ACC\n\n\nCode\nacc$Metric_plot"
  },
  {
    "objectID": "fairness.html#flere-mål-på-fairness",
    "href": "fairness.html#flere-mål-på-fairness",
    "title": "8  Fairness",
    "section": "8.2 Flere mål på fairness",
    "text": "8.2 Flere mål på fairness"
  },
  {
    "objectID": "fairness.html#tuning-til-mer-fairness",
    "href": "fairness.html#tuning-til-mer-fairness",
    "title": "8  Fairness",
    "section": "8.3 Tuning til mer fairness",
    "text": "8.3 Tuning til mer fairness"
  },
  {
    "objectID": "fairness.html#oppgaver",
    "href": "fairness.html#oppgaver",
    "title": "8  Fairness",
    "section": "8.4 Oppgaver",
    "text": "8.4 Oppgaver"
  },
  {
    "objectID": "boosting.html",
    "href": "boosting.html",
    "title": "9  Boosting",
    "section": "",
    "text": "Det er flere typer boosting-algoritmer. Vi skal først se på adaptive boosting fordi det er den enkleste (og eldste) varianten. Deretter ser vi på gradient boosting fordi andre mer avanserte boosting-algoritmer er varianter av denne.\nKilde: https://towardsdatascience.com/how-to-select-between-boosting-algorithm-e8d1b15924f7"
  },
  {
    "objectID": "boosting.html#adaptive-boosting---adaboost",
    "href": "boosting.html#adaptive-boosting---adaboost",
    "title": "9  Boosting",
    "section": "9.1 Adaptive boosting - Adaboost",
    "text": "9.1 Adaptive boosting - Adaboost\nAdaptive boosting har et enkelt prinsipp: Først estimeres en modell, og deretter estimeres en ny modell der feilklassifikasjonene fra forrige modell vektes tyngre. Teorien tilsier at dette vil bedre klassifikasjonen. Så fortsetter den slik og estimerer nye vektede modeller til vi ikke får noen vesetnlig forbedring."
  },
  {
    "objectID": "boosting.html#gradient-boosting---gbm",
    "href": "boosting.html#gradient-boosting---gbm",
    "title": "9  Boosting",
    "section": "9.2 Gradient boosting - gbm",
    "text": "9.2 Gradient boosting - gbm\nGradient boosting er bygget på et tilsvarende prinsipp, men vekter ikke dataene. Derimot bruker den loss-funksjon i stedet."
  },
  {
    "objectID": "boosting.html#extreme-gradient-boosting---xgboost",
    "href": "boosting.html#extreme-gradient-boosting---xgboost",
    "title": "9  Boosting",
    "section": "9.3 Extreme gradient boosting - XGboost",
    "text": "9.3 Extreme gradient boosting - XGboost"
  },
  {
    "objectID": "unsupervised.html",
    "href": "unsupervised.html",
    "title": "11  Unsupervised learning",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dendextend)\n\n\n\n---------------------\nWelcome to dendextend version 1.16.0\nType citation('dendextend') for how to cite the package.\n\nType browseVignettes(package = 'dendextend') for the package vignette.\nThe github page is: https://github.com/talgalili/dendextend/\n\nSuggestions and bug-reports can be submitted at: https://github.com/talgalili/dendextend/issues\nYou may ask questions at stackoverflow, use the r and dendextend tags: \n     https://stackoverflow.com/questions/tagged/dendextend\n\n    To suppress this message use:  suppressPackageStartupMessages(library(dendextend))\n---------------------\n\n\nAttaching package: 'dendextend'\n\nThe following object is masked from 'package:stats':\n\n    cutree\n\n\nCode\nlibrary(directlabels)"
  },
  {
    "objectID": "unsupervised.html#hierarkisk-klustering",
    "href": "unsupervised.html#hierarkisk-klustering",
    "title": "11  Unsupervised learning",
    "section": "11.1 Hierarkisk klustering",
    "text": "11.1 Hierarkisk klustering\n\nExercise 11.1 Last ned filen krim2016.RData fra Canvas. Dette er deler av dataene vi brukte i første seminar med kommunetall. Her er det anmeldt kriminalitet per 1000 innbyggere i kommuner i 2016.\n\nGjør en hierarkisk klusteranalsyse. Er det noen kommuner som skiller seg veldig fra de andre? Spiller det noen rolle hvilken type distance du setter?\nHvilke kommuner er de de klusterne som skiller seg ut?\nHva kjennetegner lovbruddsbildet i de ulike klustrene? Kan du tenke deg noen grunner til at akkurat disse stikker seg ut?\n\n\n\nSolution. Leser inn data om inntektsutvikling for ulike yrker fra 2001 til 2016\nDataene er i “bred” format. Det er slik vi vil ha det for clusteranalyse, men dårlig for å lage en graf.\n\n\nCode\nload(\"../data/oes.RData\")\n\ngathered_oes <- gather(data = df_oes, \n                       key = year, \n                       value = mean_salary, \n                       -occupation)\n\nggplot(gathered_oes, aes(x=as.numeric(year), y=mean_salary, col = occupation))+\n  geom_line()\n\n\n\n\n\nCode\ndist_oes <- dist(df_oes[,-1], method = \"euclidian\") # calculate distances \n\nhc_oes <- hclust(dist_oes, method = \"single\")  # minste avstand\n\nhc_oes <- hclust(dist_oes, method = \"complete\") # lengste avstand\n\nhc_oes <- hclust(dist_oes, method = \"average\") #gjennomsnittlig avstand\n\npar(mar=c(10,4,2,2))  # Endre marginer for base-plot\n\ndend_oes <- as.dendrogram(hc_oes) #Create a dendrogram object\ndend_colored <- color_branches(dend_oes, h = 100000)\nplot(dend_colored)\n\n# Illustrer mulige cutoff - legger linjer oppå eksisterende plot\nabline(h=100000, col=\"red\", lwd=1.5)  # Viser cut ved h=100000\nabline(h=10000, col=\"red\", lwd=1.5)   # Viser cut ved h=10000\n\n\n\n\n\nCode\n# Henter ut cluster ved valgt h\ncluster <- cutree(hc_oes, h=100000)\n#cluster <- cutree(hc_oes, k=3)\ntable(cluster)\n\n\ncluster\n 1  2  3 \n 2  5 15 \n\n\nCode\n# Legger til vektoren cluster til opprinnelige data\nhclust_oes <- mutate(df_oes, cluster = cluster)\n\nhead(hclust_oes)\n\n\n                 occupation  2001  2002  2003  2004  2005  2006  2007   2008\n1                Management 70800 78870 83400 87090 88450 91930 96150 100310\n2       Business Operations 50580 53350 56000 57120 57930 60000 62410  64720\n3          Computer Science 60350 61630 64150 66370 67100 69240 72190  74500\n4  Architecture/Engineering 56330 58020 60390 63060 63910 66190 68880  71430\n5 Life/Physical/Social Sci. 49710 52380 54930 57550 58030 59660 62020  64280\n6        Community Services 34190 34630 35800 37050 37530 39000 40540  41790\n    2010   2011   2012   2013   2014   2015   2016 cluster\n1 105440 107410 108570 110550 112490 115020 118020       1\n2  67690  68740  69550  71020  72410  73800  75070       2\n3  77230  78730  80180  82010  83970  86170  87880       2\n4  75550  77120  79000  80100  81520  82980  84300       2\n5  66390  67470  68360  69400  70070  71220  72930       2\n6  43180  43830  44240  44710  45310  46160  47200       3\n\n\nCode\n# vrenger dataene \"nedover\" for å plotte\ngathered_oes <- gather(data = hclust_oes,    # datasett\n                       key = year,           # navn på ny variabel, verdier hentes fra gamle variabelnavn\n                       value = mean_salary,  # navn på ny variabel med gamle variabelverdier\n                       -occupation, -cluster) # variable som skal beholdes / grupperes etter\nggplot(gathered_oes, aes(x = year, y = mean_salary, color = factor(cluster), group = occupation)) + \n  geom_line()"
  },
  {
    "objectID": "unsupervised.html#k-means-klustering",
    "href": "unsupervised.html#k-means-klustering",
    "title": "11  Unsupervised learning",
    "section": "11.2 K-means klustering",
    "text": "11.2 K-means klustering\n\nExercise 11.2 Gjenta analysen over med k-means clustering. Hvor mange klustre bør det være? Får du samme resultat?\n\n\n\nSolution. \n\nCode\n## K-means clustering med samme data \n\n# Eksempel ved å sette antall kluster til 3\n# I dette tilfellet bør vi få samme resultat\nkm_oes <- kmeans(dist_oes, centers = 3)\n\ntable(km_oes$cluster)\n\n\n\n1 2 3 \n7 7 8 \n\n\nCode\nkmclust_oes <- mutate(df_oes, cluster=km_oes$cluster)\n\n# Plotter\ngathered_kmoes <- gather(data = kmclust_oes,    # datasett\n                       key = year,           # navn på ny variabel, verdier hentes fra gamle variabelnavn\n                       value = mean_salary,  # navn på ny variabel med gamle variabelverdier\n                       -occupation, -cluster) # variable som skal beholdes / grupperes etter\nggplot(gathered_kmoes, aes(x = year, y = mean_salary, color = factor(cluster), group = occupation)) + \n  geom_line()\n\n\n\n\n\nCode\n### K-means clustering. Make a search\nwss <- 0\n# For 1 to 15 cluster centers\nfor (i in 1:5) {\n  km.out <- kmeans(dist_oes, centers = i, nstart=20)\n  # Save total within sum of squares to wss variable\n  wss[i] <- km.out$tot.withinss\n}\n\n# Plot total within sum of squares vs. number of clusters\nplot(1:5, wss, type = \"b\", \n     xlab = \"Number of Clusters\", \n     ylab = \"Within groups sum of squares\")\n# Marker \"albuen\" med en linje i plottet \nabline(v=2, col=\"red\")\n\n\n\n\n\nCode\noes <- readRDS(\"../data/oes.rds\")\n\n## Create final clustering\nkm_oes <- kmeans(oes, centers = 2, nstart=20)\ntable(km_oes$cluster)\n\n\n\n 1  2 \n 7 15 \n\n\nCode\nkmclust_oes <- mutate(df_oes, cluster=km_oes$cluster)\ngathered_kmoes <- gather(data = kmclust_oes,    # datasett\n                         key = year,           # navn på ny variabel, verdier hentes fra gamle variabelnavn\n                         value = mean_salary,  # navn på ny variabel med gamle variabelverdier\n                         -occupation, -cluster) # variable som skal beholdes / grupperes etter\nggplot(gathered_kmoes, aes(x = year, y = mean_salary, color = factor(cluster), group = occupation)) + \n  geom_line()"
  },
  {
    "objectID": "unsupervised.html#datareduksjon-med-principal-component-analysis-pca",
    "href": "unsupervised.html#datareduksjon-med-principal-component-analysis-pca",
    "title": "11  Unsupervised learning",
    "section": "11.3 Datareduksjon med principal component analysis (PCA)",
    "text": "11.3 Datareduksjon med principal component analysis (PCA)\n\n11.3.1 Multippel korrespondanseanalyse\nPCA har egentlig som forutsetning av variablene er kontinuerlige, og det er litt trøblete å bruke det på kategoriske variable. Men ofte har vi kategoriske variable.\nEn variant av PCA for kategoriske variable er korrespondanseanalyse, som i teorien altså skal være bedre enn PCA. I praksis er det imidlertid ikke nødvendigvis veldig stor forskjell (REF), så det er neppe stor skade skjedd hvis man bruker PCA likevel."
  },
  {
    "objectID": "randomForest.html#eksempel",
    "href": "randomForest.html#eksempel",
    "title": "7  Random forest",
    "section": "7.1 Eksempel",
    "text": "7.1 Eksempel\nLeser inn Compas-dataene.\n\n\nCode\ncompas <- readRDS(\"../data/compas.rds\")\nglimpse(compas)\n\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\nEstimerer random forest med alle variable\n\n\nCode\nset.seed(4356)\nrf <- randomForest(Two_yr_Recidivism ~ . , \n                    data = compas)\nrf\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.94%\nConfusion matrix:\n     0    1 class.error\n0 2462  901   0.2679156\n1 1132 1677   0.4029904\n\n\nFølgende plot gir en oversikt over feilrater for random forest etter hvor mange trær. Det siste tallet til høyre i plottet er de feilratene som vises i output fra randomForest som vist over. Den svarte linjen er altså den totale feilraten, den grønne er falske positive, og den røde er falske negative. I utgangspunktet bruker random forest 500 trær (slik den er implementert i R). Dette plottet viser når resultatene stabiliserer seg. Kort sagt: Hvis linjene er ganske stabile mot til høyre i plottet har man nok trær. Hvis det har stabilisert seg før kunne man forsåvidt klart seg med færre trær. Hvis grafen er ganske humpete mot høyre i plottet, så kan man øke antall trær og se om det bedrer seg.\n\n\nCode\nplot(rf)\n\n\n\n\n\nPredikerer på samme datasett\n\n\nCode\ncompas_p <- compas %>% \n  mutate(pred_rf = predict(rf))\n\n\nLager enkel krysstabell med predikert mot observert (dvs confusion matrix)\n\n\nCode\ntable(compas_p$pred_rf, compas_p$Two_yr_Recidivism) \n\n\n   \n       0    1\n  0 2462 1132\n  1  901 1677\n\n\nLager bedre confusion matrix med alle øvrige utregninger. NB! Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei.\n\n\nCode\nconfusionMatrix(compas_p$pred_rf,\n                compas_p$Two_yr_Recidivism, positive=\"1\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 2462 1132\n         1  901 1677\n                                          \n               Accuracy : 0.6706          \n                 95% CI : (0.6587, 0.6823)\n    No Information Rate : 0.5449          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.3313          \n                                          \n Mcnemar's Test P-Value : 3.378e-07       \n                                          \n            Sensitivity : 0.5970          \n            Specificity : 0.7321          \n         Pos Pred Value : 0.6505          \n         Neg Pred Value : 0.6850          \n             Prevalence : 0.4551          \n         Detection Rate : 0.2717          \n   Detection Prevalence : 0.4177          \n      Balanced Accuracy : 0.6645          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nEstimerer på nytt og øker antall trær og lager nytt plot. Her er det lagt inn en linje ved 500 trær for å markere tilsvarende resultat som ovenfor. Merk at det endelige resultatet endrer seg noe og mer stabilt mot slutten enn før, men kanskje ikke veldig vesentlig bedre. Merk at vi ikke kan forvente at linjene blir helt flate, og bedring i den ene feilraten går gjerne på bekostning av den andre.\n\n\nCode\nset.seed(4356)\nrf1 <- randomForest(Two_yr_Recidivism ~ . , \n                    ntree = 1500, \n                   data = compas)\n\nplot(rf1)\nabline(v=500, col = \"gray\")\n\n\n\n\n\nVi kan justere resultatet med å endre antall variable som tas med i hver split (i hvert tre). I forrige eksempel valgte funksjonen å bruke kun to variable, men det kan settes til f.eks. fire. Merk at det er et poeng at det ikke skal være så mange variable i hver split! Dette endrer normalt ikke resultatene veldig mye.\n\n\nCode\nset.seed(4356)\nrf2 <- randomForest(Two_yr_Recidivism ~ . , \n                    mtry=4,\n                    data = compas)\nrf2\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      mtry = 4) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 4\n\n        OOB estimate of  error rate: 34.36%\nConfusion matrix:\n     0    1 class.error\n0 2608  755   0.2245019\n1 1366 1443   0.4862941\n\n\n\n7.1.1 Variable importance\nFor å få ut variable importance må dette settes i estimeringen med importance = TRUE. Det tar nå litt lengre tid å estimere, så med store datasett bør du vente med dette til du ellers er fornøyd med modellen.\n\n\nCode\nset.seed(4356)\nrf <- randomForest(Two_yr_Recidivism ~ . , \n                   importance = TRUE, \n                    data = compas)\nrf\n\n\n\nCall:\n randomForest(formula = Two_yr_Recidivism ~ ., data = compas,      importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 32.42%\nConfusion matrix:\n     0    1 class.error\n0 2538  825   0.2453167\n1 1176 1633   0.4186543\n\n\nVi kan da plotte variable importance plot. Set type = 1 for at det skal vise gjennomsnittlig reduksjon i accuracy fremfor gini-koeffisienten. Endring i accuracy er lettest tolkbart og er oftest mest meningsfult.\n\n\nCode\nvarImpPlot(rf, type = 1)\n\n\n\n\n\nHer er det altså antall tidligere dommer som har størst betydning for prediksjon av tilbakefall, etterfulgt av alder og kjønn, og til sist om lovbruddet var en forseelse eller ikke.1\n\n\n7.1.2 Partial dependence\nHer må du velge hvilken variabel du ønsker å se på. Det er oftest de “viktigste variablene” fra variable importanc som er mest relevante å se på.\n\n\nCode\npartialPlot(rf, pred.data = compas, \n            x.var = Number_of_Priors, \n            which.class = \"1\")"
  },
  {
    "objectID": "grunnleggendeML.html",
    "href": "grunnleggendeML.html",
    "title": "3  Noen innledende metodiske begrep",
    "section": "",
    "text": "I standard samfunnsvitenskapelige metodekurs lærer man først og fremst teknikker for å beskrive data og statistisk inferens for å beskrive usikkerheten rundt estimatene. Avhengig av studiets øvrige design kan resultatene tolkes kausalt og/eller generalisere til en nærmere veldefinert populasjon.\nUsikkerhet beskrives typisk ved hjelp standardfeil, p-verdier og konfidensintervall tilhørende spesifikke statistiske tester. Dette innebærer at man bruker statistiske modeller for hvordan resultatene ville sett ut under spesifikke forutsetninger. Samplingfordelinger som normalfordelingen og en del andre tilsvarende fordelinger er derfor sentralt. De fleste teknikkene vi skal bruke i dette kurset er ikke statistiske modeller i samme forstand og det er ingen antakelser om samplingfordelinger. Standardfeil og konfidensintervall kan derfor ikke regnes ut. Usikkerhet og hvem resultatene gjelder for er også relevante for maskinlæring, men ikke helt på samme måte."
  },
  {
    "objectID": "grunnleggendeML.html#forklaringer-og-prediksjoner",
    "href": "grunnleggendeML.html#forklaringer-og-prediksjoner",
    "title": "3  Noen innledende metodiske begrep",
    "section": "3.1 Forklaringer og prediksjoner",
    "text": "3.1 Forklaringer og prediksjoner\nVi er i liten grad interessert i regresjonskoeffisienter, \\(\\beta\\), og tolkning av denne. Derimot er vi interessert i det predikerte utfallet \\(\\hat{y}_i\\)."
  },
  {
    "objectID": "grunnleggendeML.html#overfitting",
    "href": "grunnleggendeML.html#overfitting",
    "title": "3  Noen innledende metodiske begrep",
    "section": "3.2 Overfitting",
    "text": "3.2 Overfitting"
  },
  {
    "objectID": "grunnleggendeML.html#klassifikasjonsusikkerhet---grunnleggende-begreper",
    "href": "grunnleggendeML.html#klassifikasjonsusikkerhet---grunnleggende-begreper",
    "title": "3  Noen innledende metodiske begrep",
    "section": "3.3 Klassifikasjonsusikkerhet - grunnleggende begreper",
    "text": "3.3 Klassifikasjonsusikkerhet - grunnleggende begreper\n\n3.3.1 falske positive og negative\nNår vi predikerer et kategorisk utfall er det gjerne ett av utfallene vi primært er interessert i. Disse kalles positive og de andre er negative. Dette har ingenting å gjøre med om utfallet er bra eller dårlig å gjøre. Å predikere en sykdom vil være positivt og å være frisk vil være negativt. Å ha tilbakefall til kriminalitet vil være positivt og lovlydig vil være negativt.\nEn positiv prediksjon kan da være korrekt eller feil, og disse kalles da henholdsvis sanne eller falske positive. Tilsvarende kan en negaitv prediksjon være sann eller falsk.\n\n\n3.3.2 Confusion matrix\n\n\n3.3.3 Asymetriske kostnader"
  },
  {
    "objectID": "grunnleggendeML.html#rettferdighet-og-rimelighet",
    "href": "grunnleggendeML.html#rettferdighet-og-rimelighet",
    "title": "3  Noen innledende metodiske begrep",
    "section": "3.4 Rettferdighet og rimelighet",
    "text": "3.4 Rettferdighet og rimelighet\nI diskusjoner av anvendelser av maskinlæring står rettferdighet helt sentralt. Men det er ikke alltid like klart hva dette egentlig betyr utover at det er forskjellsbehandling. Tross alt er hele formålet med prediksjon å nettopp forskjellsbehandle, eller målrette som det også kan kalles.\n\n3.4.1 Fundamentale skjvheter i data\nSiden maskinlæring baserer seg på å lære av tilgjengelige data for å benytte det på nye tilfeller spiller det vesentlig rolle hvordan de opprinnelige dataene ble generert i utgangspunktet.\nEt velkjent eksempel er hvordan Amazon besluttet å slutte å bruke en algoritme for rekruttering fordi den systematisk valgte bort kvinner. Grunnen til at algoritmen gjorde dette var så enkelt som at dataene den var trent opp på var mannsdominert. Algoritmen hadde altså primært tilgang til informasjon om hvilke egenskaper som kjennetegnet talentfulle mannlige kandidater, som altså kan være forskjellige fra talentfulle kvinnelige kandidater.\nNår man skal ta en algoritme i bruk er det derfor helt avgjørende at man kan forsvare bruken av de dataene algoritmen er trent på. Kjente skjevheter kan i prinsippet motarbeides ved tuning (dette kommer vi tilbake til), men det er vanskelig å garantere at det er skjevheter man ikke har tenkt på.\n\n\n3.4.2 Urimelige feilrater\n\n\n3.4.3 Ulike feilrater på tvers av undergrupper"
  },
  {
    "objectID": "linear_regresjon.html#ols-i-r",
    "href": "linear_regresjon.html#ols-i-r",
    "title": "4  Lineær regresjon",
    "section": "4.1 OLS i R",
    "text": "4.1 OLS i R\nVi illustrerer lineær regresjon med et empirisk eksempel. Her skal vi bruke data for norske kommuner i 2016. La oss si at vi er interessert i hvordan antall voldshendelser per 1000 innbyggere vil endre seg i en kommune. Dette kunne være relevant for langtidsplanlegging av forebygging, politibemanning, helsetjenester osv. Det kan være et område som er i stor endring slik at befolkningssammensetningen forventes å endre seg og/eller det er endrede lokale økonomiske utsikter.\nFørst leser vi inn dataene og tar en titt på variabellisten.\n\n\nCode\nload(\"../data/kom_2016.RData\")\nglimpse(kom_2016)\n\n\nRows: 643\nColumns: 19\n$ kommune                 <chr> \"0101\", \"0104\", \"0105\", \"0106\", \"0111\", \"0119\"…\n$ year                    <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n$ bef_tot                 <int> 30328, 31802, 54192, 78159, 4480, 3613, 5346, …\n$ prop_unge_menn          <dbl> 0.11890003, 0.11533866, 0.11776646, 0.11705626…\n$ prop_kvinner_16_18      <dbl> 0.01869559, 0.01870952, 0.01967080, 0.01939636…\n$ prop_menn_16_18         <dbl> 0.01945397, 0.01911829, 0.01950472, 0.02020241…\n$ prop_menn_19_34         <dbl> 0.09944606, 0.09622036, 0.09826174, 0.09685385…\n$ prop_kvinner_19_34      <dbl> 0.09502770, 0.08993145, 0.09386994, 0.09366804…\n$ prop_shj_mottakere      <dbl> 0.03900686, 0.03631847, 0.02804842, 0.02552489…\n$ prop_shj_mottakere_6mnd <dbl> 0.013782643, 0.013018049, 0.011883673, 0.00996…\n$ gj_innt_17_34           <int> 243200, 235100, 250600, 244300, 229700, 237500…\n$ gj_innt_35_66           <int> 475800, 511100, 473400, 500700, 540200, 507300…\n$ gj_innt_alle            <int> 380500, 405300, 381400, 396600, 434400, 390600…\n$ lovb_ialt               <dbl> 108.8, 77.1, 66.5, 70.4, 59.2, 137.3, 66.8, 44…\n$ Orden                   <dbl> 18.7, 9.2, 9.6, 8.8, 4.2, 16.3, 24.7, 5.4, 9.1…\n$ Rusmiddellovbrudd       <dbl> 21.7, 14.6, 12.3, 10.3, 4.0, 29.9, 11.2, 3.9, …\n$ Trafikkovertredelse     <dbl> 14.2, 7.9, 9.6, 8.0, 5.1, 24.9, 7.9, 11.8, 8.2…\n$ Vold                    <dbl> 10.4, 8.1, 6.8, 7.4, 7.6, 5.3, 7.7, 5.4, 8.4, …\n$ lovb_annet              <dbl> 24.5, 10.3, 8.6, 10.1, 17.9, 49.3, 8.2, 8.3, 1…\n\n\nEn annen måte å få oversikt over dataene på er å bruke funksjonen skim(), som gir noe mer informasjon om fordelingen av hver enkelt variabel.\n\n\nCode\nskim(kom_2016)\n\n\n\nData summary\n\n\nName\nkom_2016\n\n\nNumber of rows\n643\n\n\nNumber of columns\n19\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n18\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nkommune\n0\n1\n4\n4\n0\n337\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n2015.49\n0.50\n2015.00\n2015.00\n2015.00\n2016.00\n2016.00\n▇▁▁▁▇\n\n\nbef_tot\n0\n1\n15435.13\n42870.98\n934.00\n3542.50\n6466.00\n14224.00\n658390.00\n▇▁▁▁▁\n\n\nprop_unge_menn\n0\n1\n0.12\n0.01\n0.08\n0.11\n0.12\n0.13\n0.17\n▁▇▆▂▁\n\n\nprop_kvinner_16_18\n0\n1\n0.02\n0.00\n0.01\n0.02\n0.02\n0.02\n0.04\n▁▇▂▁▁\n\n\nprop_menn_16_18\n0\n1\n0.02\n0.00\n0.01\n0.02\n0.02\n0.02\n0.04\n▁▇▂▁▁\n\n\nprop_menn_19_34\n0\n1\n0.10\n0.01\n0.07\n0.09\n0.10\n0.11\n0.16\n▁▇▃▁▁\n\n\nprop_kvinner_19_34\n0\n1\n0.09\n0.01\n0.06\n0.08\n0.09\n0.10\n0.15\n▂▇▃▁▁\n\n\nprop_shj_mottakere\n0\n1\n0.03\n0.01\n0.01\n0.02\n0.03\n0.03\n0.09\n▆▇▁▁▁\n\n\nprop_shj_mottakere_6mnd\n0\n1\n0.01\n0.00\n0.00\n0.00\n0.01\n0.01\n0.03\n▇▆▁▁▁\n\n\ngj_innt_17_34\n0\n1\n262773.09\n29389.17\n164200.00\n245350.00\n262500.00\n278850.00\n453100.00\n▁▇▂▁▁\n\n\ngj_innt_35_66\n0\n1\n513294.40\n55707.02\n395800.00\n479450.00\n505000.00\n533950.00\n839900.00\n▅▇▁▁▁\n\n\ngj_innt_alle\n0\n1\n407392.69\n39794.06\n319400.00\n382500.00\n400900.00\n424850.00\n629200.00\n▃▇▂▁▁\n\n\nlovb_ialt\n0\n1\n51.12\n24.18\n16.50\n35.45\n46.80\n61.65\n234.40\n▇▃▁▁▁\n\n\nOrden\n0\n1\n5.74\n3.65\n1.10\n3.30\n4.80\n7.00\n31.30\n▇▂▁▁▁\n\n\nRusmiddellovbrudd\n0\n1\n8.40\n5.57\n0.90\n4.90\n7.20\n10.70\n61.00\n▇▁▁▁▁\n\n\nTrafikkovertredelse\n0\n1\n11.19\n11.50\n2.30\n6.10\n8.90\n13.00\n209.70\n▇▁▁▁▁\n\n\nVold\n0\n1\n5.58\n2.56\n1.50\n3.80\n5.00\n6.90\n26.90\n▇▃▁▁▁\n\n\nlovb_annet\n0\n1\n9.19\n4.41\n2.60\n6.70\n8.30\n10.45\n49.30\n▇▁▁▁▁\n\n\n\n\n\n\n4.1.1 Enkel lineær regresjon\nEn ganske åpenbar faktor som forklarer forekomsten av vold er andel unge menn i kommunen. Rett og slett fordi dette er den demografiske gruppen som begår mest vold - og kriminalitet generelt, faktisk. Hvis befolkningssammensetningen forventes å bli yngre vil det medføre flere unge menn, og da kan vi kanskje forvente at det blir flere voldshendelser bare av den grunn? Sammenhengen mellom unge menn og voldsrate kan estimeres med helt vanlig lineær regresjon.\nEn god start på de fleste empiriske analyser er å beskrive sammenhengen med et plot. Her legger vi på en lineær regresjonslinje med geom_smooth() der vi presiserer lineær modell med method = \"lm\" og lar være å ta med konfidensintervallet se = FALSE.\n\n\nCode\nggplot(kom_2016, aes(x = prop_unge_menn, \n                     y = Vold)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) \n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nCode\nest <- lm(Vold ~ prop_unge_menn, data=kom_2016)\nsummary(est)\n\n\n\nCall:\nlm(formula = Vold ~ prop_unge_menn, data = kom_2016)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2293 -1.7014 -0.5256  1.2889 20.0062 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -0.9949     0.9562  -1.040    0.299    \nprop_unge_menn  54.7475     7.9243   6.909 1.18e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.469 on 641 degrees of freedom\nMultiple R-squared:  0.0693,    Adjusted R-squared:  0.06785 \nF-statistic: 47.73 on 1 and 641 DF,  p-value: 1.181e-11\n\n\nMed andre ord kan voldsraten beskrives som\n\\[ vold = -0.9949 + 54.7475 \\times ungeMenn  \\] Men vi har også sett at \\(r^2\\) er ganske lav, bare 0.0693, altså ca 7%. Denne koeffisienten kalles også “coefficient of determination” og sier noe om i hvor stor grad modellen fanger opp variasjoenen i dataene. En lav \\(r^2\\) betyr at modellen i liten grad gjør det. Vi må altså forvente at modellen vil bomme ganske kraftig i sine prediksjoner. Vi kan velge å ta modellen seriøst likevel, men ikke ha for store forventninger for prediksjonene!\nEt annet mål på hvor godt modellen treffer er “Root mean square error”, RMSE. Dette kan skrives som:\n\\[ rmse = \\sqrt{ \\frac{ \\sum{(O_i-P_i)^2} }{N} }  \\]\nder \\(O\\) er de observerte verdiene og \\(P\\) er de predikerte verdiene for observasjon \\(i\\). Merk at \\((O_i-P_i)\\) er residualene. I R kan vi hente ut residualene fra regresjons-objektet med dollartegnet ...$res etter objektnavnet. Da kan du regne ut RMSE som følger:\n\n\nCode\nrmse <- sqrt(mean(est$res^2))\nrmse\n\n\n[1] 2.465155\n\n\nRMSE sier altså omtrentlig hvor mye modellen i gjennomsnitt bommer på de observerte verdiene. 1. Hvorvidt det er presist nok eller ikke vil vel strengt tatt komme an på behovet for presisjon, altså: hva man skal bruke det til.\nFor å få litt bedre tak på hva RMSE betyr kan vi se på et plot av de predikerte og observerte verdiene. Vi kan predikere vold for hver enkelt kommune basert på denne modellen, som altså er den forventede voldsraten hvis modellen er sann. Funksjonen predict() gir oss hva vi trenger.\n\n\nCode\nkom <- kom_2016 %>% \n  mutate(pred = predict(est))\n\n\nMerk at koden her lagde en kopi av datasettet der vi har alle de opprinnelige variablene pluss en variabel med de predikerte verdiene. Vi kan nå sammenlignet prediksjonene med de observerte utfallene.\n\n\nCode\nggplot(kom, aes(x = Vold, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nHvis prediksjonen hadde vært perfekt ville disse punktene ligget på linja, noe den jo ikke gjør. Modellen bommer altså ganske mye.\nHva hvis vi vil vite forventet voldsrate for en kommune for en gitt andel unge menn? Løsningen er å lage et nytt datasett med de verdiene vi er interessert i og så predikere for dette datasettet med å spesifisere newdata = dt. Her er et eksempel der vi ønsker å vite voldsraten hvis andelen unge menn er 15%.\n\n\nCode\ndt <- data.frame(prop_unge_menn = .15)\npredict(est, newdata = dt)\n\n\n       1 \n7.217257 \n\n\nI følge modellen vil altså en kommune der 15% av populasjonen er unge menn ha en 7.2 voldshendelser per 1000 innbyggere. Fra tradisjonell statistikk vet vi jo at det er usikkerhet knyttet til dette estimatet og vi kan også ta det med i beregningen her. Vanligvis vil man estimere med et konfidensintervall, som gjelder hvis man estimerer et gjennomsnitt i en gruppe. Her skal vi derimot predikere for en enkelt kommune, som da har større usikkerhet enn om man estimerer for en enkelt observasjon. Dette kalles prediksjonsintervall og må spesifiseres i koden. Hvis det ikke er gitt vil R gi konfidensintervallet.\n\n\nCode\npredict(est, newdata = dt, interval = \"prediction\")\n\n\n       fit     lwr      upr\n1 7.217257 2.34284 12.09167\n\n\nTolkningen er ellers tilsvarende som for konfidensintervall: vi forventer med “95% sannsynlighet”2 at voldsraten vil være mellom 2.3 og 12.1 per 1000 innbyggere.\n\n\n4.1.2 Multippel regresjon\nEnkel regresjon er nettopp enkel og prediksjonen blir ikke så god. Men vi kan komplisere vesentlig ved å inkludere flere variable og bruke alle triksene man evt. har lært om multippel regresjon tidligere, primært interaksjonsledd, polynomer og transformasjoner osv.\nI R vil vi da bare legge til flere variabelnavn i formelen. Ellers er det meste likt som for enkel lineær regresjon.\n\n\nCode\nest_m <- lm(Vold ~ prop_unge_menn + gj_innt_17_34 + gj_innt_35_66 + \n                   prop_shj_mottakere_6mnd , \n            data=kom_2016)\nsummary(est_m)\n\n\n\nCall:\nlm(formula = Vold ~ prop_unge_menn + gj_innt_17_34 + gj_innt_35_66 + \n    prop_shj_mottakere_6mnd, data = kom_2016)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6397 -1.4418 -0.3125  1.2031 16.0036 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              1.004e+00  1.115e+00   0.900    0.368    \nprop_unge_menn           7.088e+01  7.337e+00   9.661  < 2e-16 ***\ngj_innt_17_34           -6.220e-06  3.302e-06  -1.884    0.060 .  \ngj_innt_35_66           -8.343e-06  1.651e-06  -5.053 5.68e-07 ***\nprop_shj_mottakere_6mnd  2.476e+02  2.040e+01  12.134  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.132 on 638 degrees of freedom\nMultiple R-squared:  0.3091,    Adjusted R-squared:  0.3048 \nF-statistic: 71.37 on 4 and 638 DF,  p-value: < 2.2e-16\n\n\nMerk at \\(r^2\\) nå har gått betraktelig opp, til ca 0.31. Gitt at vi tolker dette som i hvor stor grad vi kan predikere utfallet fra datasettet, så er det kanskje likevel ikke imponerende høyt: vi vil fremdeles forvente mye feil prediksjon.\nHer er et scatterplot av observert mot forventet voldsrater:\n\n\nCode\nkom_pred <- kom_2016 %>% \n  mutate(pred = predict(est_m))\n\nggplot(kom_pred, aes(x = Vold, y = pred)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nLa oss inkludere alle aktuelle variable i datasettet. Et lite triks her er å fjerne alle variable vi ikke er interessert i og lagre det i et nytt datasett. I lm() kan vi da presisere formelen som Vold ~ . som betyr å ta med alle variabelene i stedet for å liste hver enkelt variabel.\n\n\nCode\nkom_s <- kom_2016 %>% \n  select(-c(kommune, lovb_ialt, Orden,  \n            Rusmiddellovbrudd, Trafikkovertredelse, \n            lovb_annet, prop_unge_menn))\n\nfull_mod <- lm(Vold ~ . , data = kom_s)\nsummary(full_mod)\n\n\n\nCall:\nlm(formula = Vold ~ ., data = kom_s)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.2272 -1.3129 -0.2606  1.1059 13.8145 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              1.714e+00  3.228e+02   0.005  0.99577    \nyear                    -9.970e-04  1.602e-01  -0.006  0.99504    \nbef_tot                  4.440e-06  2.276e-06   1.951  0.05154 .  \nprop_kvinner_16_18      -7.445e+01  3.803e+01  -1.958  0.05069 .  \nprop_menn_16_18          1.529e+01  3.066e+01   0.499  0.61829    \nprop_menn_19_34          6.935e+01  1.176e+01   5.897 6.03e-09 ***\nprop_kvinner_19_34       2.019e+00  1.278e+01   0.158  0.87447    \nprop_shj_mottakere       1.010e+02  1.463e+01   6.899 1.28e-11 ***\nprop_shj_mottakere_6mnd  5.294e+01  3.102e+01   1.707  0.08837 .  \ngj_innt_17_34           -1.359e-05  4.226e-06  -3.217  0.00136 ** \ngj_innt_35_66           -2.058e-05  8.411e-06  -2.447  0.01468 *  \ngj_innt_alle             2.665e-05  1.224e-05   2.177  0.02987 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.018 on 631 degrees of freedom\nMultiple R-squared:  0.3878,    Adjusted R-squared:  0.3772 \nF-statistic: 36.34 on 11 and 631 DF,  p-value: < 2.2e-16\n\n\n\\(r^2\\) gikk noe opp, til 0.39.\nMen vi kan gjøre modellen ekstra komplisert ved inkludere alle mulige interaksjonsledd. En åpenbar ulempe med dette er at hver enkelt koeffisent blir svært mye vanskeligere å tolke. Vi fokuserer derfor kun på \\(r^2\\) som kan hentes ut uten å ta med resten av output.\n\n\nCode\nfull_mod2 <- lm( Vold ~ .^2, data = kom_s)\nsummary(full_mod2)$r.squared\n\n\n[1] 0.529478\n\n\n\\(r^2\\) gikk vesentlig opp. Men når vi først driver med kompliserte modellspesifikasjoner som uansett er vanskelige å tolke - hvorfor begrense seg til 2-veis interaksjoner? Her er en versjon med alle 3-veis interaksjoner, og nå begynner \\(r^2\\) virkelig å bli høy!\n\n\nCode\nfull_mod3 <- lm( Vold ~ .^3, data = kom_s)\nsummary(full_mod3)$r.squared\n\n\n[1] 0.7215881\n\n\nVi kan trimme modellen så den ikke har med så voldsomt mange parametre. En mulighet er å overlate dette til datamaskinen ved å la den gjøre en trinnvis test av hvorvidt modellene blir signifikant dårligere av å ta vekk noen ledd. Så beholdes den “beste” modellen.\nOBS! Merk at dette er en rent mekanisk seleksjon, og frarådes i de fleste samfunnsvitenskapelige sammenhenger. Tolkning av parametre og statistisk usikkerhet er nå på svært tynn is. Men det kan gi god prediksjon likevel.\n\n\nCode\nstep_mod <- MASS::stepAIC(full_mod3, direction=\"backward\", \n                          trace = FALSE)\nsummary(step_mod)$r.squared\n\n\n[1] 0.7046848\n\n\nHvis vi nå predikerer for hver enkelt kommune og plotter forventet mot observert, så får vi et svært mye bedre sammenfall enn tidligere.\n\n\nCode\nkom_pred <- kom_s %>% \n  mutate(pred = predict(step_mod))\n\nggplot(kom_pred, aes(x = Vold, y = pred)) +\n  geom_point(alpha = .3) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nNå kan vi også regne ut RMSE, som altså er “root mean squared error”. Med andre ord: regn ut residualene (dvs. “error”), og kvadrer denne, og så ta kvadratroten av gjennomsnittet av denne. Her er en kode skrevet litt omstendelig så den er litt lettere å forstå:\n\n\nCode\nkom_s %>% \n  mutate(pred = predict(step_mod), \n         residual = pred - Vold) %>% \n  mutate(sq.resid = residual^2) %>% \n  summarise(sqrt(mean(sq.resid)))\n\n\n  sqrt(mean(sq.resid))\n1              1.38862\n\n\nDette betyr omtrentlig at modellen i gjennomsnitt vil bomme med 1.38 prosentpoeng på voldsraten i kommunen. 3. Hvorvidt det er presist nok eller ikke vil vel strengt tatt komme an på behovet for presisjon, altså: hva man skal bruke det til."
  },
  {
    "objectID": "linear_regresjon.html#oppgaver",
    "href": "linear_regresjon.html#oppgaver",
    "title": "4  Lineær regresjon",
    "section": "4.2 Oppgaver",
    "text": "4.2 Oppgaver\n\nExercise 4.1 Velg et datasettet og formuler hva en prediksjonsmodell kan kunne brukes til. Se for deg at tiltak du foreslår vil altså ha faktiske konsekvenser, så gjør en vurdering av hvorvidt feilprediksjoner vil være problematiske og i så fall på hvilken måte. Vurder mulighetene for feil opp mot gevinst ved riktig prediksjon.\nMerk: det er ikke viktig at anvendelsen skal være realistisk, men du må alltid ta konsekvensen i vurderingene.\n\n\nExercise 4.2 Last inn valgte datasett og splitt i et training og et testing datasett. Sett splitten ved .70. Bruk training-data til å gjøre deg kjent med dataene og estimere modellene. Ikke bruk testing-dataene inntil du får beskjed om det.\n\n\nExercise 4.3 Gjør deg kjent med innholdet i disse training-dataene. Du kan gjøre f.eks. følgende:\n\nBruk glimpse() og skim() til å få oversikt over innholdet i datasettet\nHvis det er noen variable du ikke kommer til å bruke, slett gjerne disse med en gang\nLag noen tabeller og plot som viser hvordan utfallsvariabelen er fordelt etter andre variable\n\n\n\nExercise 4.4 Estimer flere lineær regresjonsmodeller med et fåtall prediktorer. Gjør et utvalg av de variablene du mener er mest relevant for å forklare utfallet. Estimer flere lineære regresjonsmodeller for å predikere utfallet, og sammenlign hvor gode prediksjoner disse gir. Mest relevante statistikker er \\(r^2\\) og RMSE.\n\nVelg ut tre forklaringsvariable og estimer en regresjonsmodell\nEstimer en ny modell med alle variable i datasettet\nEstimer en ny modell og inkluder noen få polynomer og/eller interaksjonsledd\nGjør et automatisk modellsøk\n\nLag gjerne noen plot av ROC-curve for i hvert fall noen av modellene slik at du får en følelse med hva AUC egentlig betyr. Plot også predikert verdi mot observert verdi og gjør en vurdering av RMSE.\n\n\nExercise 4.5 I forrige oppgave brukte du testing-datasettet til både å estimere modellene og vurdere resultatet. Nå skal du bruke testing-datasettet til å vurdere de samme resultatene. Dette gjør du ved å predikere på testing-datasettet og regne ut AUC og RMSE for disse dataene. For hver modell i forrige oppgave, gjør som følger:\n\nPrediker utfallet på testing-datasettet\nRegn ut AUC og RMSE\nHvor stor er endringen i AUC og RMSE fra resultatene når du brukte training-datasettet?\n\nVurdering: En mer komplisert modell beskriver dataene bedre. Men er det like stor endring i AUC og RMSE for enkle og mer kompliserte modeller? Beskriv hva du ser og gi en forklaring."
  },
  {
    "objectID": "cart.html",
    "href": "cart.html",
    "title": "6  Klassifikasjonstrær",
    "section": "",
    "text": "Code\nlibrary(tidyverse) \nlibrary(rpart)      # funksjoner for CART \nlibrary(rpart.plot) # funksjon for å plotte CART \nlibrary(caret)      # inneholder funksjon for confusion matrix \nlibrary(skimr)      # funksjonen skim()\nVi skal her bruke datasettet credit fra Canvas. Dataene er en banks kundehistorikk for kreditt for 1000 kunder. Variabelen default1 er «yes» hvis tilbakebetaling som avtalt og «no» hvis ikke. Dette er utfallsvariabelen. Øvrige variable er rimelig selvforklarende etter variabelnavn. Målet er å lage et system for hvilke nye kunder som skal få innvilget kreditt.\nVi splitter først datasettet i to deler: en til training og en til testing.\nVi starter med å inkludere noen få variable som gir en oversiktlig illustrasjon. Utfallsvariabel og prediktorer spesifiseres som en formel på samme måte som for regresjon. Siden vi her har en klassifikasjon må vi spesifisere method = \"class\". Hvis ikke vil rpart() gjette hva slags modell (som kanskje er riktig), så du kan få andre resultater enn du forventet.\nVi kan også få printet ut disse som tall i en tabell.\nVi kan så skrive ut confusion matrix."
  },
  {
    "objectID": "cart.html#oppgaver",
    "href": "cart.html#oppgaver",
    "title": "6  Klassifikasjonstrær",
    "section": "6.1 Oppgaver",
    "text": "6.1 Oppgaver\n\nExercise 6.1 Gjenta oppgave 1, men basert på dine vurderinger i e) se om du klarer å tune modellen mer i retning av ønsket cost-ratio. Bruk argumentene prior, cp, minbucket og maxdepth.\n\n\nExercise 6.2 Bruk datasettet credit til å predikere kredittverdighet for nye kunder.\n\nSpesifiser en formel med et fåtall variable og lag et klassifikasjonstre.\nPlot med rpart.plot()\nBruk predict() til å klassifisere.\nLag en confusion matrix med table()\nGi en vurdering av resultatet.\n\nSi noe om forholdet mellom resultat for training og testing datasett.\nEr cost-ratio ok fra bankens perspektiv?\nEr cost-ratio ok fra kundens perspektiv?\nAndre hensyn som bør spille inn her?\n\n\n\n\nExercise 6.3 Datafilen credit_kunder.csv inneholder data om to lånesøkere: Ola Normann og Kari Hansen.\nSkal banken gi dem lån? Bruk foretrukne modell fra forrige oppgave.\n\n\nExercise 6.4 Banker bruker slike systemer i dag i større eller mindre grad til automatisere behandling av lånesøknader. (Men de bruker både rikere data og mer avanserte algoritmer). I hvilken grad synes du slike systemer kan/bør helautomatiseres? Bør det være reguleringer på hva slags data som benyttes til slike systemer? Bør kunden få innsyn i algoritmen ved avslag? Gi noen vurderinger av mulige fordeler og ulemper med tanke på hvordan det kan slå ut for enkeltindivider."
  }
]