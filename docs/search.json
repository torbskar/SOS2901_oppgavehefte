[
  {
    "objectID": "introduksjon.html#noen-innledende-metodiske-begrep",
    "href": "introduksjon.html#noen-innledende-metodiske-begrep",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.1 Noen innledende metodiske begrep",
    "text": "1.1 Noen innledende metodiske begrep\nI standard samfunnsvitenskapelige metodekurs lærer man først og fremst teknikker for å beskrive data og statistisk inferens for å beskrive usikkerheten rundt estimatene. Avhengig av studiets øvrige design kan resultatene tolkes kausalt og/eller generalisere til en nærmere veldefinert populasjon (Berk 2016).\nUsikkerhet beskrives typisk ved hjelp standardfeil, p-verdier og konfidensintervall tilhørende spesifikke statistiske tester. Dette innebærer at man bruker statistiske modeller for hvordan resultatene ville sett ut under spesifikke forutsetninger. Samplingfordelinger som normalfordelingen og en del andre tilsvarende fordelinger er derfor sentralt. De fleste teknikkene vi skal bruke i dette kurset er ikke statistiske modeller i samme forstand og det er ingen antakelser om samplingfordelinger. Standardfeil og konfidensintervall kan derfor ikke regnes ut. Usikkerhet og hvem resultatene gjelder for er også relevante for maskinlæring, men ikke helt på samme måte."
  },
  {
    "objectID": "introduksjon.html#forklaringer-og-prediksjoner",
    "href": "introduksjon.html#forklaringer-og-prediksjoner",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.2 Forklaringer og prediksjoner",
    "text": "1.2 Forklaringer og prediksjoner\nVi er i liten grad interessert i regresjonskoeffisienter, \\(\\beta\\), og tolkning av denne. Derimot er vi interessert i det predikerte utfallet \\(\\hat{y}_i\\)."
  },
  {
    "objectID": "introduksjon.html#overfitting-training-og-testing-dataset",
    "href": "introduksjon.html#overfitting-training-og-testing-dataset",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.3 Overfitting: training og testing dataset",
    "text": "1.3 Overfitting: training og testing dataset\nNår man tilpasser en statistisk modell eller algoritme til data så er det lett å tenke at modellen bør gjenspeile dataene så godt som mulig. Samtidig sies det ofte at modellene skal være så enkle som tilrådelig. En mer komplisert modell vil jo være i stand til å tilpasses dataene i større grad, så hvordan avveie dette?\nSpørsmålet nå er ikke hvor godt modellen passer til disse dataene, men hvordan den passer til nye data! Altså fremtidige data eller fremtidig situasjon. La oss si at vi har et datasett som kan plottes om følger:\n\n\nCode\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nn <- 10\nbeta <- 1\nset.seed(42)\nx <- round(20 + runif(n)*50, digits = 1)\ny <- 1 + beta*x + rnorm(n)*10\n\ndf <- data.frame(x = x, y = y) %>% \n  mutate(d = case_when(x < 50 ~ 0,\n                       x < 56 ~ 1, \n                       TRUE ~2) %>% as_factor())\n\n\ng1 <- ggplot(df, aes(x = x, y = y)) +\n  geom_point() \ng1\n\n\n\n\n\nVi kunne her tilpasse en enkel lineær regresjonsmodell eller en mer komplisert modell. Resultatet vises i grafen nedenfor.\n\n\nCode\nest1 <- lm(y ~ x + x*d, data = df)\nest2 <- lm(y ~ x, data = df)\n\ndf_p1 <- df %>% \n  mutate(pred = predict(est1))  %>% \n  mutate(res_pred = y - pred, \n         res_y = y - mean(y))\n\ndf_p1 %>% \n  summarise(res_pred = sum(res_pred^2), \n            res_y = sum(res_y^2)) %>% \n  mutate(1 - res_pred/res_y)\n\n\n  res_pred    res_y 1 - res_pred/res_y\n1 190.8017 4411.586          0.9567499\n\n\nCode\nggplot(df, aes(x = x, y = y)) +\n  geom_point(col = \"black\") +\n  geom_line(data = df_p1, aes(y = pred), col = \"red\", linewidth = .7) +\n  stat_smooth(method='lm', formula = y ~ x, se = F, col = \"blue\", linewidth = .7)\n\n\n\n\n\nDen kompliserte modellen gir \\(r^2\\) = 0.9567499 mens den enkle lineære gir \\(r^2\\) = 0.8066771.\n\n\nCode\nsummary(est1)$r.squared\n\n\n[1] 0.9567499\n\n\nCode\nsummary(est2)$r.squared\n\n\n[1] 0.8066771\n\n\n\n\nCode\nx <- round(20 + runif(n)*50, digits = 1)\ny <- 1 + beta*x + rnorm(n)*10\ndf2 <- data.frame(x = x, y = y)\n  \ng1 +\n  geom_point(data = df2, col = \"blue\") +\n  geom_smooth(method = lm, se = F, col = \"red\")\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "introduksjon.html#klassifikasjonsusikkerhet---grunnleggende-begreper",
    "href": "introduksjon.html#klassifikasjonsusikkerhet---grunnleggende-begreper",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.4 Klassifikasjonsusikkerhet - grunnleggende begreper",
    "text": "1.4 Klassifikasjonsusikkerhet - grunnleggende begreper\nI praksis kommer vi til å fokusere mest på klassifikasjon, som altså er når det vi predikerer er en kategorisk variabel. For nye personer vil vi da gjerne predikere hvilken kategori vedkommende tilhører. En variant av dette er å predikere en fremtidig handling (slutte i jobb, ikke betale tilbake lån, begå ny kriminalitet etc).\n\n1.4.1 Confusion matrix: riktig og feil klassifisering\nNår vi predikerer et kategorisk utfall er det gjerne ett av utfallene vi primært er interessert i. Disse kalles positive og de andre er negative. Dette har ingenting å gjøre med om utfallet er bra eller dårlig å gjøre. Å predikere en sykdom vil være positivt og å være frisk vil være negativt. Å ha tilbakefall til kriminalitet vil være positivt og lovlydig vil være negativt.\nEn positiv prediksjon kan da være korrekt eller feil, og disse kalles da henholdsvis sanne eller falske positive. Tilsvarende kan en negaitv prediksjon være sann eller falsk.\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredikert\n\n\n\n\n\n\n\nNegativ\nPositiv\n\n\nObservert\nNegativ\nSanne negative (TN)\nFalske positive (FN)\n\n\n\nPositiv\nFalske negative (FN)\nSanne positive (TP)\n\n\n\n\n\n1.4.2 Asymetriske kostnader\nÅ predikere feil kan betraktes som en kostnad. Hvis vi skal bruke prediksjonenen til noe i praksis, så skal det jo få konsekvenser på en eller annen måte. Det kan innebære at man setter i verk tiltak som er unødvendige - eller ikke setter i verk tiltak der man burde gjort det.\nEt sentralt spørsmål er derfor om begge typer feil er like viktig eller alvorlig. Noen ganger er det det, men det bør man ta stilling til helt konkret i det enkelte tilfellet. Det er ikke åpenbart hvem som har kompetanse til å vurdere dette. Det kan kreves inngående fagkunnskap for å gjøre en riktig vurdering, eller det kan være politiske prioriteringer, økonomiske forhold, rettferdighetsvurderinger osv. Det er i hvert fall ikke bare opp til forskeren eller IT-personalet å vurdere.\nDette kan koke ned til helt konkret vurdering av hvor mange falske positive er du villig til å godta per falske negative. Et konkret eksempel er studien til Berk et al (2016) av menn som er arrestert for vold i nære relasjoner. Problemstillingen er hvem skal i arrest frem til saken kommer opp og hvem skal løslates mot kausjon. Prediksjonen er da hvem som vil begå ny voldshandling mot partner. Forholdet mellom TN og FN oversettes konkret til hvor mange mistenkte skal sitte unødig i fengsel (dvs. falske positive) mot hvor mange partnere skal unødig utsettes for ny voldshendelse (dvs. falske negative)? I nevnte studie har noen “stakeholders” landet på at falske negative er vesentlig mer alvorlig enn falske positive. Prediksjonsmodellen utformes så for å reflektere akkurat det."
  },
  {
    "objectID": "introduksjon.html#rettferdighet-og-rimelighet",
    "href": "introduksjon.html#rettferdighet-og-rimelighet",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.5 Rettferdighet og rimelighet",
    "text": "1.5 Rettferdighet og rimelighet\nI diskusjoner av anvendelser av maskinlæring står rettferdighet helt sentralt. Men det er ikke alltid like klart hva dette egentlig betyr utover at det er forskjellsbehandling. Tross alt er hele formålet med prediksjon å nettopp forskjellsbehandle, eller målrette som det også kan kalles. Rettferdighet kommer inn på flere nivåer, fra det helt prinsippielle ved å la data og datamaskiner ha betydning for avgjørelser til det helt konkrete til hvordan feilratene bør se ut. Vurdering av asymetriske kostnader er åpenbart også et rettferdighetsspørsmål med etiske implikasjoner. En variant er at disse feilratene kan se forskjellige ut på tvers av undergrupper.\nHvilke konsekvenser som er akseptable er viktig. Men det er også viktig før man bygger modellen. Software kommer med default innstillinger, men det betyr jo ikke at de er “nøytrale”. Resultatene kan til en viss grad styres, så det må man rett og slett gjøre.\n\n1.5.1 Fundamentale skjevheter i data\nSiden maskinlæring baserer seg på å lære av tilgjengelige data for å benytte det på nye tilfeller spiller det vesentlig rolle hvordan de opprinnelige dataene ble generert i utgangspunktet.\nEt velkjent eksempel er hvordan Amazon besluttet å slutte å bruke en algoritme for rekruttering fordi den systematisk valgte bort kvinner. Grunnen til at algoritmen gjorde dette var så enkelt som at dataene den var trent opp på var mannsdominert. Algoritmen hadde altså primært tilgang til informasjon om hvilke egenskaper som kjennetegnet talentfulle mannlige kandidater, som altså kan være forskjellige fra talentfulle kvinnelige kandidater.\nNår man skal ta en algoritme i bruk er det derfor helt avgjørende at man kan forsvare bruken av de dataene algoritmen er trent på. Kjente skjevheter kan i prinsippet motarbeides ved tuning (dette kommer vi tilbake til), men det er vanskelig å garantere at det er skjevheter man ikke har tenkt på."
  },
  {
    "objectID": "introduksjon.html#oppgaver",
    "href": "introduksjon.html#oppgaver",
    "title": "1  Introduksjon til maskinlæring",
    "section": "1.6 Oppgaver",
    "text": "1.6 Oppgaver\n\nExercise 1.1 Kan man tenke seg målrettede tiltak som ikke innebærer en form for prediksjon om fremtiden? (Implisitt eller eksplisitt)\n\n\nExercise 1.2 Hvor alvorlig er det å gjøre feil? Hva avgjør om feil prediksjon spiller noen rolle?\n\n\n\n\n\n\n\nBerk, Richard. 2016. Statistical Learning from a Regression Perspective. USA: Springer."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Berk, Richard. 2016. Statistical Learning from a Regression\nPerspective. USA: Springer.\n\n\nHsieh, John. 2008. “Receiver Operating Characteristic (ROC)\nCurve.” In Encyclopedia of Epidemiology, 895–98.\nThousand Oaks, California: Sage. https://doi.org/10.4135/9781412953948."
  },
  {
    "objectID": "datasets.html#credit",
    "href": "datasets.html#credit",
    "title": "Appendix A — Datasett",
    "section": "A.1 Credit",
    "text": "A.1 Credit\nUtfallsvariabel: “default” (misligholdelse av lån) Data er hentet fra datacamp.com\nDataene inneholder følgende variable:\n\n\nCode\ncredit <- read.csv(\"data/credit.csv\")\n\nglimpse(credit)\n\n\nRows: 1,000\nColumns: 17\n$ checking_balance     <chr> \"< 0 DM\", \"1 - 200 DM\", \"unknown\", \"< 0 DM\", \"< 0…\n$ months_loan_duration <int> 6, 48, 12, 42, 24, 36, 24, 36, 12, 30, 12, 48, 12…\n$ credit_history       <chr> \"critical\", \"good\", \"critical\", \"good\", \"poor\", \"…\n$ purpose              <chr> \"furniture/appliances\", \"furniture/appliances\", \"…\n$ amount               <int> 1169, 5951, 2096, 7882, 4870, 9055, 2835, 6948, 3…\n$ savings_balance      <chr> \"unknown\", \"< 100 DM\", \"< 100 DM\", \"< 100 DM\", \"<…\n$ employment_duration  <chr> \"> 7 years\", \"1 - 4 years\", \"4 - 7 years\", \"4 - 7…\n$ percent_of_income    <int> 4, 2, 2, 2, 3, 2, 3, 2, 2, 4, 3, 3, 1, 4, 2, 4, 4…\n$ years_at_residence   <int> 4, 2, 3, 4, 4, 4, 4, 2, 4, 2, 1, 4, 1, 4, 4, 2, 4…\n$ age                  <int> 67, 22, 49, 45, 53, 35, 53, 35, 61, 28, 25, 24, 2…\n$ other_credit         <chr> \"none\", \"none\", \"none\", \"none\", \"none\", \"none\", \"…\n$ housing              <chr> \"own\", \"own\", \"own\", \"other\", \"other\", \"other\", \"…\n$ existing_loans_count <int> 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2…\n$ job                  <chr> \"skilled\", \"skilled\", \"unskilled\", \"skilled\", \"sk…\n$ dependents           <int> 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ phone                <chr> \"yes\", \"no\", \"no\", \"no\", \"no\", \"yes\", \"no\", \"yes\"…\n$ default              <chr> \"no\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\",…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#attrition",
    "href": "datasets.html#attrition",
    "title": "Appendix A — Datasett",
    "section": "A.2 Attrition",
    "text": "A.2 Attrition\nUtfallsvariabel: “Attrition”, dvs om en arbeidstaker slutter i jobben.\nDatasettet er tilgjengelig fra Kaggle.\n\n\nCode\nattrition <- readRDS(\"data/attrition.rds\")\nglimpse(attrition)\n\n\nRows: 1,470\nColumns: 32\n$ Age                      <int> 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35, 2…\n$ Attrition                <fct> Yes, No, Yes, No, No, No, No, No, No, No, No,…\n$ BusinessTravel           <fct> Travel_Rarely, Travel_Frequently, Travel_Rare…\n$ DailyRate                <int> 1102, 279, 1373, 1392, 591, 1005, 1324, 1358,…\n$ Department               <fct> Sales, Research & Development, Research & Dev…\n$ DistanceFromHome         <int> 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26, …\n$ Education                <int> 2, 1, 2, 4, 1, 2, 3, 1, 3, 3, 3, 2, 1, 2, 3, …\n$ EducationField           <fct> Life Sciences, Life Sciences, Other, Life Sci…\n$ EmployeeNumber           <int> 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16,…\n$ EnvironmentSatisfaction  <int> 2, 3, 4, 4, 1, 4, 3, 4, 4, 3, 1, 4, 1, 2, 3, …\n$ Gender                   <fct> Female, Male, Male, Female, Male, Male, Femal…\n$ HourlyRate               <int> 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84, 4…\n$ JobInvolvement           <int> 3, 2, 2, 3, 3, 3, 4, 3, 2, 3, 4, 2, 3, 3, 2, …\n$ JobLevel                 <int> 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, …\n$ JobRole                  <fct> Sales Executive, Research Scientist, Laborato…\n$ JobSatisfaction          <int> 4, 2, 3, 3, 2, 4, 1, 3, 3, 3, 2, 3, 3, 4, 3, …\n$ MaritalStatus            <fct> Single, Married, Single, Married, Married, Si…\n$ MonthlyIncome            <int> 5993, 5130, 2090, 2909, 3468, 3068, 2670, 269…\n$ MonthlyRate              <int> 19479, 24907, 2396, 23159, 16632, 11864, 9964…\n$ NumCompaniesWorked       <int> 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5, …\n$ OverTime                 <fct> Yes, No, Yes, Yes, No, No, Yes, No, No, No, N…\n$ PercentSalaryHike        <int> 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13, 1…\n$ PerformanceRating        <int> 3, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, …\n$ RelationshipSatisfaction <int> 1, 4, 2, 3, 4, 3, 1, 2, 2, 2, 3, 4, 4, 3, 2, …\n$ StockOptionLevel         <int> 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, 0, …\n$ TotalWorkingYears        <int> 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5, 3…\n$ TrainingTimesLastYear    <int> 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, 4, …\n$ WorkLifeBalance          <int> 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, …\n$ YearsAtCompany           <int> 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, 4,…\n$ YearsInCurrentRole       <int> 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, 2, …\n$ YearsSinceLastPromotion  <int> 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0, …\n$ YearsWithCurrManager     <int> 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, 3, …\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#kommunedata",
    "href": "datasets.html#kommunedata",
    "title": "Appendix A — Datasett",
    "section": "A.3 Kommunedata",
    "text": "A.3 Kommunedata\nDisse dataene er hentet fra SSBs offisielle statistikk og koblet sammen på kommunenummer. Fra statistikkbanken tabeller nr. 06944 (inntekt), 12210 (sosialhjelp/KOSTRA), 07459 (befolkning), 08487 (anmeldte lovbrudd). Flere variable kan kobles på. Merk: det er flere endringer i kommunestruktur, særlig i 2020. Kommunene er altså ikke helt det samme over tid.\nAktuelle utfallsvariable: Flere variable kan være aktuell som utfallsvariable. Prediktorer må nok omarbeides noe etter egne vurderinger (f.eks. omregne til per 1000 eller prosent, summere totaltall etc).\n\n\nCode\nkommune <- readRDS(\"data/kommunedata.rds\")\nglimpse(kommune)\n\n\nRows: 1,529\nColumns: 28\n$ kommune_nr             <chr> \"0101\", \"0101\", \"0101\", \"0101\", \"0104\", \"0104\",…\n$ kommune                <chr> \"Halden (-2019)\", \"Halden (-2019)\", \"Halden (-2…\n$ year                   <dbl> 2015, 2016, 2017, 2018, 2015, 2016, 2017, 2018,…\n$ bef_18min              <int> 3556, 3503, 3505, 3544, 3594, 3652, 3704, 3655,…\n$ bef_18_25              <int> 3575, 3585, 3432, 3438, 3405, 3404, 3355, 3370,…\n$ bef_26_35              <int> 3728, 3804, 3985, 4035, 4057, 4071, 4124, 4110,…\n$ bef_totalt             <int> 30328, 30544, 30790, 31037, 31802, 32182, 32407…\n$ menn_18_25             <int> 1847, 1865, 1813, 1819, 1789, 1802, 1789, 1810,…\n$ menn_26_35             <int> 1880, 1919, 2005, 2062, 2063, 2083, 2113, 2134,…\n$ menn_36_67             <int> 7067, 7051, 7085, 7057, 7418, 7453, 7408, 7407,…\n$ menn_67plus            <int> 2496, 2624, 2697, 2806, 2671, 2777, 2856, 2895,…\n$ menn_18min             <int> 1880, 1847, 1873, 1876, 1842, 1885, 1919, 1878,…\n$ kvinner_18_25          <int> 1728, 1720, 1619, 1619, 1616, 1602, 1566, 1560,…\n$ kvinner_26_35          <int> 1848, 1885, 1980, 1973, 1994, 1988, 2011, 1976,…\n$ kvinner_36_67          <int> 6880, 6832, 6844, 6848, 7479, 7519, 7537, 7596,…\n$ kvinner_67plus         <int> 3026, 3145, 3242, 3309, 3178, 3306, 3423, 3555,…\n$ kvinner_18min          <int> 1676, 1656, 1632, 1668, 1752, 1767, 1785, 1777,…\n$ inntekt_totalt_median  <int> 555000, 562000, 580000, 591000, 561000, 568000,…\n$ inntekt_eskatt_median  <int> 451000, 453000, 470000, 480000, 449000, 456000,…\n$ ant_husholdninger      <int> 13890, 14124, 14281, 14454, 15046, 15132, 15313…\n$ shj_klienter           <int> 1183, 1137, 1099, 1128, 1155, 1129, 1152, 1137,…\n$ shj_unge               <int> 262, 247, 248, 242, 267, 263, 238, 222, 307, 28…\n$ vinningskriminalitet   <dbl> 19.7, 18.7, 16.5, 14.5, 24.5, 21.5, 18.0, 18.0,…\n$ voldskriminalitet      <dbl> 11.2, 12.6, 12.3, 11.2, 7.8, 8.3, 8.7, 9.7, 6.8…\n$ nark_alko_kriminalitet <dbl> 21.0, 21.9, 21.0, 20.3, 12.0, 10.2, 10.9, 10.1,…\n$ ordenslovbrudd         <dbl> 18.5, 16.5, 14.9, 13.7, 8.9, 9.0, 9.1, 9.2, 8.2…\n$ trafikklovbrudd        <dbl> 15.5, 16.3, 16.7, 19.2, 7.4, 6.3, 6.9, 8.0, 9.6…\n$ andre_lovbrudd         <dbl> 25.5, 26.5, 26.1, 25.2, 12.1, 12.2, 11.9, 12.4,…\n\n\n\n\n\n\n Download data as rds"
  },
  {
    "objectID": "datasets.html#churn",
    "href": "datasets.html#churn",
    "title": "Appendix A — Datasett",
    "section": "A.4 Churn",
    "text": "A.4 Churn\n\n\nCode\nchurn <- read.csv(\"data/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\nglimpse(churn)\n\n\nRows: 7,043\nColumns: 21\n$ customerID       <chr> \"7590-VHVEG\", \"5575-GNVDE\", \"3668-QPYBK\", \"7795-CFOCW…\n$ gender           <chr> \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Female\",…\n$ SeniorCitizen    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Partner          <chr> \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes…\n$ Dependents       <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\"…\n$ tenure           <int> 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 58, 49, 2…\n$ PhoneService     <chr> \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ MultipleLines    <chr> \"No phone service\", \"No\", \"No\", \"No phone service\", \"…\n$ InternetService  <chr> \"DSL\", \"DSL\", \"DSL\", \"DSL\", \"Fiber optic\", \"Fiber opt…\n$ OnlineSecurity   <chr> \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"…\n$ OnlineBackup     <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"N…\n$ DeviceProtection <chr> \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Y…\n$ TechSupport      <chr> \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Yes…\n$ StreamingTV      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Ye…\n$ StreamingMovies  <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"Yes…\n$ Contract         <chr> \"Month-to-month\", \"One year\", \"Month-to-month\", \"One …\n$ PaperlessBilling <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ PaymentMethod    <chr> \"Electronic check\", \"Mailed check\", \"Mailed check\", \"…\n$ MonthlyCharges   <dbl> 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89.10, 29.7…\n$ TotalCharges     <dbl> 29.85, 1889.50, 108.15, 1840.75, 151.65, 820.50, 1949…\n$ Churn            <chr> \"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Y…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#recidivism-from-iowa-prisons",
    "href": "datasets.html#recidivism-from-iowa-prisons",
    "title": "Appendix A — Datasett",
    "section": "A.5 Recidivism from Iowa prisons",
    "text": "A.5 Recidivism from Iowa prisons\nDatasettet inneholder data på 26020 personer løslatt fra fengsel i staten Iowa, USA mellom 2010 og 2015. For hver person er det informasjon om hvorvidt de har blitt fengslet på nytt innen 3 år (dvs. fulgt til mellom 2013 og 2018).\nAktuell utfallsvariabel: “Recidivism…Return.to.Prison.numeric” Endre gjerne variabelnavn til noe kortere.\nDatasettet er tilgjengelig fra Kaggle og er nærmere omtalt der.\n\n\nCode\nrecidivism <- read.csv(\"data/3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated.csv\", stringsAsFactors = TRUE)\n\nglimpse(recidivism)\n\n\nRows: 26,020\nColumns: 12\n$ Fiscal.Year.Released                      <int> 2010, 2010, 2010, 2010, 2010…\n$ Recidivism.Reporting.Year                 <int> 2013, 2013, 2013, 2013, 2013…\n$ Race...Ethnicity                          <fct> White - Non-Hispanic, White …\n$ Age.At.Release                            <fct> Under 25, 55 and Older, 25-3…\n$ Convicting.Offense.Classification         <fct> D Felony, D Felony, D Felony…\n$ Convicting.Offense.Type                   <fct> Violent, Public Order, Prope…\n$ Convicting.Offense.Subtype                <fct> Assault, OWI, Burglary, Traf…\n$ Main.Supervising.District                 <fct> 4JD, 7JD, 5JD, 8JD, 3JD, , 3…\n$ Release.Type                              <fct> Parole, Parole, Parole, Paro…\n$ Release.type..Paroled.to.Detainder.united <fct> Parole, Parole, Parole, Paro…\n$ Part.of.Target.Population                 <fct> Yes, Yes, Yes, Yes, Yes, No,…\n$ Recidivism...Return.to.Prison.numeric     <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#compas",
    "href": "datasets.html#compas",
    "title": "Appendix A — Datasett",
    "section": "A.6 Compas",
    "text": "A.6 Compas\nUtfallsvariabel: “Two_yr_Revidvism”\nData er hentet fra R-pakken fairmodels, modifisert datsett fra ProPublica\n\n\nCode\ncompas <- readRDS(\"data/compas.rds\")\nglimpse(compas)\n\n\nRows: 6,172\nColumns: 7\n$ Two_yr_Recidivism    <fct> 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1…\n$ Number_of_Priors     <int> 0, 0, 4, 0, 14, 3, 0, 0, 3, 0, 0, 1, 7, 0, 3, 6, …\n$ Age_Above_FourtyFive <fct> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Age_Below_TwentyFive <fct> 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Misdemeanor          <fct> 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Ethnicity            <fct> Other, African_American, African_American, Other,…\n$ Sex                  <fct> Male, Male, Male, Male, Male, Male, Female, Male,…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#diabetes-rehospitalization",
    "href": "datasets.html#diabetes-rehospitalization",
    "title": "Appendix A — Datasett",
    "section": "A.7 Diabetes rehospitalization",
    "text": "A.7 Diabetes rehospitalization\nData er beskrevet nærmere i Strack et al (2014) (se særlig tabell 1) og er tilgjengelig fra UCI machine learning repository\nUtfallsvariabelen av interesse er readmitted, altså om pasienten blir lagt inn på nytt på et eller annet tidspunkt etter utskrivning.\n\n\nCode\ndiabetic <- read.csv(\"data/diabetic_data.csv\")\nglimpse(diabetic)\n\n\nRows: 101,766\nColumns: 50\n$ encounter_id             <int> 2278392, 149190, 64410, 500364, 16680, 35754,…\n$ patient_nbr              <int> 8222157, 55629189, 86047875, 82442376, 425192…\n$ race                     <chr> \"Caucasian\", \"Caucasian\", \"AfricanAmerican\", …\n$ gender                   <chr> \"Female\", \"Female\", \"Female\", \"Male\", \"Male\",…\n$ age                      <chr> \"[0-10)\", \"[10-20)\", \"[20-30)\", \"[30-40)\", \"[…\n$ weight                   <chr> \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", …\n$ admission_type_id        <int> 6, 1, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 1, 3, …\n$ discharge_disposition_id <int> 25, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 6, 1,…\n$ admission_source_id      <int> 1, 7, 7, 7, 7, 2, 2, 7, 4, 4, 7, 4, 7, 7, 2, …\n$ time_in_hospital         <int> 1, 3, 2, 2, 1, 3, 4, 5, 13, 12, 9, 7, 7, 10, …\n$ payer_code               <chr> \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", \"?\", …\n$ medical_specialty        <chr> \"Pediatrics-Endocrinology\", \"?\", \"?\", \"?\", \"?…\n$ num_lab_procedures       <int> 41, 59, 11, 44, 51, 31, 70, 73, 68, 33, 47, 6…\n$ num_procedures           <int> 0, 0, 5, 1, 0, 6, 1, 0, 2, 3, 2, 0, 0, 1, 5, …\n$ num_medications          <int> 1, 18, 13, 16, 8, 16, 21, 12, 28, 18, 17, 11,…\n$ number_outpatient        <int> 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ number_emergency         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ number_inpatient         <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ diag_1                   <chr> \"250.83\", \"276\", \"648\", \"8\", \"197\", \"414\", \"4…\n$ diag_2                   <chr> \"?\", \"250.01\", \"250\", \"250.43\", \"157\", \"411\",…\n$ diag_3                   <chr> \"?\", \"255\", \"V27\", \"403\", \"250\", \"250\", \"V45\"…\n$ number_diagnoses         <int> 1, 9, 6, 7, 5, 9, 7, 8, 8, 8, 9, 7, 8, 8, 8, …\n$ max_glu_serum            <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None…\n$ A1Cresult                <chr> \"None\", \"None\", \"None\", \"None\", \"None\", \"None…\n$ metformin                <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Steady\",…\n$ repaglinide              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ nateglinide              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ chlorpropamide           <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ glimepiride              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Steady\",…\n$ acetohexamide            <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ glipizide                <chr> \"No\", \"No\", \"Steady\", \"No\", \"Steady\", \"No\", \"…\n$ glyburide                <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"St…\n$ tolbutamide              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ pioglitazone             <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ rosiglitazone            <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ acarbose                 <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ miglitol                 <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ troglitazone             <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ tolazamide               <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ examide                  <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ citoglipton              <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ insulin                  <chr> \"No\", \"Up\", \"No\", \"Up\", \"Steady\", \"Steady\", \"…\n$ glyburide.metformin      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ glipizide.metformin      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ glimepiride.pioglitazone <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ metformin.rosiglitazone  <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ metformin.pioglitazone   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ change                   <chr> \"No\", \"Ch\", \"No\", \"Ch\", \"Ch\", \"No\", \"Ch\", \"No…\n$ diabetesMed              <chr> \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes…\n$ readmitted               <chr> \"NO\", \">30\", \"NO\", \"NO\", \"NO\", \">30\", \"NO\", \"…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#absenteeism",
    "href": "datasets.html#absenteeism",
    "title": "Appendix A — Datasett",
    "section": "A.8 Absenteeism",
    "text": "A.8 Absenteeism\nDette er et syntetisk datasett som inneholder 8336 personer i en tenkt bedrift og hvor mange timer hver person har fravær fra jobben.\nData er tilgjengelig fra Kaggle\n\n\nCode\nabsenteeism <- read.csv(\"data/MFGEmployees4.csv\")\nglimpse(absenteeism)\n\n\nRows: 8,336\nColumns: 13\n$ EmployeeNumber <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ Surname        <chr> \"Gutierrez\", \"Hardwick\", \"Delgado\", \"Simon\", \"Delvalle\"…\n$ GivenName      <chr> \"Molly\", \"Stephen\", \"Chester\", \"Irene\", \"Edward\", \"Erni…\n$ Gender         <chr> \"F\", \"M\", \"M\", \"F\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", …\n$ City           <chr> \"Burnaby\", \"Courtenay\", \"Richmond\", \"Victoria\", \"New We…\n$ JobTitle       <chr> \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"Baker\", \"…\n$ DepartmentName <chr> \"Bakery\", \"Bakery\", \"Bakery\", \"Bakery\", \"Bakery\", \"Bake…\n$ StoreLocation  <chr> \"Burnaby\", \"Nanaimo\", \"Richmond\", \"Victoria\", \"New West…\n$ Division       <chr> \"Stores\", \"Stores\", \"Stores\", \"Stores\", \"Stores\", \"Stor…\n$ Age            <dbl> 32.02882, 40.32090, 48.82205, 44.59936, 35.69788, 48.44…\n$ LengthService  <dbl> 6.018478, 5.532445, 4.389973, 3.081736, 3.619091, 2.717…\n$ AbsentHours    <dbl> 36.57731, 30.16507, 83.80780, 70.02017, 0.00000, 81.830…\n$ BusinessUnit   <chr> \"Stores\", \"Stores\", \"Stores\", \"Stores\", \"Stores\", \"Stor…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#human-resources-hr",
    "href": "datasets.html#human-resources-hr",
    "title": "Appendix A — Datasett",
    "section": "A.9 Human resources (HR)",
    "text": "A.9 Human resources (HR)\nData er tilgjengelig fra Kaggle og variable er beskrevet nærmere på denne lenken.\n\n\nCode\nhr <- read.csv(\"data/HRDataset_v14.csv\")\nglimpse(hr)\n\n\nRows: 311\nColumns: 36\n$ Employee_Name              <chr> \"Adinolfi, Wilson  K\", \"Ait Sidi, Karthikey…\n$ EmpID                      <int> 10026, 10084, 10196, 10088, 10069, 10002, 1…\n$ MarriedID                  <int> 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0…\n$ MaritalStatusID            <int> 0, 1, 1, 1, 2, 0, 0, 4, 0, 2, 1, 1, 2, 0, 2…\n$ GenderID                   <int> 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1…\n$ EmpStatusID                <int> 1, 5, 5, 1, 5, 1, 1, 1, 3, 1, 5, 5, 1, 1, 5…\n$ DeptID                     <int> 5, 3, 5, 5, 5, 5, 4, 5, 5, 3, 5, 5, 3, 5, 5…\n$ PerfScoreID                <int> 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3…\n$ FromDiversityJobFairID     <int> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0…\n$ Salary                     <int> 62506, 104437, 64955, 64991, 50825, 57568, …\n$ Termd                      <int> 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1…\n$ PositionID                 <int> 19, 27, 20, 19, 19, 19, 24, 19, 19, 14, 19,…\n$ Position                   <chr> \"Production Technician I\", \"Sr. DBA\", \"Prod…\n$ State                      <chr> \"MA\", \"MA\", \"MA\", \"MA\", \"MA\", \"MA\", \"MA\", \"…\n$ Zip                        <int> 1960, 2148, 1810, 1886, 2169, 1844, 2110, 2…\n$ DOB                        <chr> \"07/10/83\", \"05/05/75\", \"09/19/88\", \"09/27/…\n$ Sex                        <chr> \"M \", \"M \", \"F\", \"F\", \"F\", \"F\", \"F\", \"M \", …\n$ MaritalDesc                <chr> \"Single\", \"Married\", \"Married\", \"Married\", …\n$ CitizenDesc                <chr> \"US Citizen\", \"US Citizen\", \"US Citizen\", \"…\n$ HispanicLatino             <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"…\n$ RaceDesc                   <chr> \"White\", \"White\", \"White\", \"White\", \"White\"…\n$ DateofHire                 <chr> \"7/5/2011\", \"3/30/2015\", \"7/5/2011\", \"1/7/2…\n$ DateofTermination          <chr> \"\", \"6/16/2016\", \"9/24/2012\", \"\", \"9/6/2016…\n$ TermReason                 <chr> \"N/A-StillEmployed\", \"career change\", \"hour…\n$ EmploymentStatus           <chr> \"Active\", \"Voluntarily Terminated\", \"Volunt…\n$ Department                 <chr> \"Production       \", \"IT/IS\", \"Production  …\n$ ManagerName                <chr> \"Michael Albert\", \"Simon Roup\", \"Kissy Sull…\n$ ManagerID                  <int> 22, 4, 20, 16, 39, 11, 10, 19, 12, 7, 14, 2…\n$ RecruitmentSource          <chr> \"LinkedIn\", \"Indeed\", \"LinkedIn\", \"Indeed\",…\n$ PerformanceScore           <chr> \"Exceeds\", \"Fully Meets\", \"Fully Meets\", \"F…\n$ EngagementSurvey           <dbl> 4.60, 4.96, 3.02, 4.84, 5.00, 5.00, 3.04, 5…\n$ EmpSatisfaction            <int> 5, 3, 3, 5, 4, 5, 3, 4, 3, 5, 4, 3, 4, 4, 5…\n$ SpecialProjectsCount       <int> 0, 6, 0, 0, 0, 0, 4, 0, 0, 6, 0, 0, 5, 0, 0…\n$ LastPerformanceReview_Date <chr> \"1/17/2019\", \"2/24/2016\", \"5/15/2012\", \"1/3…\n$ DaysLateLast30             <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Absences                   <int> 1, 17, 3, 15, 2, 15, 19, 19, 4, 16, 12, 15,…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#nettverk",
    "href": "datasets.html#nettverk",
    "title": "Appendix A — Datasett",
    "section": "A.10 Nettverk",
    "text": "A.10 Nettverk\n\n\nCode\nload(\"data/networkExample.RData\")\nglimpse(dataset)\n\n\nRows: 926\nColumns: 26\n$ degree               <dbl> 0.006282723, 0.002094241, 0.002094241, 0.00104712…\n$ betweenness          <dbl> 0.0081438885, 0.0020810695, 0.0014569424, 0.00000…\n$ closeness            <dbl> 0.08535931, 0.08049562, 0.08226376, 0.07795282, 0…\n$ transitivity         <dbl> 0.13333333, 0.00000000, 0.00000000, 0.00000000, 0…\n$ triangles            <dbl> 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0…\n$ ChurnNeighbors       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ NonChurnNeighbors    <dbl> 6, 2, 2, 1, 3, 5, 2, 2, 2, 6, 2, 3, 6, 2, 3, 2, 2…\n$ Neighbors            <dbl> 6, 2, 2, 1, 3, 5, 2, 2, 3, 6, 2, 3, 6, 2, 3, 2, 2…\n$ RelationalNeighbor   <dbl> 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.000…\n$ ChurnNeighbors2      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ NonChurnNeighbors2   <dbl> 18, 4, 8, 4, 5, 19, 6, 8, 11, 15, 7, 6, 27, 4, 6,…\n$ RelationalNeighbor2  <dbl> 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0…\n$ degree2              <dbl> 0.026178010, 0.006282723, 0.010471204, 0.00523560…\n$ averageDegree        <dbl> 0.004363002, 0.003141361, 0.005235602, 0.00523560…\n$ averageDegree2       <dbl> 0.004188482, 0.004973822, 0.004581152, 0.00549738…\n$ averageTransitivity  <dbl> 0.13888889, 0.05000000, 0.03333333, 0.10000000, 0…\n$ averageTransitivity2 <dbl> 0.11415344, 0.10833333, 0.22777778, 0.18511905, 0…\n$ averageBetweenness   <dbl> 0.005713676, 0.004259980, 0.008147263, 0.00623771…\n$ averageBetweenness2  <dbl> 0.006733850, 0.008557955, 0.007690396, 0.00625752…\n$ averageTriangles     <dbl> 0.8333333, 0.5000000, 0.5000000, 1.0000000, 0.000…\n$ averageTriangles2    <dbl> 0.7777778, 1.2500000, 0.7500000, 1.7500000, 0.400…\n$ pr_0.85              <dbl> 0.0016432968, 0.0008315249, 0.0006479747, 0.00040…\n$ pr_0.20              <dbl> 0.0011679051, 0.0010706518, 0.0009325680, 0.00088…\n$ perspr_0.85          <dbl> 0.0016432968, 0.0008315249, 0.0006479747, 0.00040…\n$ perspr_0.99          <dbl> 0.0017826047, 0.0006187399, 0.0006012571, 0.00030…\n$ Future               <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "datasets.html#occupational-wage-data",
    "href": "datasets.html#occupational-wage-data",
    "title": "Appendix A — Datasett",
    "section": "A.11 Occupational wage data",
    "text": "A.11 Occupational wage data\n\n\nCode\noes <- readRDS(\"data/oes.rds\")\nclass(oes)\n\n\n[1] \"matrix\" \"array\" \n\n\nCode\nglimpse(oes)\n\n\n num [1:22, 1:15] 70800 50580 60350 56330 49710 ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : chr [1:22] \"Management\" \"Business Operations\" \"Computer Science\" \"Architecture/Engineering\" ...\n  ..$ : chr [1:15] \"2001\" \"2002\" \"2003\" \"2004\" ...\n\n\n\n\n\n\n Download data as rds"
  },
  {
    "objectID": "datasets.html#voters",
    "href": "datasets.html#voters",
    "title": "Appendix A — Datasett",
    "section": "A.12 Voters",
    "text": "A.12 Voters\nData er hentet fra 2016 Views of the Electorate Research Survey gjennomført av Voter study group.\nAktuell problemstilling er å predikere hvilke velgere som støtter Clinton. En slik klassifisering kan brukes til f.eks. å målrette budskap. En relatert problemstilling er å klustre velgerne for å finne segmenter\n\n\nCode\nvoters <- read.csv(\"data/voters.csv\")\nglimpse(voters)\n\n\nRows: 6,426\nColumns: 42\n$ RIGGED_SYSTEM_1_2016 <int> 3, 2, 2, 1, 3, 3, 3, 2, 4, 2, 3, 3, 4, 4, 3, 3, 2…\n$ RIGGED_SYSTEM_2_2016 <int> 4, 1, 4, 4, 1, 3, 4, 3, 4, 3, 2, 2, 3, 2, 4, 3, 2…\n$ RIGGED_SYSTEM_3_2016 <int> 1, 3, 1, 1, 3, 2, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 3…\n$ RIGGED_SYSTEM_4_2016 <int> 4, 1, 4, 4, 1, 2, 1, 2, 3, 2, 4, 1, 3, 4, 2, 2, 1…\n$ RIGGED_SYSTEM_5_2016 <int> 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 3, 3, 2, 3, 2…\n$ RIGGED_SYSTEM_6_2016 <int> 2, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2…\n$ track_2016           <int> 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 3, 2, 2, 2…\n$ persfinretro_2016    <int> 2, 3, 3, 1, 2, 2, 2, 3, 2, 1, 2, 3, 2, 2, 2, 2, 2…\n$ econtrend_2016       <int> 1, 3, 3, 1, 2, 2, 1, 3, 1, 1, 1, 3, 2, 1, 4, 3, 2…\n$ Americatrend_2016    <int> 1, 1, 1, 3, 3, 1, 2, 3, 2, 1, 3, 3, 2, 1, 1, 3, 1…\n$ futuretrend_2016     <int> 4, 1, 1, 3, 4, 3, 1, 3, 1, 1, 3, 1, 1, 4, 3, 4, 3…\n$ wealth_2016          <int> 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1…\n$ values_culture_2016  <int> 2, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 2, 1, 1, 3, 8, 3…\n$ US_respect_2016      <int> 2, 3, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3…\n$ trustgovt_2016       <int> 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3…\n$ trust_people_2016    <int> 8, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 8, 8, 2, 2…\n$ helpful_people_2016  <int> 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 8, 1, 1…\n$ fair_people_2016     <int> 8, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 8, 2, 1…\n$ imiss_a_2016         <int> 2, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 2, 2, 2…\n$ imiss_b_2016         <int> 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1…\n$ imiss_c_2016         <int> 1, 2, 2, 3, 1, 2, 2, 1, 4, 2, 3, 1, 2, 2, 3, 1, 1…\n$ imiss_d_2016         <int> 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 3…\n$ imiss_e_2016         <int> 1, 1, 3, 1, 1, 3, 1, 2, 1, 1, 2, 2, 4, 1, 4, 2, 1…\n$ imiss_f_2016         <int> 2, 1, 1, 2, 1, 2, 1, 3, 2, 1, 1, 1, 2, 1, 3, 2, 2…\n$ imiss_g_2016         <int> 1, 4, 3, 3, 3, 1, 3, 4, 2, 2, 1, 4, 1, 2, 1, 1, 4…\n$ imiss_h_2016         <int> 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3…\n$ imiss_i_2016         <int> 2, 2, 4, 4, 2, 1, 1, 3, 2, 1, 1, 2, 1, 2, 2, 2, 3…\n$ imiss_j_2016         <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2…\n$ imiss_k_2016         <int> 1, 2, 1, 1, 2, 1, 1, 4, 2, 1, 1, 3, 1, 1, 1, 1, 1…\n$ imiss_l_2016         <int> 1, 4, 1, 2, 4, 1, 1, 3, 1, 1, 1, 4, 2, 1, 1, 1, 3…\n$ imiss_m_2016         <int> 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1…\n$ imiss_n_2016         <int> 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1…\n$ imiss_o_2016         <int> 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1…\n$ imiss_p_2016         <int> 2, 1, 2, 3, 1, 3, 1, 1, 4, 1, 1, 1, 2, 3, 2, 3, 1…\n$ imiss_q_2016         <int> 1, 1, 1, 2, 2, 1, 1, 4, 2, 1, 1, 3, 1, 1, 2, 2, 3…\n$ imiss_r_2016         <int> 2, 1, 1, 2, 1, 2, 1, 2, 4, 2, 2, 1, 3, 2, 2, 2, 1…\n$ imiss_s_2016         <int> 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3…\n$ imiss_t_2016         <int> 1, 1, 3, 3, 1, 1, 3, 4, 1, 1, 1, 3, 1, 3, 1, 1, 3…\n$ imiss_u_2016         <int> 2, 2, 2, 2, 1, 3, 3, 1, 4, 2, 3, 2, 4, 3, 3, 3, 1…\n$ imiss_x_2016         <int> 1, 3, 1, 2, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 2, 3…\n$ imiss_y_2016         <int> 1, 4, 2, 3, 1, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 2, 2…\n$ Clinton_supp         <chr> \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\", \"No…\n\n\n\n\n\n\n Download data as csv"
  },
  {
    "objectID": "introduksjon_R.html#rstudio-projects",
    "href": "introduksjon_R.html#rstudio-projects",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.1 Rstudio projects",
    "text": "B.1 Rstudio projects\nDet anbefales sterkt å lage en mappestruktur egnet for Rstudio projects. Lag en egen mappe for dette kurset og lag følgende undermapper:\n\nData\nScript\nOutput\nDokumenter\n\nDu kan også lage andre undermapper hvis du vil. Det vil være begrenset behov for å eksportere output, men det er selvsagt mulig. Lag"
  },
  {
    "objectID": "introduksjon_R.html#lese-inn-data",
    "href": "introduksjon_R.html#lese-inn-data",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.2 Lese inn data",
    "text": "B.2 Lese inn data\nDataene er i csv eller rds formater. Disse later du ned og lagrer i mappen for data og leser inn derfra.\ncsv-filer kan leses inn med funksjonen ‘read.csv()’ og rds-filer med ‘readRDS()’."
  },
  {
    "objectID": "introduksjon_R.html#dataframes-og-variabeltyper",
    "href": "introduksjon_R.html#dataframes-og-variabeltyper",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.3 dataframes og variabeltyper",
    "text": "B.3 dataframes og variabeltyper\nVær obs på at når man leser inn csv-filer så vil R gjette på hva slags variabeltyper det er. De vil i hovedsak være numeriske, tekst eller factor. I all hovedsak bør tekstvariable tolkes som factor. Dette kan du få til ved å spesifiser det når dataene leses inn slik:\n\n\nCode\nread.csv(\"data/navnpaadata.csv\", stringsAsFactors = TRUE)"
  },
  {
    "objectID": "introduksjon_R.html#dele-et-datasett-i-training-og-testing",
    "href": "introduksjon_R.html#dele-et-datasett-i-training-og-testing",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.4 Dele et datasett i ‘training’ og ‘testing’?",
    "text": "B.4 Dele et datasett i ‘training’ og ‘testing’?\nVi bruker pakken ‘rsample’ til å splitte datasettet. Funksjonen ‘initial_split()’ markerer hvilke observasjoner som er i hvilken del. Så kan du trekke ut disse etterpå med ‘training()’ og ‘testing()’"
  },
  {
    "objectID": "introduksjon_R.html#seed-med-set.seed",
    "href": "introduksjon_R.html#seed-med-set.seed",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.5 Seed med ‘set.seed()’",
    "text": "B.5 Seed med ‘set.seed()’\nEn tilfeldig inndeling som med ‘initial_split()’ bruker tilfeldige tall som genereres av R. Det finnes ikke helt tilfeldige tall i en datamaskin, det bare ser sånn ut. Det er en slags algoritme som generer disse tallen, og det har et startpunkt som varierer med når du setter den igang. Med andre ord: en tilfeldig inndeling vil bli forskjellig hver eneste gang.\nFunksjonen ‘set.seed()’ definerer startpunktet for neste sekvens av tilfeldige tall slik at du kan reprodusere nøyaktig samme resultat. Hvis dere jobber sammen på oppgaver er det en fordel å sette samme seed slik at dere kan sammenligne resultatet.\n\nset.seed(42)\n\nDette gjelder for alle funksjoner der det benyttes tilfeldige tall. Det gjelder altså for random forest.\nOBS! Vend deg til å alltid bruke set.seed når du jobber i dette kurset, for du kommer til å trenge det på eksamen! Du kan gjøre ting riktig på eksamen likevel, men da blir ikke resultatene reproduserbare og sensor kan ikke sjekke resultatene. (Dere skal få nøyaktige instruksjoner senere)."
  },
  {
    "objectID": "introduksjon_R.html#predict",
    "href": "introduksjon_R.html#predict",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.6 ‘Predict()’",
    "text": "B.6 ‘Predict()’\nDere skal bruke funksjonen ‘predict()’ ganske mye. Den tar et objekt fra en eller annen modell og predikerer fra denne. Merk at den bruker det objektet dere har lagret resultatene i, ser hva slags modell det er, og predikerer i henhold til det.\nI utgangspunktet bruker den det samme datasettet som modellen ble estimert med. Men kan også predikere på nye data. Da må argumentet ‘newdata = …’ angis. Det vil typisk være testing-datasettet eller helt nye observasjoner der du ikke vet utfallet. Det nye datasettet må alle de variablene som vari det opprinnelige datasettet for at det skal funke."
  },
  {
    "objectID": "introduksjon_R.html#databehandling-dplyr-verb-tidyverse",
    "href": "introduksjon_R.html#databehandling-dplyr-verb-tidyverse",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.7 Databehandling: dplyr-verb / tidyverse",
    "text": "B.7 Databehandling: dplyr-verb / tidyverse\n\nB.7.1 Hva gjør en ‘pipe-operatoren’ %>% ??\n\n\nB.7.2 lage/endre variable: mutate\n\n\nB.7.3 filtrere datasett: filter\n\n\nB.7.4 summmere data: summarise"
  },
  {
    "objectID": "introduksjon_R.html#grafikk-quickn-dirty-vs-ggplot",
    "href": "introduksjon_R.html#grafikk-quickn-dirty-vs-ggplot",
    "title": "Appendix B — Introduksjon til R",
    "section": "B.8 Grafikk: quick’n dirty vs ggplot",
    "text": "B.8 Grafikk: quick’n dirty vs ggplot"
  },
  {
    "objectID": "logistisk_regresjon.html#empirisk-eksempel",
    "href": "logistisk_regresjon.html#empirisk-eksempel",
    "title": "3  Logistisk regresjon",
    "section": "3.1 Empirisk eksempel",
    "text": "3.1 Empirisk eksempel\nSom eksempel bruker vi et datasettet Attrition. Dette er et datasett over arbeidstakere i en bedrift der utfallsvariabelen er om arbeidstakeren slutter i jobben eller ikke.\nFor arbeidsgivere kan det være kostbart med endringer i staben. Arbeidstakere som slutter tar med seg erfaring og kompetanse, og nye arbeidstakere må læres opp. Arbeidsgiver bør derfor generelt legge til rette for at arbeidstakere ønsker å bli værende, men det kan også være aktuelt med mer målrettede tiltak. Når en arbeidstaker har fått et nytt jobbtilbud kan det være for sent. Hvis man derimot kan komme i forkjøpet kan man kanskje gjøre noe før vedkommende går til det skrittet å søke ny jobb. Hvis man kunne predikere hvem som kommer til å slutte kunne man altså gjort tiltak i forkant.1\nFørst leser vi inn datasettet og evt. laster pakker i trenger. Dataene er i csv-format så vi leser inn med read.csv(). Deretter kan vi se på innholdet med skim():\n\n\nCode\nattrition <-read.csv(\"data/Attrition.csv\", stringsAsFactors = TRUE)  \nskim(attrition)  \n\n\n\nData summary\n\n\nName\nattrition\n\n\nNumber of rows\n1470\n\n\nNumber of columns\n36\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n9\n\n\nnumeric\n27\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nAttrition\n0\n1\nFALSE\n2\nNo: 1233, Yes: 237\n\n\nBusinessTravel\n0\n1\nFALSE\n3\nTra: 1043, Tra: 277, Non: 150\n\n\nDepartment\n0\n1\nFALSE\n3\nRes: 961, Sal: 446, Hum: 63\n\n\nEducationField\n0\n1\nFALSE\n6\nLif: 606, Med: 464, Mar: 159, Tec: 132\n\n\nGender\n0\n1\nFALSE\n2\nMal: 882, Fem: 588\n\n\nJobRole\n0\n1\nFALSE\n9\nSal: 326, Res: 292, Lab: 259, Man: 145\n\n\nMaritalStatus\n0\n1\nFALSE\n3\nMar: 673, Sin: 470, Div: 327\n\n\nOver18\n0\n1\nFALSE\n1\nY: 1470\n\n\nOverTime\n0\n1\nFALSE\n2\nNo: 1054, Yes: 416\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nX\n0\n1\n735.50\n424.50\n1\n368.25\n735.5\n1102.75\n1470\n▇▇▇▇▇\n\n\nAge\n0\n1\n36.92\n9.14\n18\n30.00\n36.0\n43.00\n60\n▂▇▇▃▂\n\n\nDailyRate\n0\n1\n802.49\n403.51\n102\n465.00\n802.0\n1157.00\n1499\n▇▇▇▇▇\n\n\nDistanceFromHome\n0\n1\n9.19\n8.11\n1\n2.00\n7.0\n14.00\n29\n▇▅▂▂▂\n\n\nEducation\n0\n1\n2.91\n1.02\n1\n2.00\n3.0\n4.00\n5\n▂▃▇▆▁\n\n\nEmployeeCount\n0\n1\n1.00\n0.00\n1\n1.00\n1.0\n1.00\n1\n▁▁▇▁▁\n\n\nEmployeeNumber\n0\n1\n1024.87\n602.02\n1\n491.25\n1020.5\n1555.75\n2068\n▇▇▇▇▇\n\n\nEnvironmentSatisfaction\n0\n1\n2.72\n1.09\n1\n2.00\n3.0\n4.00\n4\n▅▅▁▇▇\n\n\nHourlyRate\n0\n1\n65.89\n20.33\n30\n48.00\n66.0\n83.75\n100\n▇▇▇▇▇\n\n\nJobInvolvement\n0\n1\n2.73\n0.71\n1\n2.00\n3.0\n3.00\n4\n▁▃▁▇▁\n\n\nJobLevel\n0\n1\n2.06\n1.11\n1\n1.00\n2.0\n3.00\n5\n▇▇▃▂▁\n\n\nJobSatisfaction\n0\n1\n2.73\n1.10\n1\n2.00\n3.0\n4.00\n4\n▅▅▁▇▇\n\n\nMonthlyIncome\n0\n1\n6502.93\n4707.96\n1009\n2911.00\n4919.0\n8379.00\n19999\n▇▅▂▁▂\n\n\nMonthlyRate\n0\n1\n14313.10\n7117.79\n2094\n8047.00\n14235.5\n20461.50\n26999\n▇▇▇▇▇\n\n\nNumCompaniesWorked\n0\n1\n2.69\n2.50\n0\n1.00\n2.0\n4.00\n9\n▇▃▂▂▁\n\n\nPercentSalaryHike\n0\n1\n15.21\n3.66\n11\n12.00\n14.0\n18.00\n25\n▇▅▃▂▁\n\n\nPerformanceRating\n0\n1\n3.15\n0.36\n3\n3.00\n3.0\n3.00\n4\n▇▁▁▁▂\n\n\nRelationshipSatisfaction\n0\n1\n2.71\n1.08\n1\n2.00\n3.0\n4.00\n4\n▅▅▁▇▇\n\n\nStandardHours\n0\n1\n80.00\n0.00\n80\n80.00\n80.0\n80.00\n80\n▁▁▇▁▁\n\n\nStockOptionLevel\n0\n1\n0.79\n0.85\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▂▁\n\n\nTotalWorkingYears\n0\n1\n11.28\n7.78\n0\n6.00\n10.0\n15.00\n40\n▇▇▂▁▁\n\n\nTrainingTimesLastYear\n0\n1\n2.80\n1.29\n0\n2.00\n3.0\n3.00\n6\n▂▇▇▂▃\n\n\nWorkLifeBalance\n0\n1\n2.76\n0.71\n1\n2.00\n3.0\n3.00\n4\n▁▃▁▇▂\n\n\nYearsAtCompany\n0\n1\n7.01\n6.13\n0\n3.00\n5.0\n9.00\n40\n▇▂▁▁▁\n\n\nYearsInCurrentRole\n0\n1\n4.23\n3.62\n0\n2.00\n3.0\n7.00\n18\n▇▃▂▁▁\n\n\nYearsSinceLastPromotion\n0\n1\n2.19\n3.22\n0\n0.00\n1.0\n3.00\n15\n▇▁▁▁▁\n\n\nYearsWithCurrManager\n0\n1\n4.12\n3.57\n0\n2.00\n3.0\n7.00\n17\n▇▂▅▁▁\n\n\n\n\n\nMerk at det er fire variable vi ikke trenger, så vi sletter disse like gjerne med en gang:\n\nOver18 er en dummy for om de er over 18 år. Det er alle.\nEmployeeCount og StandardHours varierer heller ikke.\n\nBruker select() med minustegn for variable vi vil fjerne. Her overskrives datasettet med det modifiserte datasettet\n\n\nCode\nattrition <- attrition %>%  \n  select(- Over18, - EmployeeCount, -StandardHours) \nglimpse(attrition)\n\n\nRows: 1,470\nColumns: 33\n$ X                        <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14…\n$ Age                      <int> 41, 49, 37, 33, 27, 32, 59, 30, 38, 36, 35, 2…\n$ Attrition                <fct> Yes, No, Yes, No, No, No, No, No, No, No, No,…\n$ BusinessTravel           <fct> Travel_Rarely, Travel_Frequently, Travel_Rare…\n$ DailyRate                <int> 1102, 279, 1373, 1392, 591, 1005, 1324, 1358,…\n$ Department               <fct> Sales, Research & Development, Research & Dev…\n$ DistanceFromHome         <int> 1, 8, 2, 3, 2, 2, 3, 24, 23, 27, 16, 15, 26, …\n$ Education                <int> 2, 1, 2, 4, 1, 2, 3, 1, 3, 3, 3, 2, 1, 2, 3, …\n$ EducationField           <fct> Life Sciences, Life Sciences, Other, Life Sci…\n$ EmployeeNumber           <int> 1, 2, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16,…\n$ EnvironmentSatisfaction  <int> 2, 3, 4, 4, 1, 4, 3, 4, 4, 3, 1, 4, 1, 2, 3, …\n$ Gender                   <fct> Female, Male, Male, Female, Male, Male, Femal…\n$ HourlyRate               <int> 94, 61, 92, 56, 40, 79, 81, 67, 44, 94, 84, 4…\n$ JobInvolvement           <int> 3, 2, 2, 3, 3, 3, 4, 3, 2, 3, 4, 2, 3, 3, 2, …\n$ JobLevel                 <int> 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, …\n$ JobRole                  <fct> Sales Executive, Research Scientist, Laborato…\n$ JobSatisfaction          <int> 4, 2, 3, 3, 2, 4, 1, 3, 3, 3, 2, 3, 3, 4, 3, …\n$ MaritalStatus            <fct> Single, Married, Single, Married, Married, Si…\n$ MonthlyIncome            <int> 5993, 5130, 2090, 2909, 3468, 3068, 2670, 269…\n$ MonthlyRate              <int> 19479, 24907, 2396, 23159, 16632, 11864, 9964…\n$ NumCompaniesWorked       <int> 8, 1, 6, 1, 9, 0, 4, 1, 0, 6, 0, 0, 1, 0, 5, …\n$ OverTime                 <fct> Yes, No, Yes, Yes, No, No, Yes, No, No, No, N…\n$ PercentSalaryHike        <int> 11, 23, 15, 11, 12, 13, 20, 22, 21, 13, 13, 1…\n$ PerformanceRating        <int> 3, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, …\n$ RelationshipSatisfaction <int> 1, 4, 2, 3, 4, 3, 1, 2, 2, 2, 3, 4, 4, 3, 2, …\n$ StockOptionLevel         <int> 0, 1, 0, 0, 1, 0, 3, 1, 0, 2, 1, 0, 1, 1, 0, …\n$ TotalWorkingYears        <int> 8, 10, 7, 8, 6, 8, 12, 1, 10, 17, 6, 10, 5, 3…\n$ TrainingTimesLastYear    <int> 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 5, 3, 1, 2, 4, …\n$ WorkLifeBalance          <int> 1, 3, 3, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 3, 3, …\n$ YearsAtCompany           <int> 6, 10, 0, 8, 2, 7, 1, 1, 9, 7, 5, 9, 5, 2, 4,…\n$ YearsInCurrentRole       <int> 4, 7, 0, 7, 2, 7, 0, 0, 7, 7, 4, 5, 2, 2, 2, …\n$ YearsSinceLastPromotion  <int> 0, 1, 0, 3, 2, 3, 0, 0, 1, 7, 0, 0, 4, 1, 0, …\n$ YearsWithCurrManager     <int> 5, 7, 0, 0, 2, 6, 0, 0, 8, 7, 3, 8, 3, 2, 3, …\n\n\nDel datasettet i to deler. Vi trekker tilfeldig 70% og legger dette i datasettet training. Resten legges i testing. De nye datasettene behøver jo ikke hete akkurat dette. Kall det hva du vil.\n\n\nCode\nset.seed(426)\nattrition_split <- initial_split(attrition)\n\ntraining <- training(attrition_split) \ntesting  <- testing(attrition_split) \n\n\nSjekk at antallet i hvert datasett summeres til totalen\n\n\nCode\nnrow(attrition) \n\n\n[1] 1470\n\n\nCode\nnrow(training) \n\n\n[1] 1102\n\n\nCode\nnrow(testing) \n\n\n[1] 368\n\n\nOBS! variabelen Attrition er en “factor”, dvs. kategorisk med underliggende nummer. Ta en titt.\n\n\nCode\nstr(training$Attrition)   \n\n\n Factor w/ 2 levels \"No\",\"Yes\": 1 2 1 2 1 1 1 2 1 1 ...\n\n\nCode\nhead(training$Attrition) \n\n\n[1] No  Yes No  Yes No  No \nLevels: No Yes\n\n\nCode\nlevels(training$Attrition) \n\n\n[1] \"No\"  \"Yes\"\n\n\nI en regresjon vil lm() og glm() håndtere en factor automatisk som dummy. Men det funker ikke nødvendigvis like greit for plotting etc. Gjør om factor til dummy-variabel. Inni parentesen er et logisk uttrykk som får TRUE/FALSE, men med å eksplisitt be om at variabelen skal være numerisk blir det 1/0 Vi overskriver variablen slik:\n\n\nCode\ntraining$Attrition <- as.numeric(training$Attrition == \"Yes\") \nhead(training$Attrition) \n\n\n[1] 0 1 0 1 0 0\n\n\nAndelen kan vi få med mean():\n\n\nCode\nmean(training$Attrition) \n\n\n[1] 0.1533575\n\n\nVi kan vise hvordan det å slutte i jobben varierer med f.eks. alder ved å beregne andel per verdi av alder.\n\n\nCode\ntraining_p <- training %>% \n  group_by(Age) %>% \n  summarise(Attrition = mean(Attrition == 1)) \nggplot(training_p, aes(x=Age, y=Attrition))+ \n  geom_point()"
  },
  {
    "objectID": "logistisk_regresjon.html#estimere-en-sannsynlighet",
    "href": "logistisk_regresjon.html#estimere-en-sannsynlighet",
    "title": "3  Logistisk regresjon",
    "section": "3.2 Estimere en sannsynlighet",
    "text": "3.2 Estimere en sannsynlighet\nNår utfallsvariabelen er binær (to verdier) kan man likevel bruke lineær regresjon. Det kalles da gjerne en lineær sannsynlighetsmodell.\n\n\nCode\nlm_est <- lm(Attrition ~ Age , data = training)\nsummary(lm_est)\n\n\n\nCall:\nlm(formula = Attrition ~ Age, data = training)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.28444 -0.18737 -0.14576 -0.06256  0.99292 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.409254   0.044335   9.231  < 2e-16 ***\nAge         -0.006934   0.001166  -5.948 3.65e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.355 on 1100 degrees of freedom\nMultiple R-squared:  0.03116,   Adjusted R-squared:  0.03027 \nF-statistic: 35.37 on 1 and 1100 DF,  p-value: 3.652e-09\n\n\nDette betyr at vi har estimert følgende regresjonsligning:\n\n\n\\[\n\\operatorname{\\widehat{Attrition}} = 0.409 - 0.007(\\operatorname{Age})\n\\]\n\n\nVi kan da predikere for ulike aldre ved å første lage et nytt datasett med kun alder som variabel og de verdiene som finnes i datasettet, og så bruke ‘predict()’ på dette datasettet etterpå. Da kan vi også se resultatet for ulike aldre. Her er et eksempel:\n\n\nCode\nn_data <- data.frame(Age = seq(18, 65))\nn_data$pred <- predict(lm_est, newdata = n_data)\n\n\nggplot(training_p, aes(x=Age, y=Attrition))+ \n  geom_point()+ \n  geom_line(data =n_data, aes(x = Age, y = pred))\n\n\n\n\n\nMerk at det her er vist predikerte sannsynligheter litt utenfor omfanget av de opprinnelige dataene, dvs. opp til 65 år i stedet for bare til 60. Da får vi en negativ sannsynlighet. Dette er kanskje ikke så problematisk hvis man er nøye på å ikke tolke resultatene utenfor training-data. Men det kan jo hente nye data vil ha slike verdier. Det blir mer komplisert hvis det er mange prediktorer og kompliserte modeller. En ting er om de predikerte sannsynlighetene blir lavere enn 0 eller høyere enn 1, men vi vil uansett forvente at stigningstallet vil avta når det nærmer seg disse grenseverdiene.\nDen viktigste ulempen med lineære sannsynlighetsmodeller er altså at modellen da kan predikere sannsynligheter lavere enn 0 og høyere enn 1. Når man er mest interessert i \\(\\beta\\) er det ikke sikkert det er så nøye. Men når vi er interessert i \\(\\hat{y}\\) kan det derimot være viktig."
  },
  {
    "objectID": "logistisk_regresjon.html#logistisk-regresjon-i-r",
    "href": "logistisk_regresjon.html#logistisk-regresjon-i-r",
    "title": "3  Logistisk regresjon",
    "section": "3.3 Logistisk regresjon i R",
    "text": "3.3 Logistisk regresjon i R\nLogistisk regresjon har det til felles med lineær regresjon at utfallet er en lineær spesifikasjon.\n\\[  log( \\frac{\\pi}{(1-\\pi)}) = \\alpha + \\beta X \\]\nVenstresiden av ligningen kalles en logit, der \\(\\pi\\) er en sannsynlighet. Uttrykket \\(\\frac{\\pi}{(1-\\pi)}\\) er en odds, som er et forholdstall mellom sannsynligheten for at utfallet skjer mot sannsynligheten for det motsatte. Tolkningen av \\(\\beta\\) er da en endring av odds på logaritisk skala. Hvis man eksponensierer \\(\\beta\\) er den da tolkbar som en oddsrate.\nSom du nå sikkert skjønner så er altså tolkningen av regresjonskoeffisientene nokså krøkete å tolke substansielt for de fleste av oss. Det kan i seg selv være et argument mot å bruke logistisk regresjon i en del sammenhenger.\nMen man kan regne om til sannsynligheter som er vesentlig enklere å forstå. Særlig hvis man ikke er så interessert i tolkningen av \\(\\beta\\), men prediksjon av \\(\\pi\\).\nLigningen kan da skrives om slik at venstresiden av ligningen blir en sannsynlighet direkte:\n\\[  \\pi = \\frac{e^{\\alpha + \\beta X}}{1 + e^{\\alpha + \\beta X}} \\]\nEn enkel omregning av regresjonsresultatet gir altså en sannynlighet. Denne sannsynligheten kan vi da bruke til klassifikasjon hvis det er formålet med analysen. Hvis utfallsvariabelen har to kategorier, så er en nærliggende mulighet å klassifisere til den gruppen hver person mest sannsynlig tilhører. Altså: de som har \\(\\pi = P(y = 1) > 0.5\\) tilhører den ene gruppen og resten i den andre gruppen.\nLogistisk regresjon kan dessuten håndtere utfall med flere enn to kategorier, noe OLS ikke kan. Vi bruker derfor logistisk regresjon når det er kategoriske utfall. I andre sammenhenger vil folk hevde at OLS er bedre å bruke (av diverse grunner), men i denne sammenhengen er logistisk regresjon som hovedregel å foretrekke over OLS for kategoriske utfall.\nHer er et eksempel på hvordan estimere enkel logistisk regresjon i R:\n\n\nCode\nest_logit <- glm(Attrition ~ Age, data = training, family = \"binomial\")\nsummary(est_logit)\n\n\n\nCall:\nglm(formula = Attrition ~ Age, family = \"binomial\", data = training)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9093  -0.6310  -0.5343  -0.3790   2.4998  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.41516    0.36402   1.140    0.254    \nAge         -0.06026    0.01050  -5.741 9.43e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 944.39  on 1101  degrees of freedom\nResidual deviance: 907.48  on 1100  degrees of freedom\nAIC: 911.48\n\nNumber of Fisher Scoring iterations: 5\n\n\nEn penere output kan gis med ‘gtsummary’ på samme måte som for OLS slik:\n\n\nCode\ntbl_regression(est_logit)\n\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      log(OR)1\n      95% CI1\n      p-value\n    \n  \n  \n    Age\n-0.06\n-0.08, -0.04\n<0.001\n  \n  \n  \n    \n      1 OR = Odds Ratio, CI = Confidence Interval\n    \n  \n\n\n\n\n\n\n\\[\n\\log\\left[ \\frac { \\widehat{P( \\operatorname{Attrition} = \\operatorname{1} )} }{ 1 - \\widehat{P( \\operatorname{Attrition} = \\operatorname{1} )} } \\right] = 0.415 - 0.06(\\operatorname{Age})\n\\]\n\n\nHvordan plotte slike data? Bruk geom_jitter eller geom_point. Å legge til en regresjonslinje har brukte vi geom_smooth(). Med stat_smoot() kan vi spesifisere andre typer regresjonsmodeller, herunder logistisk regresjon.\n\n\nCode\nggplot(training, aes(x=Age, y=Attrition))+ \n  geom_point(alpha=.3)+ \n  stat_smooth(method=\"glm\", method.args=list(family=\"binomial\"), se=FALSE, col=\"red\") \n\n\n\n\n\nDu synes sikkert dette plottet ser litt rart ut. Bytt ut geom_point() med følgende: geom_jitter(height = .02, alpha=.3) så skal du få omtrent følgende resultat:\n\n\nCode\nggplot(training, aes(x=Age, y=Attrition))+ \n  geom_jitter(height = .02, alpha=.3)+ \n  stat_smooth(method=\"glm\", method.args=list(family=\"binomial\"), se=FALSE, col=\"red\") \n\n\n\n\n\nDet ser muligens fremdels rart ut, men litt tydeligere, kanskje.\nHer er en variant der andelen som slutter i jobben er regnet ut for hvert alderstrinn. Da er utfallsvariabelen en andel som er litt enklere å tolke når det plottes, og regresjonslinjen er den samme.\n\n\nCode\ntraining_p <- training %>% \n  group_by(Age) %>% \n  summarise(Attrition = mean(Attrition == 1)) \nggplot(training_p, aes(x=Age, y=Attrition))+ \n  geom_point()+ \n  stat_smooth(method=\"glm\", method.args=list(family=\"binomial\"), se=FALSE, col=\"red\")"
  },
  {
    "objectID": "logistisk_regresjon.html#oppgaver",
    "href": "logistisk_regresjon.html#oppgaver",
    "title": "3  Logistisk regresjon",
    "section": "3.9 Oppgaver",
    "text": "3.9 Oppgaver\nDisse oppgavene vil være ganske tilsvarende som for oppgavene med lineær regresjon. Men du skal nå bruke logistisk regresjon med tilhørende teknikker og vurderinger.\n\nExercise 3.1 Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer.\n\n\nExercise 3.2 Velg et datasettet og formuler hva en prediksjonsmodell kan kunne brukes til. Se for deg at tiltak du foreslår vil altså ha faktiske konsekvenser, så gjør en vurdering av hvorvidt feilprediksjoner vil være problematiske og i så fall på hvilken måte. Vurder mulighetene for feil opp mot gevinst ved riktig prediksjon.\nMerk: det er ikke viktig at anvendelsen skal være realistisk, men du må alltid ta konsekvensen i vurderingene.\n\n\nExercise 3.3 Last inn valgte datasett og splitt i et training og et testing datasett. Sett splitten ved .70. Bruk training-data til å gjøre deg kjent med dataene og estimere modellene. Ikke bruk testing-dataene inntil du får beskjed om det.\n\n\nExercise 3.4 Gjør deg kjent med innholdet i disse training-dataene. Du kan gjøre f.eks. følgende:\n\nBruk glimpse() og skim() til å få oversikt over innholdet i datasettet\nHvis det er noen variable du ikke kommer til å bruke, slett gjerne disse med en gang\nLag noen tabeller og plot som viser hvordan utfallsvariabelen er fordelt etter andre variable\n\n\n\nExercise 3.5 Estimer flere logistiske regresjonsmodeller med et fåtall prediktorer. Gjør et utvalg av de variablene du mener er mest relevant for å forklare utfallet. Estimer flere regresjonsmodeller for å predikere utfallet, og sammenlign hvor gode prediksjoner disse gir. Mest relevante statistikk er AUC og ROC-curve.\n\nVelg ut tre forklaringsvariable og estimer en regresjonsmodell\nEstimer en ny modell med alle variable i datasettet\nEstimer en ny modell og inkluder noen få polynomer og/eller interaksjonsledd\nGjør et automatisk modellsøk\n\nLag gjerne noen plot av ROC-curve for i hvert fall noen av modellene slik at du får en følelse med hva AUC egentlig betyr. Plot også predikert verdi mot observert verdi og gjør en vurdering av RMSE.\n\n\nExercise 3.6 I forrige oppgave brukte du training-datasettet til både å estimere modellene og vurdere resultatet. Nå skal du bruke testing-datasettet til å vurdere de samme resultatene. Dette gjør du ved å predikere på testing-datasettet og regne ut AUC for disse dataene. For hver modell i forrige oppgave, gjør som følger:\n\nPrediker utfallet på testing-datasettet\nRegn ut AUC\nHvor stor er endringen i AUC er fra resultatene når du brukte training-datasettet?\n\nVurdering: En mer komplisert modell beskriver dataene bedre. Men er det like stor endring i AUC og RMSE for enkle og mer kompliserte modeller? Beskriv hva du ser og gi en forklaring.\n\n\nExercise 3.7 Når over har predikert en sannsynlighet og regnet ut AUC har du ennå ikke tatt noen avgjørelse. Bestem deg for et grenseverdi for når du vil klassifisere som det ene eller andre. (Alså: ved hvilken sannsynlighet). Gjør så en klassifikasjon og lag en confusion matrix. Gi en vurdering av resultatet.\n\n\n\n\n\n\n\nHsieh, John. 2008. “Receiver Operating Characteristic (ROC) Curve.” In Encyclopedia of Epidemiology, 895–98. Thousand Oaks, California: Sage. https://doi.org/10.4135/9781412953948."
  },
  {
    "objectID": "logistisk_regresjon.html#prediksjon",
    "href": "logistisk_regresjon.html#prediksjon",
    "title": "3  Logistisk regresjon",
    "section": "3.4 Prediksjon",
    "text": "3.4 Prediksjon\nVi kan predikere med bruk av ‘predict()’ som tidligere. Nå er det imidlertid viktig å presisere hva vi ønsker å predikere: \\(log( \\frac{\\pi}{(1-\\pi)})\\) eller \\(\\pi\\). Vi ønsker det siste fordi det er direkte tolkbart. Vi må da skrive ‘type = “response”’ som følger.\n\n\nCode\nattrition_pred <- training %>% \n  mutate(prob = predict(est_logit, type = \"response\"))\n\n\n\n3.4.1 ROC og AUC\n\n\nCode\nROC <- roc( attrition_pred$Attrition, attrition_pred$prob )\n\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\nCode\ndf <- data.frame(Sensitivity = ROC$sensitivities, \n                 Specificity = ROC$specificities)\n\nggplot(df, aes(y = Sensitivity, x= (1-Specificity))) + \n  geom_line() + \n  geom_abline(intercept = 0, slope = 1, col = \"gray\")+\n  coord_equal()\n\n\n\n\n\nArea under the curve er 0.65."
  },
  {
    "objectID": "logistisk_regresjon.html#multippel-logistisk-regresjon",
    "href": "logistisk_regresjon.html#multippel-logistisk-regresjon",
    "title": "3  Logistisk regresjon",
    "section": "3.5 Multippel logistisk regresjon",
    "text": "3.5 Multippel logistisk regresjon\nVi kan estimere en multippel regresjon på tilsvarende måte som for lineær regresjon ved å legge til flere variable eller angi å bruke samtlige variable i datasettet med ‘Attrition ~ .’\n\n\nCode\nest_multlogit <- glm(Attrition ~ ., data = training, family = \"binomial\")\nsummary(est_multlogit)\n\n\n\nCall:\nglm(formula = Attrition ~ ., family = \"binomial\", data = training)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6401  -0.4811  -0.2375  -0.0845   3.3022  \n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                      -1.108e+01  7.391e+02  -0.015 0.988043    \nX                                 1.182e-02  1.808e-02   0.654 0.513232    \nAge                              -3.616e-02  1.638e-02  -2.208 0.027268 *  \nBusinessTravelTravel_Frequently   1.643e+00  4.677e-01   3.513 0.000443 ***\nBusinessTravelTravel_Rarely       8.972e-01  4.279e-01   2.097 0.035993 *  \nDailyRate                        -3.215e-04  2.659e-04  -1.209 0.226523    \nDepartmentResearch & Development  1.304e+01  7.391e+02   0.018 0.985923    \nDepartmentSales                   1.353e+01  7.391e+02   0.018 0.985390    \nDistanceFromHome                  4.283e-02  1.309e-02   3.272 0.001068 ** \nEducation                         4.622e-03  1.047e-01   0.044 0.964782    \nEducationFieldLife Sciences      -8.897e-01  1.040e+00  -0.856 0.392123    \nEducationFieldMarketing          -3.319e-01  1.089e+00  -0.305 0.760642    \nEducationFieldMedical            -9.632e-01  1.041e+00  -0.925 0.354759    \nEducationFieldOther              -8.369e-01  1.110e+00  -0.754 0.450862    \nEducationFieldTechnical Degree    2.182e-02  1.062e+00   0.021 0.983613    \nEmployeeNumber                   -8.665e-03  1.275e-02  -0.680 0.496737    \nEnvironmentSatisfaction          -4.975e-01  9.991e-02  -4.980 6.37e-07 ***\nGenderMale                        2.164e-01  2.159e-01   1.002 0.316129    \nHourlyRate                       -3.806e-03  5.398e-03  -0.705 0.480752    \nJobInvolvement                   -5.455e-01  1.458e-01  -3.741 0.000183 ***\nJobLevel                         -1.874e-02  3.836e-01  -0.049 0.961030    \nJobRoleHuman Resources            1.412e+01  7.391e+02   0.019 0.984759    \nJobRoleLaboratory Technician      1.592e+00  5.597e-01   2.845 0.004437 ** \nJobRoleManager                   -1.635e+00  1.281e+00  -1.276 0.201838    \nJobRoleManufacturing Director    -2.252e-01  6.130e-01  -0.367 0.713385    \nJobRoleResearch Director         -2.466e+00  1.246e+00  -1.979 0.047785 *  \nJobRoleResearch Scientist         3.869e-01  5.743e-01   0.674 0.500517    \nJobRoleSales Executive            2.910e-01  1.614e+00   0.180 0.856906    \nJobRoleSales Representative       1.429e+00  1.662e+00   0.860 0.389873    \nJobSatisfaction                  -3.271e-01  9.728e-02  -3.362 0.000773 ***\nMaritalStatusMarried              3.761e-01  3.139e-01   1.198 0.230851    \nMaritalStatusSingle               9.239e-01  4.068e-01   2.271 0.023146 *  \nMonthlyIncome                     9.567e-05  9.900e-05   0.966 0.333874    \nMonthlyRate                       1.159e-05  1.500e-05   0.772 0.439838    \nNumCompaniesWorked                1.692e-01  4.654e-02   3.635 0.000278 ***\nOverTimeYes                       1.908e+00  2.326e-01   8.202 2.36e-16 ***\nPercentSalaryHike                -6.615e-02  4.722e-02  -1.401 0.161299    \nPerformanceRating                 6.925e-01  4.825e-01   1.435 0.151248    \nRelationshipSatisfaction         -3.892e-01  9.894e-02  -3.934 8.35e-05 ***\nStockOptionLevel                 -2.752e-01  1.826e-01  -1.507 0.131890    \nTotalWorkingYears                -6.554e-02  3.581e-02  -1.830 0.067226 .  \nTrainingTimesLastYear            -2.180e-01  8.601e-02  -2.535 0.011257 *  \nWorkLifeBalance                  -2.202e-01  1.476e-01  -1.492 0.135830    \nYearsAtCompany                    6.773e-02  4.882e-02   1.387 0.165295    \nYearsInCurrentRole               -1.035e-01  5.563e-02  -1.860 0.062819 .  \nYearsSinceLastPromotion           2.056e-01  5.163e-02   3.983 6.81e-05 ***\nYearsWithCurrManager             -1.928e-01  6.082e-02  -3.170 0.001525 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 944.39  on 1101  degrees of freedom\nResidual deviance: 616.23  on 1055  degrees of freedom\nAIC: 710.23\n\nNumber of Fisher Scoring iterations: 15\n\n\n\n3.5.1 ROC og AUC\nFor å beregne ROC og AUC gjør vi tilsvarende som over med predict og angi type respons. Dette brukes så videre i ROC og AUC.\n\n\nCode\nattrition_pred <- training %>% \n  mutate(prob = predict(est_multlogit, type = \"response\")) \n\n\nFunksjonen roc() gjør utregningene som trengs for ROC-kurven basert på observert utfall og predikerte sannsynligheter (Hsieh 2008).\nOBS! Man må man angi data som første argument i funksjonen roc(), deretter observerte utfall og til sist predikert sannsynlighet. Rekkefølgen er viktig!\nDet går an å få ut plottet med en quick-and-dirty versjon med plot(ROC), men det blir penere med bruk av ggplot() slik som er gjort nedenfor. Det krever at man lager en data.frame først ved å plukke ut de relevante tallene fra ROC-objektet. (Men layout er strengt tatt ikke viktig i dette kurset).\n\n\nCode\nROC <- roc(attrition_pred, Attrition, prob)\n\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\nCode\ndf <- data.frame(Sensitivity = ROC$sensitivities, \n                 Specificity = ROC$specificities)\n\nggplot(df, aes(y = Sensitivity, x= (1-Specificity))) + \n  geom_line() + \n  geom_abline(intercept = 0, slope = 1, col = \"gray\")+\n  coord_equal()\n\n\n\n\n\nVi kan da få rapportert arealet under kurven med auc() slik:\n\n\nCode\nauc(ROC)\n\n\nArea under the curve: 0.869\n\n\nNår arealet under kurven (AUC) er 0.869 er det vesentlig bedre prediksjon enn den enkle modellen."
  },
  {
    "objectID": "logistisk_regresjon.html#testing-data",
    "href": "logistisk_regresjon.html#testing-data",
    "title": "3  Logistisk regresjon",
    "section": "3.6 Testing-data",
    "text": "3.6 Testing-data\nOvenfor er øvelsen gjort på training-data, men vi må sjekke på testing-dataene.\nFor å beregne ROC og AUC gjør vi tilsvarende som over med predict, men nå er det viktig å angi ‘newdata = …’ slik at prediksjonen gjøres på riktig datasett.\n\n\nCode\nattrition_test <- testing %>% \n  mutate(prob = predict(est_multlogit, newdata = testing, type = \"response\")) \n\n\nFunksjonen roc() gjør utregningene som trengs for ROC-kurven basert på observert utfall og predikerte sannsynligheter (Hsieh 2008).\nOBS! Man må man angi data som første argument i funksjonen roc(), deretter observerte utfall og til sist predikert sannsynlighet. Rekkefølgen er viktig!\nDet går an å få ut plottet med en quick-and-dirty versjon med plot(ROC), men det blir penere med bruk av ggplot() slik som er gjort nedenfor. Det krever at man lager en data.frame først ved å plukke ut de relevante tallene fra ROC-objektet. (Men layout er strengt tatt ikke viktig i dette kurset).\n\n\nCode\nROC_test <- roc(attrition_test, Attrition, prob)\n\n\nSetting levels: control = No, case = Yes\n\n\nSetting direction: controls < cases\n\n\nCode\ndf <- data.frame(Sensitivity = ROC_test$sensitivities, \n                 Specificity = ROC_test$specificities)\n\nggplot(df, aes(y = Sensitivity, x= (1-Specificity))) + \n  geom_line() + \n  geom_abline(intercept = 0, slope = 1, col = \"gray\")+\n  coord_equal()\n\n\n\n\n\nVi kan da få rapportert arealet under kurven med auc() slik:\n\n\nCode\nauc(ROC_test)\n\n\nArea under the curve: 0.8376\n\n\nNår arealet under kurven (AUC) er 0.838. Kanskje litt overraskende, men dette like godt som for på training dataene. Dette altså selv om det er tydelige forskjeller på ROC-curvene som er plottet. AUC er altså arealet under kurven. Litt ulik form kan i prinsippet ha samme areal."
  },
  {
    "objectID": "logistisk_regresjon.html#klassifikasjon",
    "href": "logistisk_regresjon.html#klassifikasjon",
    "title": "3  Logistisk regresjon",
    "section": "3.7 Klassifikasjon",
    "text": "3.7 Klassifikasjon\nMen for et handlingsvalg må vi gjøre faktisk klassifisering. Det vi har estimert så langt er bare en sannsynlighet. Selve klassifiseringen krever at man tar et aktivt valg på en cut-off for hvem man tror faktisk slutter. La oss først se på fordelingen av sannsynligheter.\n\n\nCode\nggplot(attrition_test, aes(x = prob)) +\n  geom_histogram()\n\n\n\n\n\nVi kan bestemme oss for at et rimelig cut-off er 50/50, altså med sannsynlighet 0.5. Her gjøres en klassifisering for testing-datasettet, og lager en krysstabell med den klassifiserte etter prediksjon mot observert utfall. En slik krysstabell kalles altså en confusion matrix.\n\n\nCode\nattrition_test <- attrition_test %>% \n  mutate(attrition_class = as.factor(ifelse(prob < .5, \"No\", \"Yes\")))\n\nattrition_test %>% \n  select(Attrition, attrition_class) %>% \n  table()\n\n\n         attrition_class\nAttrition  No Yes\n      No  287  13\n      Yes  41  27\n\n\nHvis du nå lurer på om det spiller noen rolle om du har observert eller predikert i rader/kollonner, så gjør det ikke det. Det er bare to variable krysset mot hverandre. I dette tilfellet er det altså 30 personer som er gjettet riktig at vil slutte, men bare halvparten av de som faktisk sluttet ble fanget opp (27 av 30). Det var 12 som ble feilaktig gjettet at ville slutte, men som altså ikke gjorde det.\n\n3.7.1 Confusion matrix\nFra pakken ‘caret’ er det en funksjon for confusion matrix som regner ut masse greier for oss. (Vi skal bare bruke akkurat den funksjonen fra ‘caret’).\n\n\nCode\nconfusionMatrix(attrition_test$Attrition, attrition_test$attrition_class, positive = \"Yes\")\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  287  13\n       Yes  41  27\n                                          \n               Accuracy : 0.8533          \n                 95% CI : (0.8129, 0.8878)\n    No Information Rate : 0.8913          \n    P-Value [Acc > NIR] : 0.9902805       \n                                          \n                  Kappa : 0.4207          \n                                          \n Mcnemar's Test P-Value : 0.0002386       \n                                          \n            Sensitivity : 0.67500         \n            Specificity : 0.87500         \n         Pos Pred Value : 0.39706         \n         Neg Pred Value : 0.95667         \n             Prevalence : 0.10870         \n         Detection Rate : 0.07337         \n   Detection Prevalence : 0.18478         \n      Balanced Accuracy : 0.77500         \n                                          \n       'Positive' Class : Yes"
  },
  {
    "objectID": "logistisk_regresjon.html#hvor-feil-kan-man-ta",
    "href": "logistisk_regresjon.html#hvor-feil-kan-man-ta",
    "title": "3  Logistisk regresjon",
    "section": "3.8 Hvor feil kan man ta?",
    "text": "3.8 Hvor feil kan man ta?\nI klassifiseringen over er det gjort et klart valg for hvem man tror faktisk vil slutte i jobben eller ikke. Det er selvsagt slik at noen er mer sannsynlige vil slutte enn andre, men ingen har 0 sannsynlighet. Ingen har 1 heller, for den saks skyld. Det er altså usikkerhet. Men hvis vi skal gjøre et tiltak, så må vi ta det valget!\nHvis vi gjør klassifiseringen på 0.5 som over, så betyr jo det at vi synes begge feil er like viktige: Falske positive eller falske negative. Hvis det er et langt større problem at folk slutter enn at noen f.eks. får tilbud om goder eller ekstra oppfølging etc, så kan det hende cut-off skal settes lavere? Da får man flere sanne positive, men også flere feil. Det kan det jo være verd, men kommer jo an på hva konsekvensene. Vi kommer tilbake til dette, men test gjerne ut selv med ulik cut-off og se hvordan resultatene endrer seg."
  }
]