@book{berk2016a,
  author = {Berk, Richard},
  title = {Statistical learning from a regression perspective},
  year = {2016},
  publisher = {Springer},
  address = {USA}
}



@inbook{hsieh2008, 
  author = {Hsieh, John}, 
  title = {Receiver Operating Characteristic (ROC) Curve},
  booktitle = {Encyclopedia of Epidemiology},
  year = {2008}, 
  publisher = {Sage}, 
  doi = {10.4135/9781412953948}, 
  address = {Thousand Oaks, California},
  pages = {895–98}
}


@Inbook{James2021,
  author="James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert",
  title="Unsupervised Learning",
  bookTitle="An Introduction to Statistical Learning: with Applications in R",
  year="2021",
  publisher="Springer US",
  address="New York, NY",
  pages="497--552",
  abstract="Most of this book concerns supervised learning methods such as regression and classification. In the supervised learning setting, we typically have access to a set of p features {\$}{\$} X{\_}{\{}1{\}}, X{\_}{\{}2{\}}, {\backslash}ldots, X{\_}{\{}p{\}},{\$}{\$}X1,X2,{\ldots},Xp,measured on n observations, and a response Y also measured on those same n observations. The goal is then to predict Y using {\$}{\$} X{\_}{\{}1{\}}, X{\_}{\{}2{\}}, {\backslash}ldots, X{\_}{\{}p{\}}.{\$}{\$}X1,X2,{\ldots},Xp.", 
  isbn="978-1-0716-1418-1", 
  doi="10.1007/978-1-0716-1418-1_12",
  url="https://doi.org/10.1007/978-1-0716-1418-1_12"
}



@article{land2020, 
  doi = {10.1146/annurev-lawsocsci-060220-081955},
  author = {Land, Molly K. and Aronson, Jay D.},
  title = {Human Rights and Technology: New Challenges for Justice and Accountability},
  journal = {Annual Review of Law and Social Science},
  volume = {16},
  number = {1},
  pages = {223-240},
  year = {2020},
  doi = {10.1146/annurev-lawsocsci-060220-081955},
  URL = { https://doi.org/10.1146/annurev-lawsocsci-060220-081955},
  eprint = { https://doi.org/10.1146/annurev-lawsocsci-060220-081955} ,
  abstract = { This review surveys contemporary challenges in the field of technology and human rights. The increased use of artificial intelligence (AI) in decision making in the public and private sectors—e.g., in criminal justice, employment, public service, and financial contexts—poses significant threats to human rights. AI obscures and attenuates responsibility for harms in ways that undermine traditional mechanisms for holding wrongdoers accountable. Further, technologies that scholars and practitioners once thought would democratize human rights fact finding have been weaponized by state and non-state actors. They are now used to surveil and track citizens and spread disinformation that undermines public trust in knowledge. Addressing these challenges requires efforts to ensure that the development and implementation of new technologies respects and promotes human rights. Traditional distinctions between public and private must be updated to remain relevant in the face of deeply enmeshed state and corporate action in connection with technological innovation. }
}









 @Manual{kozodoi2021, 
    title = {fairness: Algorithmic Fairness Metrics},
    author = {Nikita Kozodoi and Tibor {V. Varga}},
    year = {2021},
    note = {R package version 1.2.2},
    url = {https://CRAN.R-project.org/package=fairness},
  }
