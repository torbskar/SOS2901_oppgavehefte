# Boosting

I dette kapittelt skal vi bruke følgende pakker: 

```{r}
#| eval: true
#| code-fold: false
#| echo: true
#| warning: false 
#| message: false
library(tidyverse)   # datahåndtering, grafikk og glimpse()
library(rsample)     # for å dele data i training og testing
library(gbm)         # Funksjoner for boosting 
library(caret)       # For funksjonen confusionMatrix()
library(fairness)    # For fairnessmetrics 
library(gtsummary)   # For å lage litt penere tabeller
```


Det er flere typer boosting-algoritmer. Men vi skal fokusere på stochastic gradient boosting. Adaptive boosting er presentert i læreboka, men først og fremst som et illustrativt eksempel eller en pedagogisk introduksjon. Andre boosting-algoritmer er varianter av gradient boosting. 

Det er også et poeng at softwaren for adaptive boosting er mer begrenset enn for gradient boosting. Vi bruker 'gbm' pakken som gir grunnleggende funksjonalitet.

Det sentrale punktet for boosting er at modellen bygges steg for steg med en gradvis forbedring fra forrige runde slik at modellen blir gradvis bedre og bedre. Dette til kontrast til *bagging* der styrken ligger i avstemning på tvers av mange klassifikasjonstrær. I boosting er det altså samme modell som forbedres i hvert steg. Dette gjøres på en måte der feilklassifiseringen vektes opp i hver iterasjon. I adaptive boosting lages den en vekt litt mekanisk, mens i gradient boosting baseres det på en gradient fra velkjente statistiske fordelinger, f.eks. binomisk fordeling for kategorisk utfall. 

<!-- # Kilde: https://towardsdatascience.com/how-to-select-between-boosting-algorithm-e8d1b15924f7 -->
<!-- # http://uc-r.github.io/gbm_regression -->


Vi bruker compas-dataene igjen. Men nå må vi omkode utfallsvariabelen til en numerisk variabel fordi funksjonen `gbm` krever nummerisk utfallsvariabel. 

```{r}
compas <- readRDS("../data/compas.rds") %>% 
  mutate(Two_yr_Recidivism = ifelse(Two_yr_Recidivism == "1", 1, 0)) %>% 
  na.omit()
glimpse(compas)

```

Vi lager en split som tidligere

```{r}
set.seed(42)
training_init <- initial_split(compas)

training <- training(training_init)
testing  <- testing(training_init)

```


## Stochastic gradient boosting
Gradient boosting for klassifisering bruker ikke vekter på samme måte som adaboost, men bruker residualene. For et binomisk utfall (to kategorier kodet 0 eller 1) er residualen, $r_i$, er definert som 

$$ r_i = y_i - \frac{1}{e^{-f(x_i)}} $$
Litt forenklet kan vi si at dette er det observert utfallet minus det predikerte utfallet fra logistisk regresjon. "Gradienten" er da $f(x)$. 

Gradient boosting fungerer med flere andre fordelinger, men hvis vi begrenser oss til klassifikasjon kan vi angi `distribution = "bernoulli"`. Merk at for `gbm` må utfallsvariabelen være numerisk, ikke factor. 

```{r}
set.seed(542)
gradboost1 <- gbm(formula = Two_yr_Recidivism ~ .,
                 data = training,
                 distribution = "bernoulli",
                 n.trees = 4000,
                 interaction.depth = 3,
                 n.minobsinnode = 1,
                 shrinkage = 0.001,
                 bag.fraction = 0.5)

```

Merk angir argumentet `bag.fraction = 0.5` i modellen (som forøvrig også er forvalget, så man behøver ikke skrive det, egentlig). I hver split brukes altså halve utvalget til å bestemme neste split slik at andre halvdel er out-of-bag data. Hvis dette argumentet settes til 1 brukes hele datasettet i hver split. 

Standard plot av gis ved `gbm.perf()` som nedenfor, og viser forbedring for hver iterasjon. Ytterligere forbedring stopper opp ved nærmere 2500 iterasjoner, markert ved den vertikale blå linjen. 

```{r}
#| message: false
#| error: false

gbm.perf(gradboost1, oobag.curve = TRUE, method = "OOB", 
            plot.it=T, overlay = T) 
  
```

Denne estimeringen kan justeres ved å endre tuningparametrene. 

* `n.trees` er antall iterasjoner, dvs. antall klassifikasjonstrær. Forvalget er 100, som er åpenbart altfor lavt, så sett noen tusen. 
* `interaction.depth` er antall split i hvert tre. Forvalget er 1, men Berk sier at 1-3 er ok. 
* `n.minobsinnode` er minste antall observasjoner i siste node. Forvalg er 1, men Berk anslår at 5-15 fungerer bra. (Hvis modellen har bare en split er det ikke sikkert dette er så viktig)
* `shrinkage` er hvor store skritt langs gradienten som testes i hver iterasjon, og dette skal være lavt. Forvalget er 0.001. Kostnaden er at det tar lengre tid enn ved et høyere tall (opp til 10 kan testes). 
* `bag.fraction` er hvor stor andel av data som brukes i hver iterasjon. Dette hjelper for å redusere overfitting. Forvalget er 0.5, som innebærer at andre del av data kan fungere som OOB. Merk at Berk understreker at OOB bare kan brukes til å vurdere tilpassingen slik som i figuren over. 


## Tolkbarhet
Som i random forest kan vi undersøke hvilke variable som er mest betydningsfulle i prediksjonen. I utgangspunktet gir `summary()` mot et gbm-objekt et plot, men dette er stygt og kan være vanskelig å lese skikkelig. Derfor inneholder koden nedenfor argumentet `plotit=FALSE`, så lages det et bedre plot med `ggplot()` etterpå.^[Estetikken er imidlertid underordet her. Sett gjerne `plotit = TRUE` for et mer quisk-and-dirty plot.] 

Resultatene er tolkbare tilsvarende som relative importance som vi så i random forest. 

```{r}
sumboost <- summary(gradboost1, method = permutation.test.gbm, normalize = T, 
                    plotit = F)

ggplot(sumboost, aes(x = reorder(var, rel.inf), y = rel.inf)) +
  geom_col()+
  ylab("Relative influence")+
  xlab("")+
  coord_flip()


```

Merk at resultatet fra `summary()` her returnerer en data.frame som kan plottes direkte med `ggplot`. Eneste mystiske som skjer er at `x` er angitt som sortert etter verdier på `y`-variabelen. Så er plottet snudd om med `coord_flip` til slutt. 

Man kan også plotte hvordan resultatet endres med ulike verdier på prediktorene. Dette tilsvarer *partial dependence*. Her er det mest hensiktsmessig å bruke den innebygde funksjonen `plot()` som kaller en underliggende plot-funksjon for gbm-objekter. 

```{r}
plot(gradboost1, "Number_of_Priors", type = "response")
plot(gradboost1, "Age_Below_TwentyFive", type = "response")
plot(gradboost1, "Ethnicity", type = "response")
plot(gradboost1, "Misdemeanor", type = "response")

```




## Prediksjon og confusion matrix 
Vi gjør prediksjon på tilsvarende måte som før, men det er et par viktige detaljer. Forvalget for `predict()` for gbm-objekter er $f(x)$ som her er på log odds skalaen, men hvis vi setter `type = "response"` så får vi ut en sannsynlighet (dvs. et tall mellom 0 og 1). Da kan vi klassifisere etter hvilken gruppe som er mest sannsynlig, dvs. hvis høyere enn 0.5


```{r}
#| message: false
#| warning: false
compas_p <- training %>% 
  mutate(pred = predict(gradboost1, type = "response"), 
         p_klass = ifelse(pred > 0.5, 1, 0))

```

Lager enkel krysstabell med predikert mot observert (dvs confusion matrix)

```{r}
tab <- table(compas_p$p_klass, training$Two_yr_Recidivism) 
tab
```

Lager bedre confusion matrix med alle øvrige utregninger. NB! Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei. 

```{r}
confusionMatrix(tab, positive="1")
```



## Asymetriske kostnader 
Vi har det vanlige problemet med å vurdere om falske positive og falske negative er like problematisk. Igjen er det slik at den vurderingen krever en vurdering av utfallet man ønsker gjøre noe med og konsekvensene av tiltaket som skal iverksettes. For credit-dataene kan det jo være at noen ikke vurderes som kredittverdige.^[Det er forresten også en implisitt vurdering her om hvem sitt problem dette er: banken behøver ikke synes det er problematisk å si nei til et boliglån, mens det fra samfunnets synsvinkel kan være uheldig at noen grupper sperres ute av boligmarkedet. Hvem som er "stakeholder" her er altså også et poeng, som vi lar ligge i denne sammenheng.] 

For å håndtere asymetriske kostnader kan vi vekte utfallene forskjellig og angi denne vekten i prosedyren. Argumentet `weights = ...` tar en vektor med verdier (ét tall for hver observasjon i dataene) og skal ikke være en del av datasettet. 

Her er et eksempel der falske positive tillegges 3 ganger så mye vekt som falske negative.  


```{r}
wts <- training %>% 
  mutate(wts = ifelse(Two_yr_Recidivism == 1, 1, 2)) %>%   # se begrunnelse s. 277 i Berk 
  pull(wts)

set.seed(542)
gradboost2 <- gbm(formula = Two_yr_Recidivism ~ .,
                 data = training,
                 weights = wts, 
                 distribution = "bernoulli",
                 n.trees = 4000,
                 interaction.depth = 3,
                 n.minobsinnode = 1,
                 shrinkage = 0.001,
                 bag.fraction = 0.5)


```


Så kan vi gjøre prediksjon og confusion matrix på nytt. 


```{r}
#| message: false
#| warning: false
compas_p <- training %>% 
  mutate(pred = predict(gradboost2, type = "response"), 
         p_klass = ifelse(pred > 0.5, 1, 0))

```

Lager enkel krysstabell med predikert mot observert (dvs confusion matrix)

```{r}
tab <- table(compas_p$p_klass, training$Two_yr_Recidivism) 
tab
```

Så kan vi legge tabellen inn i funksjonen `confusionMatrix()` for å også få diverse utregninger. (Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei.) Dette er altså akkurat samme prosedyre som vi har brukt ved tidligere prediksjoner. 

```{r}
confusionMatrix(tab, positive="1")
```



## Hva med bias og fairness? 
Det er heller ingenting nytt når det gjelder om prediksjonen kan slå ut skjevt for ulike grupper. Selvfølgelig kan det skje, og det bør jo undersøkes. Vi kan bruke akkurat de samme funksjonene som før. 

Her er et eksempel med forskjeller i "accuracy" for menn og kvinner. Det er altså høyere andel riktig klassifiserte for kvinner enn for menn. 

```{r}
acc <- fairness::acc_parity(data = compas_p, 
                  outcome      = 'Two_yr_Recidivism', 
                  group        = 'Sex',
                  preds        = 'p_klass', 
                  base         = 'Female')

acc[[2]]

```

## Justere rettferdighet med vekting
Vi har allerede sett at vi kan justere algoritmen for asymetriske kostnader ved å vekte utfallet forskjellig. Vi kan også justere slik at vi også vekter opp undergrupper. Igjen er det ikke helt åpenbart hvordan det vil slå ut å vekte en gruppe opp eller ned, så det må vi sjekke. 

La oss først 

Her er en kode for å lage vekter og legger den vekten inn i `gbm`. Tanken i koden her er å først angi vektingen for kostnader og undergrupper hver for seg, og så legge disse til per person i datasettet. 

La oss først se på fordelingen av utfallet etter kjønn ved en enkel krysstabell. Her har jeg brukt funksjonen `tbl_cross()` for å få en penere tabell med summeringer, men en enklere tabell gjør også nytten.  

```{r}
training %>% 
   tbl_cross( row = Sex, col =  Two_yr_Recidivism)
```

Vi ser her at i datamaterialet er det lavere residiv blant kvinner enn menn, men det er også færre kvinner enn menn totalt. Dette kan jo være en indikator på hva som bør vektes opp. Her er et forslag der kvinner vektes opp generelt, men kvinner med residiv vektes opp enda mer. For menn vektes også residiv opp. 

Vekten skal lages så det blir et tall per observasjon i datasettet, så utgangspunktet er trainingdataene. Så la oss lage en vekt som tar utgangpunktet i menn uten residiv og vekter det som 1. Hvis vi vil vekte opp residiv, så settes menn med residiv til 2. Tilsvarende for kvinner kan vi sette vektene høyere, f.eks. henholdsvis 2 og 4. 

I koden nedenfor lages også en krysstabell bare for å sjekke at det ble slik det var tenkt. Tabellen har bare funksjon for å sjekke at det ble riktig. 


```{r}

wts <- training %>%  
  mutate(wts1 = case_when(
    Sex == "Male" & Two_yr_Recidivism == 0 ~ 1,
    Sex == "Male" & Two_yr_Recidivism == 1 ~ 2, 
    Sex == "Female" & Two_yr_Recidivism == 0 ~ 2,
    Sex == "Female" & Two_yr_Recidivism == 1 ~ 4)) %>% 
    pull(wts1)

library(gtsummary)
df <- training %>% 
  mutate(wts = factor(wts))

df %>%  
  select(Sex, Two_yr_Recidivism, wts) %>% 
 tbl_strata(
    strata = Sex,
    ~.x %>%
      tbl_summary(
        by = Two_yr_Recidivism, 
        #type = everything()~"categorical", 
        statistic = all_categorical() ~ "{n}"
      )
  )
```

Kodingen av vekten kan treng litt forklaring. Det er forsåvidt standard R-kode, men likevel: 

* `case_when()` brukes for gjentatt if-else i flere ledd. Altså først vurderes første kriterium og får tilskrevet den verdien som følger etter `~`.  *For øvrige observasjoner* sjekkes neste kriterium på samme måte. 
* `pull()` brukes når man bare skal beholde én variabel som en vektor (ikke ny data.frame) 
* `tbl_strata` fra pakken gtsummary brukes til å lage en tre-veis tabell. Det spiller liten rolle hvordan tabellen lages, men denne gir en pen og lett lesbar tabell. 

Da kan vi gjøre en ny boostingmodell og sjekke resultatene. Koden er identisk som ovenfor, bare at vektene er endret 

```{r}
set.seed(542)
gradboost3 <- gbm(formula = Two_yr_Recidivism ~ .,
                 data = training,
                 weights = wts, 
                 distribution = "bernoulli",
                 n.trees = 4000,
                 interaction.depth = 3,
                 n.minobsinnode = 1,
                 shrinkage = 0.001,
                 bag.fraction = 0.5)

```



```{r}
#| message: false
#| warning: false
compas_p <- training %>% 
  mutate(pred = predict(gradboost3, type = "response"), 
         p_klass = ifelse(pred > 0.5, 1, 0))

```

Lager enkel krysstabell med predikert mot observert (dvs confusion matrix)

```{r}

tab <- table(compas_p$p_klass, training$Two_yr_Recidivism) 
tab
```

Lager bedre confusion matrix med alle øvrige utregninger. NB! Husk å presisere hva som er positiv verdi for at tallene skal blir riktig vei. 
```{r}
confusionMatrix(tab, positive="1")
```



```{r}
#| message: false
#| error: false
acc <- acc_parity(data = compas_p, 
                  outcome      = 'Two_yr_Recidivism', 
                  group        = 'Sex',
                  preds        = 'p_klass', 
                  base         = 'Female')
acc[[2]]

```





## Oppgaver
::: {#exr-}
Se over de vurderingene du gjorde i tidligere analyser av compas-dataene, herunder hva slags feilrater du er villig til å akseptere og hva slags konsekvenser de ulike typene feil kan få. Vil du gjøre andre vurderinger nå? Ta stilling til om du fremdeles synes tidligere vurderinger var ok. Bestem deg for hvor mange falske positive du er villig til å godta per falske negative (dvs asymetriske kostnader). Bruk dette videre i neste oppgave. 
:::

::: {#exr-}
Gå gjennom eksempelet over og repliker disse analysene slik at du ser at du skjønner hvordan det fungerer. Men du må gjøre tre endringer: 

1) Vurder asymetriske konstnader, spesielt cost-ratio (dvs. forholdet mellom falske positive og falske negative). Se om du klarer å justere modellen så du får dette resultatet. 
1) Sjekk mål på fairness også for etnisitet. Test ut flere forskjellige mål fra fairness-pakken. Bruk fortsatt *training*datasettet. 
1) Etter at du har kjørt gjennom alt med *training*datasettet må du sjekke resultatet mot *testing*datasettet. Ble det vesentlig endring i resultatene? 

:::


::: {#exr-}
Bruk et annet datasett og gjør tilsvarende analyser. Husk å få med følgende deler: 

a) Vurdering av konsekvenser av feil: hva vil du godta? Begrunn svaret med et tenkt tiltak som skal settes i verk. 
a) Tilpass modellen, og vurder om du har nok iterasjoner (antall runder i boostingen). Øk ved behov. 
a) Prediker, lag confusion matrix og sammenlign med hva du i utgangspunktet bestemte deg for å godta. Hvis det trengs endringer, juster modellen på nytt til du er mer fornøyd. 
a) Kommenter hvilke variable som er mest betydningsfulle for prediksjonen og på hvilken måte. 
a) Hvilke mål på fairness synes du er mest relevant her og for hvilke undergrupper? Sjekk dette empirisk. 
a) Prøv å justere modellen til et mer tilfredsstillende rettferdig resultat for valgte undergrupper.
a) Sjekk nå resultatene (inkl. fairness) for *testing*dataene også. 
a) Vil du sette i verk tiltak basert på en slik prediksjonsmodell? Begrunn svaret. 

:::



