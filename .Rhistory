filter(complete.cases(.))
dim(test)
dim(tcom_train)
tcom <- tcom %>%
select(-c(customerID)) %>%
filter(complete.cases(.))
tcom <- tcom %>%
select(-c(customerID)) %>%
filter(complete.cases(.))
tcom <- read.csv("data/WA_Fn-UseC_-Telco-Customer-Churn.csv")
set.seed(786)
tcom <- tcom %>%
select(-c(customerID)) %>%
filter(complete.cases(.))
tcom_split <- initial_split(tcom, prop=.75)
tcom_train <- training(tcom_split)
tcom_test <- testing(tcom_split)
tcom_train$Churn <- as.numeric(tcom_train$Churn == "Yes")
est_log <- glm(Churn ~., family = "binomial", data=tcom_train)
summary(est_log)
test <- tcom_train %>%
mutate(prob = predict(est_log, type = "response"))
dim(tcom_train)
tcom <- read.csv("data/WA_Fn-UseC_-Telco-Customer-Churn.csv")
set.seed(786)
tcom <- tcom %>%
select(-c(customerID))
tcom_split <- initial_split(tcom, prop=.75)
tcom_train <- training(tcom_split)
tcom_test <- testing(tcom_split)
tcom_train$Churn <- as.numeric(tcom_train$Churn == "Yes")
est_log <- glm(Churn ~., family = "binomial", data=tcom_train)
test <- tcom_train %>%
mutate(prob = predict(est_log, newdata = tcom_train, type = "response"))
attrition <- read.csv("data\\attrition.csv",
sep = ";")
#Tar bort variabel som inte behövs
attrition <- attrition %>%
select(-EmployeeNumber)
#Dela dataset i training/testing
set.seed(426)      # algoritmen för var splitten i data är
attrition_split <- initial_split(attrition)
training <- training(attrition_split)
testing <- testing(attrition_split)
#Gör om Attrition till en dummyvariabel 1, 0
training <- training %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
#Kör en multippel regressionsmodell
est_multlogit <- glm(Attrition ~ ., data = training, family = "binomial")
summary(est_multlogit)
attrition <- read.csv("data\\attrition.csv",
sep = ";")
glimpse(attrition)
attrition <- read.csv("data\\attrition.csv",
sep = ",")
glimpse(attrition)
#Tar bort variabel som inte behövs
attrition <- attrition %>%
select(-EmployeeNumber)
#Dela dataset i training/testing
set.seed(426)      # algoritmen för var splitten i data är
attrition_split <- initial_split(attrition)
training <- training(attrition_split)
testing <- testing(attrition_split)
#Gör om Attrition till en dummyvariabel 1, 0
training <- training %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
#Kör en multippel regressionsmodell
est_multlogit <- glm(Attrition ~ ., data = training, family = "binomial")
#Kör en multippel regressionsmodell
est_multlogit <- glm(Attrition ~ ., data = training, family = "binomial")
glimpse(training)
attrition <- read.csv("data\\attrition.csv",
sep = ",") %>%
select(-X)
#Tar bort variabel som inte behövs
attrition <- attrition %>%
select(-EmployeeNumber)
#Dela dataset i training/testing
set.seed(426)      # algoritmen för var splitten i data är
attrition_split <- initial_split(attrition)
training <- training(attrition_split)
testing <- testing(attrition_split)
#Gör om Attrition till en dummyvariabel 1, 0
training <- training %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
glimpse(training)
#Kör en multippel regressionsmodell
est_multlogit <- glm(Attrition ~ ., data = training, family = "binomial")
#Tar bort variabel som inte behövs
attrition <- attrition %>%
select(-EmployeeNumber, -Over18)
attrition <- read.csv("data\\attrition.csv",
sep = ",") %>%
select(-X)
glimpse(attrition)
#Tar bort variabel som inte behövs
attrition <- attrition %>%
select(-EmployeeNumber, -Over18)
#Dela dataset i training/testing
set.seed(426)      # algoritmen för var splitten i data är
attrition_split <- initial_split(attrition)
training <- training(attrition_split)
testing <- testing(attrition_split)
#Gör om Attrition till en dummyvariabel 1, 0
training <- training %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
glimpse(training)
#Kör en multippel regressionsmodell
est_multlogit <- glm(Attrition ~ ., data = training, family = "binomial")
summary(est_multlogit)
#Gör om Attrition till en dummyvariabel 1, 0
testing <- testing %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
#Kör prediktion på testing-datasett
attrition_test <- testing %>%
mutate(prob = predict(est_multlogit, newdata = testing, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
#Confusion Matrix med training
cm <- confusionMatrix(attrition_train$Attrition, attrition_train$attrition_class, positive = "Yes")
library(caret)
#Confusion Matrix med training
cm <- confusionMatrix(attrition_train$Attrition, attrition_train$attrition_class, positive = "Yes")
glimpse(attrition_train)
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.numeric(ifelse(prob < .5, "No", "Yes")))
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.numeric(ifelse(prob < .5, "No", "Yes")))
#Confusion Matrix med training
cm <- confusionMatrix(attrition_train$Attrition, attrition_train$attrition_class, positive = "Yes")
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response"))
glimpse(attrition_train)
hist(attrition_train$prob)
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.numeric(ifelse(prob < .5, "No", "Yes")))
glimpse(attrition_train)
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.numeric(ifelse(prob < .5, "No", "Yes")))
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
glimpse(attrition_train)
#Dela dataset i training/testing
set.seed(426)      # algoritmen för var splitten i data är
attrition_split <- initial_split(attrition)
training <- training(attrition_split)
testing <- testing(attrition_split)
#Gör om Attrition till en dummyvariabel 1, 0
training <- training %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
glimpse(training)
#Kör en multippel regressionsmodell
est_multlogit <- glm(Attrition ~ ., data = training, family = "binomial")
summary(est_multlogit)
#Gör om Attrition till en dummyvariabel 1, 0
testing <- testing %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
testing <- testing(attrition_split)
#Kör prediktion på testing-datasett
attrition_test <- testing %>%
mutate(prob = predict(est_multlogit, newdata = testing, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
#Confusion Matrix med training
cm <- confusionMatrix(attrition_train$Attrition, attrition_train$attrition_class, positive = "Yes")
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
glimpse(attrition_train)
attrition <- read.csv("data\\attrition.csv",
sep = ",") %>%
select(-X)
glimpse(attrition)
attrition <- read.csv("data\\attrition.csv",
sep = ",", stringsAsFactors = TRUE) %>%
select(-X)
#Tar bort variabel som inte behövs
attrition <- attrition %>%
select(-EmployeeNumber, -Over18)
attrition_split <- initial_split(attrition)
training <- training(attrition_split)
testing <- testing(attrition_split)
#Gör om Attrition till en dummyvariabel 1, 0
training <- training %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
#Kör en multippel regressionsmodell
est_multlogit <- glm(Attrition ~ ., data = training, family = "binomial")
#Kör prediktion på testing-datasett
attrition_test <- testing %>%
mutate(prob = predict(est_multlogit, newdata = testing, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
#Confusion Matrix med training
cm <- confusionMatrix(attrition_train$Attrition, attrition_train$attrition_class, positive = "Yes")
glimpse(attrition_train)
#Gör om Attrition till en dummyvariabel 1, 0
testing <- testing %>%
mutate(Attrition = as.numeric(Attrition == "Yes"))
#Kör prediktion på testing-datasett
attrition_test <- testing %>%
mutate(prob = predict(est_multlogit, newdata = testing, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
#Kör prediktion på training-datasett
attrition_train <- training %>%
mutate(prob = predict(est_multlogit, newdata = training, type = "response")) %>%
mutate(attrition_class = as.factor(ifelse(prob < .5, "No", "Yes")))
require(devtools)
remotes::install_github("MichelNivard/gptstudio")
Sys.setenv(OPENAI_API_KEY = "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")
gptstudio:::chat_gpt_addin()
Sys.setenv(OPENAI_API_KEY = "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")
gptstudio:::chat_gpt_addin()
remotes::install_github("JamesHWade/gpttools")
The following is a list of the television networks and announcers who have broadcast college football's Army–Navy Game over the years.
write code for estimate Ols
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 40)
#| eval: true
#| code-fold: false
#| echo: true
#| warning: false
#| message: false
library(tidyverse)   # datahåndtering, grafikk og glimpse()
library(skimr)       # funksjonen skim() for å se på data
library(rsample)     # for å dele data i training og testing
library(rpart)      # funksjoner for CART
library(rpart.plot) # funksjon for å plotte CART
library(caret)      # inneholder funksjon for confusion matrix
credit <- read.csv("../data/credit.csv", stringsAsFactors = TRUE)
skim(credit)
set.seed(42)
training_init <- initial_split(credit)
training <- training(training_init)
testing  <- testing(training_init)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class")
rpart.plot(credit_tree)
rpart.rules(credit_tree, extra=4)
training_pred <- training %>%
mutate(default_pred = predict(credit_tree,  type="class"))
tab <- training_pred %>%
select(default_pred, default) %>%
table()
tab
confusionMatrix(tab)
testing_pred <- testing %>%
mutate(default_pred = predict(credit_tree, newdata=testing, type="class"))
tab <- testing_pred %>%
select(default_pred, default) %>%
table()
tab
confusionMatrix(tab)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 40)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 100)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 2)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 20)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 5)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 20)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 30)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 15)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 20)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 1)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 40)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 30)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 50)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 20)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minsplit = 50)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 50)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 10)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 3)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 1)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 1, minsplit = 2)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 1)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class")
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 10)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 3)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 10)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class")
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", minbucket = 15)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", maxdepth = 15)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", maxdepth = 3)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", maxdepth = 4)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = 0)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = 1)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .00001)
rpart.plot(credit_tree)
rpart
?rpart
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .00001)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .00001, minsplit = 10)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .00001, minsplit = 30)
rpart.plot(credit_tree)
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .00001, minsplit = 2)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .05)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .005)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .01)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .005)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .005, minbucket = 5)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .005, minbucket = 5, minsplit = 10)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .005, minbucket = 5, minsplit = 10, maxdepth = 5)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .005, minbucket = 5, minsplit = 10, maxdepth = 6)
rpart.plot(credit_tree)
#| warning: false
#| error: false
credit_tree <- rpart(default ~ age + amount + percent_of_income + purpose + employment_duration + housing,
data=training, method="class", cp = .005, minbucket = 5, minsplit = 10, maxdepth = 7)
rpart.plot(credit_tree)
?prune
pruned_credit_tree <- prune(credit_tree)
pruned_credit_tree <- prune(credit_tree, cp = .005)
rpart.plot(pruned_credit_tree)
pruned_credit_tree <- prune(credit_tree, cp = .01)
rpart.plot(pruned_credit_tree)
pruned_credit_tree <- prune(credit_tree, cp = .015)
rpart.plot(pruned_credit_tree)
library(ipred)       # for fitting bagged decision trees
#| eval: true
#| code-fold: false
#| echo: true
#| warning: false
#| message: false
library(tidyverse)   # datahåndtering, grafikk og glimpse()
library(skimr)       # funksjonen skim() for å se på data
library(rsample)     # for å dele data i training og testing
library(rpart)       # for fitting decision trees
library(ipred)       # for fitting bagged decision trees
library(e1071)       # for calculating variable importance
library(caret)       # for general model fitting og confusionMatrix()
baggedtree <- bagging(default ~ . , data = training)
?bagging
attr(baggedtree)
str(baggedtree)
baggedtree$OOB
baggedtree <- bagging(default ~ . , data = training, OOB = TRUE)
length(baggedtree$y)
baggedtree <- bagging(default ~ . , data = training, OOB = FALSE)
length(baggedtree$y)
baggedtree <- bagging(default ~ . , data = training, coob = TRUE)
baggedtree$OOB
baggedtree <- bagging(default ~ . , data = training, ns = 100)
length(baggedtree$mtrees)
baggedtree <- bagging(default ~ . , data = training, ns = 100)
length(baggedtree$mtrees)
baggedtree <- bagging(default ~ . , data = training, mtree = 100)
length(baggedtree$mtrees)
baggedtree <- bagging(default ~ . , data = training, nbagg = 100)
baggedtree <- bagging(default ~ . , data = training, nbagg = 100)
length(baggedtree$mtrees)
plot(baggedtree)
credit <- read.csv("../data/credit.csv", stringsAsFactors = TRUE, minsplit = 10)
baggedtree <- bagging(default ~ . , data = training, nbagg = 100, minsplit = 20)
baggedtree
baggedtree <- bagging(default ~ . , data = training, nbagg = 100, coob = TRUE)
baggedtree
baggedtree <- bagging(default ~ . , data = training, nbagg = 100)
credit <- read.csv("../data/credit.csv", stringsAsFactors = TRUE)
baggedtree <- bagging(default ~ . , data = training, nbagg = 100)
baggedtree
summary(baggedtree)
baggedtree
baggedtree <- bagging(default ~ . , data = training, nbagg = 100)
baggedtree
baggedtree
baggedtree <- bagging(default ~ . , data = training, nbagg = 100, coob = TRUE)
baggedtree
oob_baggedtree <- bagging(default ~ . , data = training, nbagg = 100, coob = TRUE)
oob_baggedtree
#| eval: true
#| code-fold: false
#| echo: true
#| warning: false
#| message: false
library(tidyverse)   # datahåndtering, grafikk og glimpse()
library(skimr)       # funksjonen skim() for å se på data
library(rsample)     # for å dele data i training og testing
library(rpart)       # for fitting decision trees
library(ipred)       # for fitting bagged decision trees
library(e1071)       # for calculating variable importance
library(caret)       # for general model fitting og confusionMatrix()
#| warning: false
#| message: false
credit <- read.csv("../data/credit.csv", stringsAsFactors = TRUE)
baggedtree <- bagging(default ~ . , data = training, nbagg = 100)
baggedtree
print(baggedtree)
print(baggedtree)
baggedtree
baggedtree <- bagging(default ~ . , data = credit, nbagg = 100)
